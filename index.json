[{"content":"0. Introduction   HTML과 CSS에 대한 기본적인 내용을 정리해보는 글이다.\n  크롬, 익스플로어, 파이어폭스 같은 브라우저들은 서버에서 보내는 HTML, CSS 그리고 javascript 파일을 분석하여 구현한 후, 클라이언트들에게 보여준다.\n  지난 \u0026lsquo;Study01.md\u0026rsquo;에서 이 3가지 중 HTML과 CSS가 무엇인지에 알아보았고, 더 나아가 HTML tag에 대해 알아보았다. 이번에는 CSS에 대해 더 알아보자.\n   1. What is CSS ? 지난 study에서 css란 HTML의 tag를 꾸며주는 역할로, 클라이언트에게 보여주는 스타일을 담당한다는 걸 알았다.\n그렇다면 CSS라는 명칭은 무슨 의미일까??\nCSS란 \u0026lsquo;Cascading Style Sheets\u0026rsquo; 의 약어로, 여기서 Cascading이란 \u0026lsquo;one after the other\u0026rsquo; 순서대로 위에서부터 차례대로 흘러간다는 의미다.\n무슨 말인가??\n브라우저가 CSS를 읽은 방법이 위에서부터 아래로 읽는다는 것이다.\n즉, 동일한 부분에 대해 다른 방식으로 CSS가 코드 위에서와 아래에서 스타일을 적용했다면, 맨 마지막에 있는 아래의 것이 최종적으로 적용된다는 것이다.\n CSS란 Cascading Style Sheets의 약어로, 브라우저가 css를 읽는 방식을 나타내는데 브라우저가 CSS를 읽을 때 상대적으로 아래의 있는 css를 최종적으로 적용한다. 그리고, 이 CSS는 HTML tag를 꾸며주는 역할을 수행한다.\n ❗ CSS의 속성들 또한 html의 tag처럼 매우 종류가 다양하므로 외우지 않고, 어떻게 동작하는지만 기억하자.\n 2. CSS를 추가하는 방식: 두 가지  CSS를 추가하는 방식에는 inline 방식와 External 방식이 있다.\n CSS를 추가하는 방식인 inline 방식와 external 방식에 대해 알아보자.\n첫 번째, \u0026lsquo;Inline\u0026rsquo; 방식은 방식의 명칭대로 \u0026lsquo;코드 라인 내부에\u0026rsquo; CSS를 넣는 방식으로, HTML 파일에 HTML 코드와 CSS 코드를 다 작성하는 방식 이다.\n두 번째, \u0026lsquo;External\u0026rsquo; 방식은 첫 번째와 반대로 CSS와 HTML code를 분리하는 것으로, CSS를 별도의 파일로 만들어서 HTML 파일에서 불러와 사용하는 방식 이다.\n대부분 권장하는 방식은 \u0026lsquo;External\u0026rsquo; 방식이 있는데, 2가지 이유가 있다.\n 첫 번째, 별도의 파일로 만들기 때문에 다른 더 많은 html page에서 사용할 수 있다. 두 번째, 분리된 파일을 가지고 있는 방식이 보기 깔끔하다.  2.1 Inline 방식 그러면 코드 라인 내부에 CSS를 입력한다면 html tag의 어디에 입력할까?\nhtml tag의 기본 템플렛이 다음과 같을 때, \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; tag 안에 \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt;를 넣어서, 이 \u0026lt;style\u0026gt; \u0026lt;/style\u0026gt; tag 안에 입력한다.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;  \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt;  \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt;  \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt;  \u0026lt;style\u0026gt;   {css}   \u0026lt;/style\u0026gt;  \u0026lt;/head\u0026gt;  \u0026lt;body\u0026gt;   \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 2.2 External 방식 외부에서 CSS 파일을 가져오는 방식은 \u0026lt;style\u0026gt; tag 사이에 입력하는 게 아닌 \u0026lt;head\u0026gt; \u0026lt;/head\u0026gt; tag 사이에 \u0026lt;link href ='css file 이름.css' rel = \u0026quot;stylesheet\u0026quot; \u0026gt;를 입력한다.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;kr\u0026#34;\u0026gt; \u0026lt;head\u0026gt;  \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt;  # External 방식  \u0026lt;link href=\u0026#34;css file 이름.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34; /\u0026gt;  \u0026lt;style\u0026gt;\u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt;  \u0026lt;div class=\u0026#34;sub\u0026#34;\u0026gt;  \u0026lt;div class=\u0026#34;subsub\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;  \u0026lt;div class=\u0026#34;subsub subsubelement\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;  \u0026lt;div class=\u0026#34;subsub\u0026#34;\u0026gt;\u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  3. CSS를 입력하는 방식 3.1 css의 일반적인 입력 방식과 사용하면 안되는 문자 꾸미고자하는 HTML tag를 \u0026lsquo;selector\u0026rsquo;라고 한다.\n이 \u0026lsquo;selector\u0026rsquo;를 입력한 후 중괄호를 열어 원하는 css 속성 이름과 속성값을 입력한다.\n또한, css를 입력할 때는 띄어쓰기, 언더바(_). 슬래쉬(/)를 사용하면 안되며, css의 속성들은 각 줄이 세미클론(;)으로 끝나야 한다.\n \u0026lt;!-- \u0026lt;h1\u0026gt; \u0026lt;/h1\u0026gt; tag에 대해 CSS를 적용한다고 하자. --\u0026gt; \u0026lt;html\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;style\u0026gt;  h1 {  /* # 속성 이름: 속성값; */  color: yellowgreen;  font-size: 50px;  }  \u0026lt;/style\u0026gt;  \u0026lt;/head\u0026gt; \u0026lt;/html\u0026gt;  3.2 tag의 id 이용하여 css 입력하기  id라는 tag attribute를 사용하여 동일한 종류의 태그들이어도, 각각 지정하여 css를 적용할 수 있다.\n 한 종류의 태그가 여러 개 있을 때, 이 태그들 각각에 서로 다른 css style을 적용하고 싶다면 어떻게 해야할까???\n바로 아래 코드와 같이 id 속성을 사용한다.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;  \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt;  \u0026lt;/head\u0026gt;  \u0026lt;body\u0026gt;  \u0026lt;div id = \u0026#34;red\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;yellow\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;green\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;blue\u0026#34;\u0026gt;   \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 그러면 이 각 div에 서로 다른 css를 적용해보기 위해서, id 값을 css에 입력하는 방법을 밑에 코드로 확인해보자.\n\u0026lt;style\u0026gt;  #id_name {  css attibute name: attribute value;  } \u0026lt;/style\u0026gt; 어떻게 id 를 사용하여 css를 입력할지 알았으니, 각각의 \u0026lt;div\u0026gt; 에 적용해보자.\n\u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;  \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt;  \u0026lt;style\u0026gt;   div {  height: 200px;  width: 200px;  }  #red {  background-color: red  }  #yellow {  background-color: yellow  }  #green {  background-color: green  }  #blue {  background-color: blue  }   \u0026lt;/style\u0026gt;  \u0026lt;/head\u0026gt;  \u0026lt;body\u0026gt;  \u0026lt;div id = \u0026#34;red\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;yellow\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;green\u0026#34;\u0026gt;  \u0026lt;div id = \u0026#34;blue\u0026#34;\u0026gt;   \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  기존 tag name을 사용하여 입력하는 방식에는 \u0026lsquo;공통사항\u0026rsquo;을 입력하고, id 값을 사용하여 각각의 tag에 id 값을 사용하여 구별해서 적용할 수 있다.\n \u0026lt;div\u0026gt; tag에만 관련하여 브라우저에게 이와 같이 말하는 것이다.\n \u0026lt;div\u0026gt; tag의 height와 width는 모두 200px로 해주고, \u0026lt;div\u0026gt; tag 중 id 값이 \u0026lsquo;red\u0026rsquo;인 것의 배경색은 red color로,  id 값이 \u0026lsquo;yellow\u0026rsquo;인 것의 배경색은 yellow color로, id 값이 \u0026lsquo;green\u0026rsquo;인 것의 배경색은 green color로, id 값이 \u0026lsquo;blue\u0026rsquo;인 것의 배경색은 blue color로 정한다.     3.3 tag의 class를 이용하여 css 입력하기  tag의 속성 class는 속성 id처럼 각 tag element들을 구별해서 가리킬 수도 있고, id와는 다르게 겹쳐서 가리킬 수 있는 attribute다.\n class 속성을 css에 입력하는 방법을 밑에 코드로 확인해보자.\nid 속성과는 달리 #아니라 .을 사용한다.\n\u0026lt;style\u0026gt;  .class값 {  css attibute name: attribute value;  } \u0026lt;/style\u0026gt; 그러면 \u0026lsquo;id\u0026rsquo; 속성으로 구현한 css 코드를 \u0026lsquo;class\u0026rsquo; 속성을 사용해서 구현해보겠다.\n\u0026lt;html\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;style\u0026gt;  .btn {  height: 200px;  width: 200px;  }  .red {  background-color: red;  }  .yellow {  background-color: yellow;  }  .green {  background-color: green;  }  .blue {  background-color: blue;  }  \u0026lt;/style\u0026gt;  \u0026lt;/head\u0026gt;  \u0026lt;body\u0026gt;  \u0026lt;div class = \u0026#34;btn red\u0026#34;\u0026gt;  \u0026lt;div class = \u0026#34;btn yellow\u0026#34;\u0026gt;  \u0026lt;div class = \u0026#34;btn green\u0026#34;\u0026gt;  \u0026lt;div class = \u0026#34;btn blue\u0026#34;\u0026gt;   \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; class는 id 속성과는 달리 속성값을 공백을 기준으로 여러 개를 입력할 수 있다.\n Reference  노마드코더 - 코코아톡 클론 코딩  ","permalink":"http://jeha00.github.io/post/html_css/study02/","summary":"CSS 입력방식인 inline과 external 방식이 각각 무엇인지, css 속성값을 입력하는 방식과 html tag의 속성인 id, class를 사용하여 css 속성 값을 입력하는 방식을 알아본다.","title":"[TIL] HTML \u0026 CSS study - CSS 01"},{"content":"0. Introduction   해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.\n  Chapter 12로 Git 자체에 대한 마지막 강의로 gitmoji 와 git submodules를 학습한다.\n   1. git hooks  git 상의 이벤트마다 자동적으로 실행될 스크립트를 지정하는 것으로 \u0026lsquo;자동화\u0026rsquo; 라고 생각하자.\n   git hooks와 함께 Gitmoji에 대해 알아보자.\n  커밋을 하면 자동적으로 푸쉬가 실행되게 하던가, 커밋 전 코드가 약속된 형식대로 되어있는지 확인하는 것 등등 \u0026lsquo;자동화\u0026rsquo;가 이뤄지게 한다.\n  프로젝트 폴더 내의 .git \u0026gt; hooks 폴더를 들어가 확인하면 .sample이란 형식의 파일들이 들어있다.\n  그러면 실습을 하기 위한 환경을 만들기 위해 gitmoji 를 설치해보자.\n  Gitmoji   Gitmoji란?\n gitmoji - README.md를 참고한다. an initiative to standardize and explain the use of emojis on GitHub commit messages. 깃헙의 커밋 메세지에 대해서 이모지 사용을 표준화하고 설명하는 것으로서, 커밋 메세지에 관해 이모지를 사용하여 커밋의 의도 또는 목적을 쉽게 식별할 수 있는 방법이다. 그래서 gitmoji - list에 나와있는대로 각 이모지마다 독립적인 의미를 가진다.    Gitmoji 설치하기\n  먼저 node.js를 설치하기.\n command에 npm -v를 입력하여 version이 뜨면 성공적으로 설치된 것  ❗ node.js를 설치했어도 npm 명령어가 인식되지 않으면 vsc를 껐다가 다시 켜보자.\n  터미널 명령어를 사용하여 gitmoji-cli를 설치한다.\n npm i -g gitmoji-cli    그 후, gitmoji -i를 입력하면, 아래 코드처럼 진행되면서 prepare-commit.msg 가 생성.\n  \u0026gt; gitmoji -i - Creating the gitmoji commit hook Gitmoji commit hook created successfully   hook 과 Gitmoji 학습하기   그러면 본격적으로 hook과 gitmoji 둘 다 학습해보자.\n  파일의 변화를 준 후, git add .를 실행한다.\n 그 다음 git commit 만 입력하면, 이모지가 뜬다. 원하는 이모지 스펠링을 입력 후, 선택 및 엔터를 누른다. 남기기 원하는 commit mesage를 입력 후, 엔터를 누른다. vim 모드가 뜨면 :wq를 입력하여 저장 및 나간다.    ❗ gitmoji-cli hook 해제하기 hooks 폴더에서 prepare-commit-msg file을 삭제하면 된다.\n 2. git submodules  프로젝트 폴더 안에 또 다른 프로젝트가 포함될 때 사용한다.\n  프로젝트 폴더 구성은 다음과 같다.  # 경로: main-project \u0026gt; dir main-project-files module-project-1 module-project-2  main-project와 main-project 안에 module-project-1,2 도 git으로 관리된다.  그런데, module project가 물리적으로는 main-project 안에 있지만, git 관리는 따로 하고 싶을 때 어떻게 해야할까? 즉, main-project에 대한 git 관리에 module-project-1,2를 별도로 떨어뜨려 관리하고 싶으면 어떻게 해야할까?    ❗ module-project 또한 git이 지속해서 관리해야해서 .gitignore에 등록하면 안된다.\n 여러 프로젝트에 사용되는 공통모듈일 때 유용하다.  2.1사용해보기 2.1.1. 두 프로젝트 생성하기 첫 번째, main-project에 git remote add origin \u0026lt;Github addess\u0026gt; 를 추가한다.\n두 번째, 두 개의 프로젝트를 생성하기\n2.1.2. submodule 추가하기 main-project에 서브모듈로 submodule 프로젝트 추가한다.\n  main-project 디렉토리상 터미널에서 아래 명령어 실행\n git submodule add (submodule의 GitHub 레포지토리 주소) (하위폴더명, 없을 시 생략) 프로젝트 폴더 내 submodule 폴더와 .gitmodules 파일 확인 스테이지된 변경사항 확인 뒤 커밋 양쪽 모두 수정사항 만든 뒤 main-project 에서 git status로 확인  $ git status On branch main Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) (commit or discard the untracked or modified content in submodules)  modified: main.txt  modified: submodule1 (modified content)  modified: submodule2 (modified content)  no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;)  그러면 git add .를 실행한 후 다시 확인해보자.  $ git add . $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  modified: main.txt  Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory) (commit or discard the untracked or modified content in submodules)  modified: submodule1 (modified content)  modified: submodule2 (modified content)  submodule의 변경사항은 포함되지 않음을 확인    main-project에서 변경사항 커밋 후 푸시 -\u0026gt; submodule에서 변경사항 커밋 후 푸시 -\u0026gt; main-project에서 상태 확인 -\u0026gt; main-project에 커밋, 푸시 후 GitHub에서 확인\n   즉, submodule로 등록되었으면 서브 모듈로 등록된 폴더 내부의 파일 변화는 감지할지라도, 서브 모듈 내부 파일들의 변화까지 한 번에 커밋되지는 않는다.\n 2.1.3. 서브모듈 업데이트   main-project 새로운 곳에 clone하기\n 서브모듈 폴더들은 존재해도 파일들은 없기 때문에 아래 단계를 진행한다.    아래 명령어들로 서브모듈 init 후 클론\n  git submodule init (특정 서브모듈 지정시 해당 이름만 입력)\n .gitmodules의 [submodule \u0026quot;\u0026lt;submodule name\u0026gt;\u0026quot;] 에서 \u0026lt;submodule name\u0026gt;을 입력한다. ex) git submodule init submodule1    git submodule update\n    # 경로: main-project가 있는 folder  $ git submodule init $ git submodule update Cloning into \u0026#39;C:/Users/rudtl/Desktop/Dev/GitHub/git-test/git-practice1/submodule1\u0026#39;... Cloning into \u0026#39;C:/Users/rudtl/Desktop/Dev/GitHub/git-test/git-practice1/submodule2\u0026#39;... Submodule path \u0026#39;submodule1\u0026#39;: checked out \u0026#39;0434727626afe874b8a0ccaa4cd89ce716f14b37\u0026#39; Submodule path \u0026#39;submodule2\u0026#39;: checked out \u0026#39;8f86fe62491d0930f4d93963a3c42f7db852447b\u0026#39; (base) 4. GitHub에서 submodule에 수정사항 커밋\n git submodule update --remote  $ git submodule update --remote remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 627 bytes | 27.00 KiB/s, done. From https://github.com/JeHa00/git-submodule1 033d9fe..e46b343 main -\u0026gt; origin/main Submodule path \u0026#39;submodule1\u0026#39;: checked out \u0026#39;e46b3437d1b2d7c3e03ebc6fabbc9956572399c7\u0026#39; remote: Enumerating objects: 5, done. remote: Counting objects: 100% (5/5), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 626 bytes | 34.00 KiB/s, done. From https://github.com/JeHa00/sub2 8de549f..4e300ab main -\u0026gt; origin/main Submodule path \u0026#39;submodule2\u0026#39;: checked out \u0026#39;4e300ab56e9282da6278decca5e067ee025c7aa7\u0026#39;  서브모듈 안에 또 서브모듈 있을 시: --recursive 추가   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter12/","summary":"hook을 사용하여 gitmoji 를 사용하는 방법을 학습하나 후, submodule이란 무엇이고 어떠한 장점이 있는지를 학습한다. 그리고, git submodule 명령어를 통해 submodule 연결을 해본다.","title":"[TIL] Git study: Lecture Chapter 12 - Gitmoji \u0026 git submodules"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 그래서 이번 소단원에서는 git bisect 라는 명령어로 코드에서 문제가 발생한 지점을 찾아내보겠다.   git bisect   Problem: 아래와 같이 많은 커밋 버전을 하나 하나 실행해보면서 오류가 어디서부터 시작했는지 찾을려면 시간이 많이 걸린다.\n  git log로 commit 내역을 확인해본다.\n$ git log ... commit 9a9304295288c28e0ddf6f66997c1f453831c14d Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:28 2022 +0900   v4  commit 7d167e9e36af71c5d42c77a30640610a1ba57164 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:10 2022 +0900   v3 - suspicious!  commit 37dd5cc8d9c8f93e293fa024dbdb48bf9d5b0170 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:09:28 2022 +0900   v2  commit aded506c5583e1556ba052facb5aeb169afbc880 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:09:20 2022 +0900   v1     Solution: git bisect를 사용한다.\n 원리: 이진 탐색으로 점차 탐색 범위를 줄여가면서 오류의 원인을 찾아나간다.    탐색 순서\n  첫 번째, 이진 탐색 시작\n git bisect start    두 번쨰, 오류발생 지점임을 표시\n 현재 시점에서는 오류가 발생된 걸 확인했으므로, git bisect bad    세 번째, 의심 지점으로 이동\n git checkout (해당 커밋 해시) commiet message가 v3 지점으로 이동해본다.    네 번째, 오류 발생 않을 시 양호함 표시\n git bisect good 이동했지만, 에러가 없는 시점이므로, 위와 같이 입력한다. 그러면 git bisect good 과 git bisect bad를 입력한 두 커밋의 중간 지점으로 자동적으로 이동한다.    다섯 번째, 원인을 찾을 때까지 반복\n git bisect good/bad를 입력하면서 반복하며 좁혀지다가 끝에 다다르면 밑 메세지와 같이 동일한 메세지가 뜬다.    eb18f28cad35687a712ff2c58dbfcba6ac6d97a9 is the first bad commit commit eb18f28cad35687a712ff2c58dbfcba6ac6d97a9 Author: yalco \u0026lt;yalco@kakao.com\u0026gt; Date: Tue Jan 4 14:10:39 2022 +0900   v5  program.yaml | 4 ++-- 1 file changed, 2 insertions(+), 2 deletions(-)  이진 탐색 종료  git bisect reset       Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-04/","summary":"git bisect 명령어를 통해서 이진 탐색과 commit hash number를 이용하여 오류 지점을 찾아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git bisect"},{"content":"0. Introduction   HTML과 CSS에 대한 기본적인 내용을 정리해보는 글이다.\n  크롬, 익스플로어, 파이어폭스 같은 브라우저들은 서버에서 보내는 HTML, CSS 그리고 javascript 파일을 분석하여 구현한 후, 클라이언트들에게 보여준다.\n  그러면 이 3가지 중 HTML과 CSS가 무엇인지에 대해 알아보자.\n   1. What is HTML and CSS ?   브라우저는 사람의 언어를 이해하지 못 하기 때문에, 만든 웹 사이트를 이해하기 위해서는 브라우저가 이해하는 언어로 전달해야 하기 때문에, 브라우저의 구성 요소인 3가지로 전달한다.\n  그러면 웹 사이트의 구성 요소인 HTML, CSS, Javascript란 무엇일까??\n  흔히들 이 3가지를 신체와 비교하여 다음과 같이 설명한다.\n  HTML: 사람의 신체에 비유하자면 뼈대로서, Markup language 종류로 브라우저에게 tag 를 사용하여 이 컨텐츠의 종류가 무엇인지를 알려주는 역할   CSS: 사람의 신체에 비유하자면 근육으로서, 이 콘텐츠를 디자인하는 역할\n  Javascript: 사람의 신체에 비유하자면 brain으로서, web site가 동적으로 움직여서 interactivity 하기 위해 필요하다.\n    ❗ 브라우저는 오류가 있어도 오류를 알려주지 않는다.\n 2. HTML  브라우저에게 \u0026rsquo;tag\u0026rsquo;를 사용하여 컨텐츠의 종류를 알려주는 마크업 언어의 종류\n 2.1 HTML의 tag tag란?   \u0026rsquo;tag\u0026rsquo; 에는 아래 코드에서 보이듯이 괄호로 갇혀진 부분이 태그다.\n self-closing tag 와 그렇지 않은 태그 두 종류로 나눠진다. 그렇지 않은 태그는 여는 태그와 닫는 태그로 구성된다. 여는 태그와 닫는 태그 사이에 있는게 contents 내용이며, 태그로 이 컨텐츠의 종류를 결정한다.  # self-closing tag \u0026lt; input /\u0026gt;  # non self-closing tag # 태그 사이에 있는 Home - My website가 content  \u0026lt;title\u0026gt;Home - My website\u0026lt;/title\u0026gt;   tag 작성과 찾는 방법   HTML \u0026rsquo;tag`는 매우 많은 종류가 있기 때문에, 암기하려고 하지않는다. 다만, 태그를 작성하는 방법과 찾는 방법을 알면 된다.\n 태그를 찾는 방법: \u0026lsquo;html tag mdn\u0026rsquo;을 구글링하여 mozilla 에서 알아본다.    또한, 원하는 사이트의 html code 구성을 보고 싶다면 마우스 오른쪽 클릭을 하여 검사 또는 inspection을 클릭하면 확인할 수 있다.\n  HTML tag의 기본 구성   Visual Studio Code로 doc만 입력하면 바로 아래의 코드가 펼쳐진다.\n  html에는 반드시 따라야만 하는 틀이 있다.\n  \u0026lt;!DOCTYPE html\u0026gt;로 html 문서는 시작한다.\n  \u0026lt;html\u0026gt; tag 안에 \u0026lt;head\u0026gt;와 \u0026lt;body\u0026gt;로 크게 나눠진다.\n \u0026lt;head\u0026gt; : 브라우저에게 사이트의 정보를 알려주는 단계로 웹 사이트의 보이지 않는 부분인 환경을 설정한다. \u0026lt;body\u0026gt; : 브라우저 화면 상에 보여질 내용들인, 사용자가 볼 수 있는 content를 보여준다.    \u0026lt;html lang = \u0026quot;ko\u0026quot;\u0026gt;: 웹 사이트에서 사용되는 언어를 이 웹 사이트의 검색 엔진에게 알려주는 속성\n  \u0026lt;meta charset = \u0026quot;UTF-8\u0026quot;\u0026gt;은 문자 인코딩 방식을 브라우저에게 알려준다.\n  \u0026lt;title\u0026gt;은 브라우저의 탭에 뜨는 문구를 브라우저에게 알려준다.\n    \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;ko\u0026#34;\u0026gt;  \u0026lt;head\u0026gt;  \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt;  \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt;  \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt;  \u0026lt;title\u0026gt;Document\u0026lt;/title\u0026gt;  \u0026lt;/head\u0026gt;  \u0026lt;body\u0026gt;   \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; semantic tag와 non-semantic tag   tag의 다른 나눠지는 기준으로 semantic tag와 non-semantic tag가 있다.\n tag 자체 명칭에 의미가 있는 tag를 semantic tag라 하고, tag 자체 명칭에 의미가 없는 tag를 non-semantic tag라 한다.    non-semantic tag의 예로는 \u0026lt;div\u0026gt; \u0026lt;/div\u0026gt; 가 있다. division이란 단어에서 나온 것으로, 박스나 경계선이라 생각하면 된다.\n 기능은 가지고 있지만, 의미론적으로는 아무런 값이 없는 box다.    semantic tag의 예로는 \u0026lt;header\u0026gt; \u0026lt;/header\u0026gt;가 있다. \u0026lt;head\u0026gt; 와는 다른 것이며 \u0026lt;body\u0026gt; \u0026lt;/body\u0026gt;에 포함된다. 이 예시를 읽었을 때 그 의미를 짐작할 수 있기 때문에 semantic tag로 분류된다.\n 코드를 짤 때는 최대한 semantic tag로만 코드를 짜는 거를 추천하는 이유가 코드만 보고도 무엇인지 빠르게 파악 가능하다.    tag의 attribute  각 \u0026rsquo;tag\u0026rsquo;는 attribute(속성)을 가지는데, 태그의 부가적인 정보를 말한다.  attribute를 입력할 때는 '' 이 아닌 \u0026quot;\u0026quot;를 사용해야 한다. attribute에는 아무거나 작성핻 되지만, 각 tag에 정해진 attribute를 작성하지 않으면 브라우저는 인식하지 않는다. 자주 사용되는 tag는 암기하는 것을 추천한다. tag에 사용되는 attribute 중 id는 어느 태그에서든 사용할 수 있다.     3. HTML tag의 다양한 예 h1 ~ h6  \u0026lt;body\u0026gt;의 \u0026lt;h1\u0026gt; 부터 \u0026lt;h6\u0026gt; 로 갈수록 title의 글자 크기가 작아진다. \u0026lt;h7\u0026gt; 부터는 title로 인식하지 않는다.  \u0026lt;body\u0026gt;  \u0026lt;h1\u0026gt;website!\u0026lt;/h1\u0026gt;  \u0026lt;h2\u0026gt;website!\u0026lt;/h1\u0026gt;  \u0026lt;h3\u0026gt;website!\u0026lt;/h3\u0026gt;  \u0026lt;h4\u0026gt;website!\u0026lt;/h4\u0026gt;  \u0026lt;h5\u0026gt;website!\u0026lt;/h5\u0026gt;  \u0026lt;h6\u0026gt;website!\u0026lt;/h6\u0026gt; \u0026lt;body/\u0026gt; \u0026lsquo;id\u0026rsquo; 속성  \u0026lsquo;id\u0026rsquo; 속성은 body 태그 안에 어떤 태그에든지 넣을 수 있는 속성이다. 이 속성은 고유 식별자(unique identifier) 역할을 하기 때문에, element 당 하나의 id만 가지는 것 이 id의 필수적인 규칙이다.  하나의 태그는 하나의 id만 가지면, 다른 태그의 id 값과 동일한 값을 가지면 안된다.   또한, CSS가 이 id 속성을 통해 디자인을 브라우저에게 지시할 수 있다.  \u0026lt;body\u0026gt;  \u0026lt;div\u0026gt;  \u0026lt;label for = \u0026#34;FullName\u0026#34;\u0026gt; site \u0026lt;/label\u0026gt;  \u0026lt;input id = \u0026#34;FullName\u0026#34; requried placeholder= \u0026#34;Full name\u0026#34;/\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;div\u0026gt;  \u0026lt;label for = \u0026#34;first-name\u0026#34;\u0026gt; First Name \u0026lt;/label\u0026gt;  \u0026lt;input id = \u0026#34;first-name\u0026#34; required placeholder = \u0026#34;first name\u0026#34; type = \u0026#34;text\u0026#34;/\u0026gt;  \u0026lt;/div\u0026gt;  \u0026lt;div\u0026gt;  \u0026lt;label for = \u0026#34;password\u0026#34;\u0026gt; Password \u0026lt;/label\u0026gt;  \u0026lt;input id = \u0026#34;password\u0026#34; required placeholder = \u0026#34;Password\u0026#34; type = \u0026#34;password\u0026#34; minlength = \u0026#34;10\u0026#34;/\u0026gt;  \u0026lt;/div\u0026gt; \u0026lt;body\u0026gt;  for의 값과 id의 값을 동일하게 입력하여 연결시킨다. required placeholder: input 할 칸에 뜨는 설명 문자를 받는 속성 text: 입력받을 데이터의 type을 브라우저에게 알려줘서, type에 맞는 input 창을 생성한다.  password type의 경우, text type과 달리 입력한 값이 드러나지 않고 숨겨진다.    a href  링크 첨부하는 태그와 속성  \u0026lt;body\u0026gt;  \u0026lt;a href = \u0026#34;www.google.com\u0026#34;\u0026gt;Go to google.com\u0026lt;/a\u0026gt;  \u0026lt;a href = \u0026#34;www.google.com\u0026#34; target = \u0026#34;_self\u0026#34;\u0026gt;Go to google.com \u0026lt;/a\u0026gt;  \u0026lt;a href = \u0026#34;www.google.com\u0026#34; target = \u0026#34;_blank\u0026#34;\u0026gt;Go to google.com \u0026lt;/a\u0026gt; \u0026lt;/body\u0026gt;  target 속성은 새로운 tab에서 첨부한 링크를 열지, 아니면 tab을 새로 열지 않고 첨부한 링크로 이동할지를 결정하는 속성  _self는 후자이고, _blank는 전자다. target 속성을 사용하지 않으면 기본적으로 _self를 default로 인식한다.    img src  이미지를 첨부하는 태그와 속성  img 라는 태그에 속성 src = 를 입력하여 이미지 주소를 입력한다.    \u0026lt;body\u0026gt;  \u0026lt;img src = \u0026#34;img/id_img.jpg\u0026#34; \u0026lt;/body\u0026gt;  Reference  노마드코더 - 코코아톡 클론 코딩  ","permalink":"http://jeha00.github.io/post/html_css/study01/","summary":"HTML, CSS가 무엇이고, 브라우저에서 무슨 역할을 하는지, html의 tag란 무엇인지, semantic tag과 non-semantic tag란 무엇인지 학습한다. 그리고, tag의 다양한 속성 중 몇 가지를 학습해본다.","title":"[TIL] HTML \u0026 CSS study - HTML이란?"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 그래서 이번 소단원에서는 git blame 명령어를 통해 각 라인의 작성자를 확인하는 법에 대해 알아본다.   git blame 🔅 코드에 대한 책임을 따지는 것을 넘어서 이 코드를 수정해도 되는지, 왜 이렇게 했는지를 묻기 위해서도 필요하다.\n  파일의 부분별로 작성자 확인하기\n git blame (파일명) 파일명을 CLI에 입력할 때는 첫 글자를 입력하고 tab을 누르면 자동완성된다.   $ git blame whoCodedThis.txt  그러면 왼쪽 칼럼 부분에 괄호 치고 작성자가 누군지 알 수 있다. git config user.name 을 바꿔가면서 작성자를 바꿨다. 맨 오른쪽 칼럼 부분은 코드의 각 줄을 의미하는데, 각 줄마다 누가 작성했는지를 알 수 있다.    특정 부분 지정해서 작성자 확인하기\n git blame -L (시작줄) (끝줄, 또는 +줄수) (파일명)  $ git blame -L 10,12 whoCodedThis.txt 65f63a2d (pikachu 2022-01-04 13:31:27 +0900 10) d1ef31c6 (mito 2022-01-04 13:31:45 +0900 11) 나 미친토끼 미토에요. d1ef31c6 (mito 2022-01-04 13:31:45 +0900 12)  # 또는 다음과 같이 입력할 수 있다.   $ git blame -L 10,+3 whoCodedThis.txt 65f63a2d (pikachu 2022-01-04 13:31:27 +0900 10) d1ef31c6 (mito 2022-01-04 13:31:45 +0900 11) 나 미친토끼 미토에요. d1ef31c6 (mito 2022-01-04 13:31:45 +0900 12)    GitLens  git 명령어로 하는 방법보다 권장되는 방법으로, 플러그 인 프로그램인 GitLens를 사용하는 것이다. source tree로도 볼 수 있지만, GitLens를 사용하는 걸 추천한다.   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-03/","summary":"git blame 명령어와 VSC의 extension program인 GitLens를 통해 각 라인의 작성자를 확인하는 법을 알아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git blame \u0026 GitLens"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   Chapter 11에서는 분석하고 디버깅하는 것에 대해 다룬다. 이번 단원에서는 차이를 살펴보는 git diff 명령어에 대해 알아본다.   Git diff  working directory의 변경사항을 확인하는 명령어\n   git diff 명령어를 통해서 현재 파일들의 변경사항, staging area에 올라간 파일들의 변경사항, 브랜치 간의 변경사항, 커밋 간의 변경사항들 여러 관계 사이의 변경사항을 알 수 있다.\n  먼저 실습하기 위한 변경 사항을 임의로 만들어본다.\n$ git diff # leopards.yaml diff --git a/leopards.yaml b/leopards.yaml index 9c8086a..eca1191 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,5 +13,3 @@ members: - Dongho - Drax - Groot - - Onepiece - - No jam Thore  # panthers.yaml diff --git a/panthers.yaml b/panthers.yaml index 8e2ee18..fb9738a 100644 --- a/panthers.yaml +++ b/panthers.yaml @@ -11,3 +11,4 @@ members: - Freddie - Arachi - Hoki + - Harus \\ No newline at end of file  # tigers.yaml diff --git a/tigers.yaml b/tigers.yaml index cd48481..c8ca3e0 100644 --- a/tigers.yaml +++ b/tigers.yaml @@ -11,5 +11,3 @@ members: - George - Tyler - Kim - - Gamora - - Nebula   파일명만 확인:\n 변경사항 있는 파일의 이름들만 확인 git diff --name-only  $ git diff --name-only leopards.yaml panthers.yaml tigers.yaml   스테이지의 확인:\n working directory에 있다가 staging area에 올라간 파일들의 변경사항을 확인하고자 할 때 사용 git diff --staged: git diff --caced도 이와 동일한 명령어  $ git add . $ git diff --staged  # git diff를 한 것과 동일한 결과가 나온다.    커밋간의 차이 확인\n git diff (커밋 1) (커밋 2)  또는 커밋 해시나 HEAD 번호로도 가능하다. 현재 커밋과 비교하려면 이전 커밋만 입력한다.    # 지난 번에 학습한 단축키 설정 명령어로 정한 git log 명령어를 사용한다.  # 그래서 두 개의 커밋을 골라보자.  $ git gg  $ git diff 7a6d996 09994e8  # 또는 HEAD 번호를 사용해보자.  $ git diff HEAD~ HEAD~10   그러면 git diff의 다른 옵션과 같이 사용해보자.\n$ git diff --name-only HEAD~3 HEAD~7 leopards.yaml panthers.yaml pumas.yaml tigers.yaml   브랜치간의 차이 확인\n git diff (브랜치 1) (브랜치 2)  $ git branch -a citrus fruit * main root  $ git diff main root diff --git a/onion b/onion deleted file mode 100644 index e69de29..0000000    Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-02/","summary":"git diff 명령어를 통해서 현재 파일들의 변경사항, staging area에 올라간 파일들의 변경사항, 브랜치 간의 변경사항, 커밋 간의 변경사항들 여러 관계 사이의 변경사항을 알 수 있다.","title":"[TIL] Git study: Lecture Chapter 11 - Git diff"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git log를 옵션들과 함께 사용하여 더 자세히 살펴보겠다.   옵션들을 활용한 다양한 사용법 각 커밋마다의 변경사항 함께 보기  git log -p\n  커밋 해쉬 번호만 보여주는 게 아닌, 각 커밋마다의 변경사항을 함께 보여준다.  $ git log -p commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900   edit members of leopards.yaml  diff --git a/leopards.yaml b/leopards.yaml index 2aaf3d2..ed823d4 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,5 +13,3 @@ members:  - Dongho  - Drax  - Groot - - I\\\u0026#39;m groot - - Guardians of Glaxy  commit 7a6d9965f2f366fb4d10e1739b804572beef0fcf (main2) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:14:35 2022 +0900   edit memebers in leopards.yaml  diff --git a/leopards.yaml b/leopards.yaml index ed823d4..fb150cc 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -1,6 +1,6 @@  team: Leopards  -manager: Peter +manager: Harry Poter^M   coach: Rocket  @@ -13,3 +13,4 @@ members:  - Dongho  - Drax  - Groot + - No jam Thore^M  최근 n개 커밋만 보기  git log -(갯수)\n  최근 커밋을 원하는 갯수만큼 볼 수 있다.  # 이전 커밋 3개만 보고 싶다. $ git log -3 commit 1dccdb61b999634cba358a0a27c5dd4d9fca7a30 (HEAD -\u0026gt; main) Merge: f217dc2 7a6d996 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jul 15 13:50:21 2022 +0900   Merge branch \u0026#39;main2\u0026#39;  commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900   edit memebers in leopards.yaml  commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900   edit members of leopards.yaml  또한 -p와 함께 사용하여 원하는 만큼의 커밋을 보는데, 각 커밋의 변경사항과 함께 볼 수 있다.  $ git log -p -3 commit 1dccdb61b999634cba358a0a27c5dd4d9fca7a30 (HEAD -\u0026gt; main) Merge: f217dc2 7a6d996 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jul 15 13:50:21 2022 +0900   Merge branch \u0026#39;main2\u0026#39;  commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900   edit memebers in leopards.yaml  diff --git a/leopards.yaml b/leopards.yaml index ed823d4..24e6957 100644 --- a/leopards.yaml +++ b/leopards.yaml @@ -13,3 +13,4 @@ members:  - Dongho  - Drax  - Groot + - Onepiece^M  commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900   edit members of leopards.yaml  통계와 함께 보기  git log \u0026ndash;stat\n $ git log --stat commit f217dc2eec6877db8a3e8828ba24e05c05f742f9 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:34 2022 +0900   edit memebers in leopards.yaml   leopards.yaml | 1 +  1 file changed, 1 insertion(+)  commit 51075e540e06075761bd17080ef3a01b79f25056 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Mon Jul 11 18:15:06 2022 +0900   edit members of leopards.yaml   leopards.yaml | 2 --  1 file changed, 2 deletions(-)  한 줄로 보기  git log \u0026ndash;oneline\n  --pretty=oneline --abbrev-commit을 줄인 것  $ git log ---oneline 1dccdb6 (HEAD -\u0026gt; main) Merge branch \u0026#39;main2\u0026#39; f217dc2 edit memebers in leopards.yaml 51075e5 edit members of leopards.yaml 7a6d996 (main2) edit memebers in leopards.yaml 9302244 edit memebers in leopards.yaml ...  변경사항 내 단어 검색  git log -S (검색어)\n  S는 반드시 대문자를 입력해야 한다. George를 검색해본다고 하자.  $ git log -S George commit 679d1f1788575666f8b368c67dfbb14f69c6a637 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:28:44 2022 +0900   add George to tigers  커밋 메시지로 검색  git log \u0026ndash;grep (검색어)\n $ git log --grep Olivia commit 904db06ba9495801734d1fa81580a269e6f37ba6 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Fri Jun 24 13:40:58 2022 +0900   Add Olivia to Leopards  커밋 메시지로 검색하는 것에 대한 그 밖에 옵션들은 기타 옵션 보기를 참고한다.   자주 사용되는 그래프 로그 보기  git log \u0026ndash;all \u0026ndash;decorate \u0026ndash;oneline \u0026ndash;graph\n  위 명령어 사용된 옵션들에 대한 설명은 다음과 같다.  --all: 모든 브랜치 보기 --graph: 그래프 표현 --decorate: 브랜치, 태그 등 모든 레퍼런스 표시  --decorate=no --decorate=short: 기본 --decorate=full      🔅 이 명령어로 그래프를 보는 것보다 소스 트리로 보는 걸 추천한다.\n  단축키를 설정하여 이 명령어를 자주 사용하기도 한다.\n 단축키 설정은 Chapter06을 참고하자.    다음 명령어는 포맷된 로그의 한 종류다.\n log --graph --all --pretty=format:'%C(yellow) %h %C(reset)%C(blue)%ad%C(reset) : %C(white)%s %C(bold green)-- %an%C(reset) %C(bold red)%d%C(reset)' --date=short 여기서 data를 relative로 바꿔보자.    위 명령어를 단축키를 통해 사용하고자 한다면\n  git config --global alias.(단축키) \u0026quot;명령어\u0026quot;\n  위 명령어에 입력할 때, git은 빼고 입력한다.\n  git config --global alias.gg \u0026quot;log --graph --all --pretty=format:'%C(yellow) %h %C(reset)%C(blue)%ad%C(reset) : %C(white)%s %C(bold green)-- %an%C(reset) %C(bold red)%d%C(reset)' --date=short\u0026quot;\n  그리고 나서 git gg를 입력하면 뜬다.\n    ❗ 단축키 설정을 했지만, Expansion of alias failed; not a git command 이와 같은 에러가 발생했다면 git update-git-for-windows를 사용하여 업데이트 후, 다시 해보자.\n Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter11-01/","summary":"git log에 달려있는 여러 옵션들을 사용하여 log를 더 자세히 알아본다.","title":"[TIL] Git study: Lecture Chapter 11 - Git log 자세히 알아보기"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 Gitflow를 사용해서 협업을 위한 브랜치 활용법을 알아본다.   협업을 위한 branch 활용법  체계적으로 협업하기 위한 브랜칭 전략이 gitflow다.  사용되는 브랜치들    브랜치 용도     main 제품 출시/배포   develop 다음 출시/배포를 위한 개발 진행   release 출시/배포 전 테스트 진행(QA)   feature 기능 개발   hotfix 긴급한 버그 수정      main\n 실제로 사용자들에게 최종적으로 출시될 것들로서, tag가 붙여진다.    develop\n main을 만들어내기 위한 개발 작업은 이 브랜치에서 이뤄진다. 여기서 새로운 기능을 추가하거나, 문제들을 해결해가면서 커밋들을 추가해간다.    feature:\n develop 과정에서 굵직한 것들은 이 feature branch에서 만들어진다. 그래서 여러 개의 feature branch가 만들어 질 수 있다. ex) feature - 기능 이름 기능이 완성되면 develop branch를 합쳐진다.    release:\n develop branch에서 개발이 이뤄지다가, 이제 출시를 해도 될 정도로 성능과 버그 등등이 괜찮을 때 해당 브랜치에서 테스트하기 위해 이동된다. 이 브랜치에서 수정되면 develop branch에 합쳐진다. 이 브랜치에서 작업하다가 확실하게 출시해도 괜찮으면 main branch로 옮겨진다.    hotfix:\n main branch로 출시된 제품들 중에서 갑자기 오류가 발생했을 경우, hotfix branch에서 작업한다. 해결되면 다시 main branch를 병합하여 출시한다.     Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 A successful Git branching model  ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-05/","summary":"협업 시 여러 branch를 생성하여 어떻게 활용하는지, 각 branch의 이름은 현업에서 주로 사용되는 이름이 있는지 Gitflow를 사용한 브랜치 활용법에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 10 - Gitflow"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git merge --squash 명령어를 사용해서 다른 가지의 마디들을 묶어서 가져와본다.   다른 가지의 마디들 묶어서 가져오기  git merge \u0026ndash;squash (대상 브랜치): 다른 branch의 구체적인 commit 내역을 기억하고 싶지 않아서 다른 branch의 커밋들을 묶어서 한 커밋으로 가져오는 명령어\n   소단원 2,3과 동일한 branch와 commit을 사용한다.\n  현재 branch는 main이며, root branch에 있는 커밋들을 묶어서 한 커밋으로 가져온다.\n$ git merge --squash root  $ git status On branch main Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  new file: beet  new file: potato  new file: radish  # git commit -m 으로 commit message를 별도로 적어도 되고, 아래와 같이 해도 된다. $ git commit Squashed commit of the following:   git log를 통해서 합쳐진 것을 알 수 있다.\n$ git log commit b2d15aa2b4b9f7b7d63036fce1256274168fb7b7 (HEAD -\u0026gt; main) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jul 13 12:48:30 2022 +0900   Squashed commit of the following:   일반 merge와의 차이  일반 merge와 merge --squash는 실행 후, 코드의 상태는 같지만 내역 면에서 큰 차이가 있는 것이라 이해해자. 일반 merge: A와 B 두 브랜치를 한 곳으로 이어붙인다. merge \u0026ndash;squash: B 브랜치의 마디들을 복사하여, 한 마디로 모아 staged state로 A 브랜치에 붙인다.   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-04/","summary":"git merge \u0026ndash;squash 명령어를 사용해서 다른 브랜치의 여러 커밋들을 rebase와 달리 하나의 커밋으로 묶어서 가져와본다.","title":"[TIL] Git study: Lecture Chapter 10 - git merge --squash"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git rebase --onto 를 사용하여 다른 브랜치에서 파생된 브랜치를 다른 브랜치로 옮겨 붙여본다.   파생된 브랜치 옮겨붙이기  git rebase \u0026ndash;onto (도착 브랜치) (출발 브랜치) (이동할 브랜치): 다른 브랜치에서 파생된 브랜치 옮겨붙이기\n  이전 단원과 동일한 branch와 commit을 사용한다.    fruit branch에서 파생된 citrus branch를 main branch로 옮겨붙이기\n citrus로 fast forward  $ git rebase --onto main fruit citrus   실행한 결과 다음과 같다.\n    그러면 마지막으로 main branch의 HEAD를 옮겨보자.\n# 위 명령어를 실행하면서 branch가ㅏ citrus로 전환됬다. $ git switch main $ git merge citrus $ git branch -d citrus    rebase \u0026ndash;onto 되돌리기   ❗ 되돌리기 위해서는 관련된 브랜치는 삭제되지 않아야 한다.\n 왜냐하면 해당 명령어 이전으로 되돌리기 위해서는 이 명령어로 영향을 받은 모든 브랜치들에서 하나하나 리셋을 진행해주어야 하기 때문이다.    git reflog를 사용해서 내역을 살펴보면 rebase \u0026ndash;onto 명령 시 여러 내역들이 진행된 것을 볼 수 있다.\n$ git reflog c519fac (HEAD -\u0026gt; main) HEAD@{0}: merge citrus: Fast-forward a8bfbbf HEAD@{1}: checkout: moving from citrus to main c519fac (HEAD -\u0026gt; main) HEAD@{2}: rebase (finish): returning to refs/heads/citrus   main branch\n main이 fast-forward 되기 이전 기록으로 git reset --hard를 실행한다.    citrus branch\n  방법 A\n citrus branch는 해당 branch가 옮겨지기 전 마지막 커밋인 commit: Lime 부분을 reflog에서 찾아 그리로 reset --hard한다.    방법 B\n 다시 rebase --onto를 사용해서 citrus의 커밋들을 main으로부터 도로 fruit branch의 orange 부분으로 옮긴다. 이를 위해서 orange commit으로 checkout 후, 새로운 브랜치를 만들고 아래 명령어를 실행한다. git rebase --onto temp main citrus  citrus branch는 main branch에 붙여진 것이므로, 시작 브랜치가 main이다.   citrus의 두 커밋들을 해당 위치로 옮겨붙인 뒤, 새로 만든 브랜치를 삭제한다.       Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-03/","summary":"git rebase \u0026ndash;onto 명령어를 사용하여 다른 브랜치에서 파생된 브랜치를 현재 브랜치로 옮겨서 붙여본다.","title":"[TIL] Git study: Lecture Chapter 10 - git rebase --onto"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git cherry-pick 명령어를 사용하여 다른 브랜치에 있는 원하는 커밋만 따오는 실습을 해본다.   다른 브랜치에서 원하는 커밋만 따오기  git cherry-pick (가져올 commit hash): 다른 브랜치의 원하는 특정 커밋을 복사해서 가져오는 명령어\n  새롭게 branch와 commit을 형성하여 다음과 같은 commit tree를 구성했다.   위 image에서 fruit branch에서 cherry commit을 main branch로 가져오기 위해, 가져올 브랜치의 커밋 해쉬 번호를 가져온다.  # git cherry-pick (가져올 commit hash) $ git cherry-pick cadfd026 [main 53ad573] Cherry  Author: yalco \u0026lt;yalco@kakao.com\u0026gt;  Date: Sat Jan 1 15:33:36 2022 +0900  1 file changed, 0 insertions(+), 0 deletions(-)  create mode 100644 cherry   그러면 파일 목록에 새로운 파일이 추가된 걸 확인할 수 있다.\n  소스 트리에서도 확인해보면 cherry commit을 복사해서 가져왔기 때문에, fruit branch에는 여전히 존재한다.\n   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-02/","summary":"git cherry-pick 명령어를 사용하여 다른 브랜치에 있는 원하는 commit만 따오는 실습을 해본다.","title":"[TIL] Git study: Lecture Chapter 10 - git cherry-pick"},{"content":"0. Introduction   Write a minimal form use generic views: Less code is better     django 공식 문서를 번역하는 작업을 통해 튜토리얼을 진행하여 이해해본다.\n  이번 tutorial을 통해서 기본적인 설문조사 애플리케이션을 만들 수 있다.\n 이 애플리케이션은 다음 2가지로 구성된다.  사람들이 설문조사를 보고 투표할 수 있는 \u0026lsquo;public site\u0026rsquo; 설문조사를 더하고, 수정하고, 삭제하는 \u0026lsquo;admin site\u0026rsquo;       1. Write a minimal form  Par03에서 만들었던 detail template을 업데이트해보자.  업데이트할 detail template에는 HTML form 요소가 포함된다.    \u0026gt; \u0026lt;form action=\u0026#34;{% url \u0026#39;polls:vote\u0026#39; question.id %}\u0026#34; method=\u0026#34;post\u0026#34;\u0026gt; \u0026gt; {% csrf_token %} \u0026gt; \u0026lt;fieldset\u0026gt; \u0026gt; \u0026lt;legend\u0026gt;\u0026lt;h1\u0026gt;{{ question.question_text }}\u0026lt;/h1\u0026gt;\u0026lt;/legend\u0026gt; \u0026gt; {% if error_message %}\u0026lt;p\u0026gt;\u0026lt;strong\u0026gt;{{ error_message }}\u0026lt;/strong\u0026gt;\u0026lt;/p\u0026gt;{% endif %} \u0026gt; {% for choice in question.choice_set.all %} \u0026gt; \u0026lt;input \u0026gt; type=\u0026#34;radio\u0026#34; \u0026gt; name=\u0026#34;choice\u0026#34; \u0026gt; id=\u0026#34;choice{{ forloop.counter }}\u0026#34; \u0026gt; value=\u0026#34;{{ choice.id }}\u0026#34;\u0026gt; \u0026gt; \u0026lt;label for=\u0026#34;choice{{ forloop.counter }}\u0026#34;\u0026gt;{{ choice.choice_text }}\u0026lt;/label\u0026gt; \u0026gt; {% endfor %} \u0026gt; \u0026lt;/fieldset\u0026gt; \u0026gt; \u0026lt;input type=\u0026#34;submit\u0026#34; value=\u0026#34;Vote\u0026#34;\u0026gt; \u0026gt; \u0026lt;/form\u0026gt;   질문을 선택하기 위한 라디오 버튼을 보여준다. 각 라디오 버튼의 값은 question choice의 ID 값이다. 누군가 라디오 버튼의 하나를 클릭하여 이 form을 전송할 때, POST data choice = # 을 보낸다. 여기서 # 은 선택된 ID다. 이것인 HTML 형태의 기본 개념이다.\n  이 form의 action을 {% url 'polls:vote' question.id %} 으로 정하고, method는 post로 정했다. \u0026lsquo;post\u0026rsquo;는 서버 쪽 데이터를 변경하려는 form을 생성하려고 할 때 사용해야 하는 method다. 이는 django에만 해당되는 게 아닌 일반적으로 웹 개발의 좋은 예시에서 찾을 수 있다.\n  method \u0026lsquo;POST\u0026rsquo;를 사용하는 만큼 \u0026lsquo;Cross Site Request Forgeries\u0026rsquo; 에 대해 고려해야 한다.\n CSRF(Cross Site Request Forgeries)란 사용자가 자신의 의지와는 무관하게 다른 사용자가 의도한 행위를 특정 웹사이트에 요청하게 하는 공격으로, 개인정보 유출이 일어날 수 있다.    하지만, django에는 이를 도와주는 보안 시스템이 있는데, {% csrf_token %} template tag를 사용하는 것이다. 내부 URLs를 대상으로 하는 모든 POST method는 이 tag를 사용해야 한다.\n  아래 코드에는 이번 tutorial에서 아직 다루지 않는 것들을 포함시킨다.\n# 경로: polls/views.py  \u0026gt; def vote(request, question_id): \u0026gt; question = get_object_or_404(Question, pk = question_id) \u0026gt; try: \u0026gt; selected_choice = question.choice_set.get(pk = request.POST[\u0026#39;choice\u0026#39;]) \u0026gt; except (KeyError, Choice.DoesNotExist): \u0026gt; return render(request, \u0026#39;polls/detail.html\u0026#39;, {\u0026#39;question\u0026#39;: question, \u0026#39;error_message\u0026#39;: \u0026#34;You didn\u0026#39;t select a choice.\u0026#34;, }) \u0026gt; else: \u0026gt; selected_choice.votes += 1 \u0026gt; selected_choice.save() \u0026gt; return HttpResponseRedirect(reverse(\u0026#39;polls:results\u0026#39;, args = (question.id, )))  request.POST: 이 request.POST의 값은 언제나 string이다. request.post['choice'] 는 선택된 choice의 ID 값을 문자열로서 반환한다. 하지만 선택된 choice가 존재하지 않는다면 KeyError를 발생시킨다. 선택된 choice의 count가 증가된 후, 일반적인 HttpResponse가 아닌 HttpResponseRedirect를 반환한다. HttpResponseRedirect 는 user가 원래 정한 url이 아닌 다른 url로 가도록 끌어준다. POST data를 성공적으로 처리한 후, 항상 HttpResponseRedirect 를 반환해야 한다. HttpResponseRedirect의 인자로 reverse를 사용하고 있는데 이 함수는 view function에서 hardcoding을 방지해준다.    이 vote view 코드의 경우 **race condition**에 대한 해결책이 나와있지 않는다. 둘 이상의 유저가 동시에 같은 quesition을 클릭했을 경우, +2가 되어야 하지만 +1이 증가될 수도 있다. 이 문제를 해결하는 걸 학습하고 싶으면 Avoiding race conditions using F() 를 읽어보자.\n  question에 누군가 vote를 한 후, vote() view가 결과 page로 보여지도록 설계한다.\ndef results(request, question_id):  question_id = get_object_or_404(Question, pk = question_id)  return render(request, \u0026#39;polls/resul   polls/templates/polls/results.html 를 만들어보자.\n\u0026lt;h1\u0026gt;{{ question.question_text }}\u0026lt;/h1\u0026gt; \u0026lt;ul\u0026gt; {% for choice in question.choice_set.all %} \u0026lt;li\u0026gt;{{ choice.choice_text }} -- {{ choice.votes }} vote{{ choice.votes|pluralize }}\u0026lt;/li\u0026gt; {% endfor %} \u0026lt;/ul\u0026gt; \u0026lt;a href=\u0026#34;{% url \u0026#39;polls:detail\u0026#39; question.id %}\u0026#34;\u0026gt;Vote again?\u0026lt;/a\u0026gt;    2. Use generic views: Less code is better   위 코드들을 통해서 기본적인 웹 배포의 흔한 경우를 알 수 있다.\n URL로 넘긴 매개변수에 따라 DB로부터 데이터를 얻고, template을 로딩하고, 구현된 template을 반환하는 흐름을 말한다.    그래서 django에서는 이에 대한 짧고 효과적인 방법인 generic views 를 제공한다.\n  그러면 polls app을 generic view로 전환하기 위해 몇 가진 단계를 거쳐보자.\n URLconf를 전환하기 -\u0026gt; 오래되고 불필요한 view를 제거하기 -\u0026gt; Django의 generic views를 기반으로한 새로운 views를 도입하기  여태 generic view를 사용하지 않은 이유는 django의 핵심 개념에 집중하기 위해서다.      2.1 Amend URLconf  polls/urls.py의 urlpatterns에서 두 번째, 세 번째 url의 question_id를 pk로 바꿨다.  \u0026gt; app_name = \u0026#39;polls\u0026#39; \u0026gt; urlpatterns = [ \u0026gt; path(\u0026#39;\u0026#39;, views.indexView.as_view(), name = \u0026#39;index\u0026#39;), \u0026gt; path(\u0026#39;\u0026lt;int:pk\u0026gt;/\u0026#39;, views.DetailView.as_view(), name = \u0026#39;detail\u0026#39;), \u0026gt; path(\u0026#39;\u0026lt;int:pk\u0026gt;/results/\u0026#39;, views.ResultsView.as_view(), name = \u0026#39;results\u0026#39;), \u0026gt; path(\u0026#39;\u0026lt;int:question_id\u0026gt;/vote/\u0026#39;, views.vote, name = \u0026#39;vote\u0026#39;), \u0026gt; ] 2.2 Amend views  기존에 만들었던 index, detail, results 를 generic view로 대체할 것이다.  ## 경로: polls/views.py # def index -\u0026gt; class IndexView로 대체  \u0026gt; from django.views import generic  \u0026gt; class IndexView(generic.ListView): \u0026gt; template_name = \u0026#39;polls/index.html\u0026#39; \u0026gt; context_object_name = \u0026#39;latest_question_list\u0026#39;  \u0026gt; def get_queryset(self): \u0026gt; \u0026#34;\u0026#34;\u0026#34;Return the last five published questions\u0026#34;\u0026#34;\u0026#34; \u0026gt; return Question.objects.order_by(\u0026#39;-pub_date\u0026#39;)[:5]  ## 경로: polls/views.py # def detail -\u0026gt; class DetailView로 대체  \u0026gt; class DetailView(generic.DetailView):  # 밑에 model이 오타라든가 생성되지 않은 model을 할당하지 않으면 오류가 난다.  \u0026gt; model = Question \u0026gt; template_name = \u0026#39;polls/detail.html\u0026#39;   ## 경로: polls/views.py # def results -\u0026gt; class ResultsView로 대체  \u0026gt; class ResultsView(generic.DetailView): \u0026gt; model = Question \u0026gt; template_name = \u0026#39;polls/results.html\u0026#39;  두 가지의 generic view: ListView, DetailView 를 사용했다.  각 generic view는 어떤 model 위에 작동하는지 알아야 한다. 왜냐하면 model 속성을 사용하여 제공되기 때문이다. 각 generic view는 \u0026lt;app name\u0026gt;/\u0026lt;model name\u0026gt;_detail.html 명칭의 템플릿을 사용하며, template_name을 사용하는 이유는 자동 생성되는 기본 템플릿 말고 이 이름을 가진 템플릿을 사용하라고 django에게 말해주는 것이다.     Reference  Django at a glance  ","permalink":"http://jeha00.github.io/post/django/doc_tutorial_04/","summary":"0. Introduction   Write a minimal form use generic views: Less code is better     django 공식 문서를 번역하는 작업을 통해 튜토리얼을 진행하여 이해해본다.\n  이번 tutorial을 통해서 기본적인 설문조사 애플리케이션을 만들 수 있다.\n 이 애플리케이션은 다음 2가지로 구성된다.  사람들이 설문조사를 보고 투표할 수 있는 \u0026lsquo;public site\u0026rsquo; 설문조사를 더하고, 수정하고, 삭제하는 \u0026lsquo;admin site\u0026rsquo;       1. Write a minimal form  Par03에서 만들었던 detail template을 업데이트해보자.","title":"Django study: Document tutorial Part 4 따라해보기"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git의 merge 원리인 Fast-forward와 3-way merge에 대해 알아본다.   Fastforward vs 3-way merge  Git에서 merge가 이뤄지는 두가지 방식인 Fast forward 와 3-way merge를 비교해보자.  Fast forward(빨리 감기)  두 브랜치가 공통 커밋을 조상으로 가지고 있는데, 한 쪽 브랜치에만 이후의 커밋이 있을 때, 병합하기 위한 다른 커밋을 만들지 않고, HEAD만 이동하여 병합한 방식\n  아래 이미지처럼 A branch에서 B branch가 분기되었다. B branch의 최신 버전에는 A branch의 최신 버전을 가지고 포함하고 있다.   이런 상황에서 Fast forward는 A branch의 HEAD를 단지 아래처럼 B branch의 최근 commit으로 옮긴 후, B branch를 제거하는 방법이다.  ❗ 단점: 작업을 하고나서 어떤 브랜치를 사용했고, 언제 병합했는지 기록에 남지 않는다.\n  그러면 fast-forwad 방식으로 merge 작업을 해보자.\n\u0026gt; $ git branch another-branch \u0026gt; $ git switch another-branch  # leopards.yaml의 memeber에 하나를 추가한다.  \u0026gt; $ git commit -am\u0026#39;Add memebers in Leopards.yaml\u0026#39;  # leopards.yaml의 memeber에 또 하나를 추가한다.  \u0026gt; $ git commit -am\u0026#39;Add memebers in Leopards.yaml\u0026#39;  \u0026gt; $ git switch main \u0026gt; $ git merge another-branch Updating 3d75f7f..09994e8 Fast-forward leopards.yaml | 2 ++ 1 file changed, 2 insertions(+) (base)  # 그리고 another-branch를 제거한다. \u0026gt; $ git branch -d another-branch   위 코드를 보면 Fast-forward 단어를 확인할 수 있다.\n  만약 이 방식으로 하지 않고, 병합 커밋 을 만들어 merge하려면 아래 명령어를 사용한다.\n git merge --no-ff (병합할 branch명)    3-way merge  이 방식은 Fast-forward와 달리 기록이 남는 방법으로, 한 branch에서 두 branch로 분기되고, 분기된 후 각 branch에서 추가적인 commit이 발생한 상황에서 merge를 할 때의 원리를 말한다.\n  아래 총 3 군데 를 비교하여 어느 변화를 받아들일지 또한 어느 부분을 충돌로 인식하여 사용자에게 맡겨야 하는지를 결정한는 걸 3-way merge 라 한다.  아래 이미지 같은 상황에서 분기가 시작된 부분을 기준으로 A branch의 최근 commit 부분 B branch의 최근 commit 부분     그래서 새로운 merge commit이 생성된다.    git merge --no-ff (병합할 branch명) 를 사용한다.\n ff는 fastforward를 의미한다.  $ git merge --no-ff main2 Auto-merging leopards.yaml CONFLICT (content): Merge conflict in leopards.yaml Automatic merge failed; fix conflicts and then commit the result.    Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 누구나 쉽게 이해할 수 있는 Git 입문 - merge  ","permalink":"http://jeha00.github.io/post/git/lec_chapter10-01/","summary":"git의 merge 원리인 Fast-forward와 3-way merge에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 10 - Fast forwad vs 3-way merge"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 reset으로 사라진 커밋을 복구할 수 있는 reflog 명령어를 알아본다.   git reflog  프로젝트가 위치한 commit이 바뀔 때마다 기록되는 내역을 보여주고, 이를 사용하여 reset 하기 이전 시점으로 프로젝트를 복구할 수 있다. 즉, 내가 사용한 Git 작업을 기준으로 과거내역을 살펴보고 원하는 시점으로 프로젝트를 되돌릴 수 있다.\n  현재 기준 15번째 전 commit으로 reset 해본 후, git reflog를 입력해보면 여태 입력했던 명령어들과 각 명령어에 해당되는 commit 번호를 확인할 수 있다.  $ git reset --hard HEAD~15 $ git reflog ed807a6 (HEAD -\u0026gt; main) HEAD@{0}: reset: moving to HEAD ed807a6 (HEAD -\u0026gt; main) HEAD@{1}: reset: moving to HEAD~15 c99c341 HEAD@{2}: reset: moving to HEAD~15 3d75f7f (origin/main) HEAD@{3}: merge remote-branch: Fast-forward 1b2bbcb (tag: v1.0.5) HEAD@{4}: checkout: moving from remote-branch to main 3d75f7f (origin/main) HEAD@{5}: checkout: moving from main to remote-branch 1b2bbcb (tag: v1.0.5) HEAD@{6}: checkout: moving from remote-branch to main 3d75f7f (origin/main) HEAD@{7}: checkout: moving from main to remote-branch 1b2bbcb (tag: v1.0.5) HEAD@{8}: pull origin main: Fast-forward ...  그러면 제일 최근 단계로 돌아가기 위해서는 commit 해쉬번호 를 복사한 후, git reset --hard \u0026lt;복사한 commit 해쉬번호\u0026gt; 를 입력한다.  가장 최근 상태의 커밋 번호가 3d75f7f 이므로 git reset --hard 3d75f7f을 입력하면 원 상태로 돌아온다.     Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-03/","summary":"git reset 으로 사라진 커밋을 복구하기 위해서 git reflog 명령어를 통해 더 자세한 commit 번호를 확인 후, git reset \u0026ndash;hard 명령어를 통해서 사라진 커밋을 복구해본다.","title":"[TIL] Git study: Lecture Chapter 08 - git reflog"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 특정 파일을 지정된 상태로 복구하는데 사용하는 git restore에 대해 알아본다.   git restore  특정 파일을 지정된 상태로 복구하는 것\n   git checkout에서 git switch와 git restore로 나눠졌다.\n  파일 여러 개를 수정한 후, 명렁어 사용해보기\n  git restore (파일명)\n working directory의 특정 파일을 복구한다. 또는 파일명 자리에 .을 입력하면 모든 파일이 복구된다.  # panthers.yaml에서 members를 수정한다.  # 수정하기 전 상태 \u0026gt; members: \u0026gt; - Violet \u0026gt; - Stella \u0026gt; - Anthony \u0026gt; - Freddie \u0026gt; - Arachi  # 수정 후 상태 \u0026gt; members: \u0026gt; - Violet \u0026gt; - Stella \u0026gt; - Anthony \u0026gt; - Freddie \u0026gt; - Hoki # 변경된 부분 \u0026gt; - change # 변경된 부분  # git 명령어 실행 \u0026gt; git restore panthers.yaml  # 수정하기 전 상태로 돌아간 걸 알 수 있다.  그러면 panthers.yaml 이외에도 pumas.yaml과 leopards.yaml을 마음대로 수정해본 후, git restore .을 입력하면 이 두 가지 파일 한 번에 수정 전 상태로 돌아가는 걸 확인할 수 있다.      변경 상태를 스테이지에서 워킹 디렉토리로 돌려놓기\n  이번에는 위에 3가지 파일 모두 변경 후 상태로 다시 만든 후, git add .으로 staging area에 올려보자. 그리고 git status로 확인해보자.\n$ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;.  Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  modified: leopards.yaml  modified: panthers.yaml  modified: pumas.yaml   git restore --stage (파일명)\n$ git restore --stage leopards.yaml $ git status  $ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;.  Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  modified: panthers.yaml  modified: pumas.yaml  Changes not staged for commit: (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)  modified: leopards.yaml     파일을 특정 커밋의 상태로 되돌리기\n  git restore --source=(head 또는 commit hash) 파일명\n 첫 번째 commit으로 돌아가려는 상황이라고 가정하자. 그러면 첫 번재 commit의 해쉬번호를 복사하자.  \u0026gt; $ git restore --source=ed807a60e49db810008b8fcb5fd4deddf4f200ec leopards.yaml  # 위 커밋 시점을 기준으로 현재 working directory에 있는 것과 다른 부분들은 수정된 부분으로 인식된다. \u0026gt; $ git status On branch main Your branch is up to date with \u0026#39;origin/main\u0026#39;.  Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  modified: panthers.yaml  modified: pumas.yaml  Changes not staged for commit: (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed) (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)  deleted: leopards.yaml     마지막으로 git restore .으로 되돌리자.\n   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-02/","summary":"git restore 명령어를 통해서 첫 번째, 특정 파일을 지정된 상태로 복구해보는 것과 두 번째, 변경 상태를 stage area에서 working directory로 돌려보는 것을 해본다.","title":"[TIL] Git study: Lecture Chapter 08 - git restore"},{"content":"0. Introduction   django 공식 문서를 번역하는 작업을 통해 튜토리얼을 진행하여 이해해본다.\n  이번 tutorial을 통해서 기본적인 설문조사 애플리케이션을 만들 수 있다.\n 이 애플리케이션은 다음 2가지로 구성된다.  사람들이 설문조사를 보고 투표할 수 있는 \u0026lsquo;public site\u0026rsquo; 설문조사를 더하고, 수정하고, 삭제하는 \u0026lsquo;admin site\u0026rsquo;      이번 tutorial에서는 database를 설치하고, 첫 번째 model을 만들고, 장고가 자동적으로 생성되는 \u0026lsquo;admin site\u0026rsquo;에 대해 quick introduction을 얻는다.\n   1. Database setup   mysite/setting.py 를 열어보자. 이는 Django settings 내용이 있는 Python module이다.\n  기본적으로 SQLite를 사용하는데, SQLite는 파이썬에 포함되어 있기 때문에, 다른 db를 설치할 필요는 없다.\n  하지만, 또 다른 database를 사용하고자 한다면 mysite/setting.py의 DATABASE 변수에서 key가 'default'인 dictionary value에 있는 django.db.backends.\u0026lt;사용하려는 DB\u0026gt; 로 수정한다. 그리고, sqlite 이외의 DB를 사용하고자 한다면 USER, PASSWORD, HOST 같이 세팅을 추가해야 한다.\n mysite/settings.py 에서 제공되는 db user는 db를 생성할 권리를 가지고 있고, test database를 자동적으로 생성할 수 있다.      INSTALLED_APPS 에는 모든 Django applications들의 이름을 가지고 있다. 이 애플리케이션들로 다양한 프로젝트에서 사용될 수 있다. 아래에 있는 application 들은 기본적으로 포함되어 있다.\n django.contrib.admin: admin site django.contrib.auth: 권한 부여 시스템 django.contrib.contenttypes: content type을 위한 framework django.contrib.sessions: session framework django.contrib.messages: messaging framework django.contrib.staticfiles: static 파일들을 관리하기 위한 framework    위 application들은 최소 1개 이상의 database를 사용하기 때문에, db 안에 table을 더 생성할 필요가 있으니 아래 명령어를 실행해보자.\n  $ python manage.py migrate  migrate는 mysite/settings 안에 db settings에 따라 필요한 db table을 생성한다.   2. Creating models  한 개의 model은 data에 대한 정보의 단 하나의 확정적인 출처다. 이 model에는 저장된 데이터의 필수적인 field와 행동들을 포함한다. Django는 DRY(Don\u0026rsquo;t Repeat Yourself) 법칙을 따르기 때문에, Django의 목표는 데이터 모델을 한 장소에 저장하고, 이 한 장소로부터 자동적으로 많은 것들을 시작되도록 하는 게 목표다.\n   poll app에서는 2개의 model을 만들 것이다. Question 과 Choice 다.\n 전자는 question과 public data를 가진다. 후자는 2개의 필드를 가지는데, choice_text 와 votes 다. 후자는 전자와 연관되어 있다.    이 개념들은 Python classes 에 의해서 나타낸다.\n  그러면 polls/models.py file을 아래와 같이 수정해보자.\n  \u0026gt; from django.db import models  # model: Question \u0026gt; class Question(models.Model): \u0026gt; question_text = models.CharField(max_length = 200) \u0026gt; pub_data = models.DataTimeField(\u0026#39;data published\u0026#39;)  # model: Choice \u0026gt; class Choice(models.Model): \u0026gt; question = models.foreignKey(Question, on_delete = models.CASCADE) \u0026gt; choice_text = models.CharField(max_length = 200) \u0026gt; votes = models.integerField(default = 0)   각 model은 클래스로 구현된다.\n  각 클래스는 django.db.models.Model의 서브클래스다.\n  각 model은 그래서 클래스 변수를 가지고 있고, 각 클래스 변수는 db에서 db field로 표현된다.\n    Field class\n  question class 변수를 제외한 클래스 변수들은 Field 클래스의 인스턴스로서, CharField는 문자열 data type을, DataTimeField는 datetime에 대한 field다. 즉, 이 2개의 field는 django에게 각 filed가 보유하고 있는 데이터 타입이 무엇인지를 알려준다.\n  또한, 각 Field의 인스턴스인 클래스 변수의 이름은 databse의 field의 이름이며, 파이썬 코드 안에서 이 값을 사용할 것이고, db에서는 이 이름들을 column name으로 사용할 것이다.\n  CharField class: max_length 값을 요구한다. 이는 db schema에서뿐만 아니라, validation(확인, 검증)에서도 사용한다.\n  또한 Choice.votes 처럼 Field class는 다양한 값을 인자로 받는다.\n  ForeignKey (외래키)를 사용하여 관계를 정의할 수 있다. 각 Choice class는 Question class 와 관련 있다. django는 모든 DB 관계들을 지원한다.\n     3. Activating models  Django apps은 \u0026lsquo;pluggable\u0026rsquo; 하다. 이 말의 의미는 django app은 하나의 app으로 plug 처럼 다양하나 프로젝트에 사용될 수 있다는 의미로서, 하나의 프로젝트에 묶여있지 않다는 말이다.\n   위 코드는 django에게 많은 정보를 제공한다.\n 이 앱을 위한 db schema를 생산하라. 객체 Question과 Choice에 접근하기 위한 파이썬 코드로 된 API를 생산하라.    이를 위해서 첫 번째, polls app을 설치해야 한다.\n  INSTALLED_APPS setting에 poll app의 class에 대한 참조를 추가해야 한다.\n  그 참조는 polls/apps.py에 있는 class PollsConfig를 dot notation으로 입력한다.\nINSTALLED_APPS = [ \u0026#39;polls.apps.PollsConfig\u0026#39;, \u0026#39;django.contrib.admin\u0026#39;, \u0026#39;django.contrib.auth\u0026#39;, \u0026#39;django.contrib.contenttypes\u0026#39;, \u0026#39;django.contrib.sessions\u0026#39;, \u0026#39;django.contrib.messages\u0026#39;, \u0026#39;django.contrib.staticfiles\u0026#39;, ]     다음으로 python manage.py makemigrations polls를 실행한다.\n$ python manage.py makemigrations polls Migrations for \u0026#39;polls\u0026#39;:  polls\\migrations\\0001_initial.py  - Create model Question  - Create model choice  makemigrations를 실행하면 model에 변화를 줬으니 migration 으로서 저장하겠다는 의미다.    migrations 는 django가 model의 변화를 저장하는 방법으로, database에 model table을 생성하는 방법이다.\n  migration 한 것을 보고 싶다면 polls/migrations/0001_inital.py 에서 읽을 수 있다.\n  migration이 사용하는 SQL이 무엇인지를 보고 싶다면 python manage.py sqlmigrate polls 0001을 입력하자.\n$ python manage.py sqlmigrate polls 0001 BEGIN; -- -- Create model Question -- CREATE TABLE \u0026#34;polls_question\u0026#34; (\u0026#34;id\u0026#34; integer NOT NULL PRIMARY KEY AUTOINCREMENT, \u0026#34;question_text\u0026#34; varchar(200) NOT NULL, \u0026#34;pub_date\u0026#34; datetime NOT NULL); -- -- Create model Choice -- CREATE TABLE \u0026#34;polls_choice\u0026#34; (\u0026#34;id\u0026#34; integer NOT NULL PRIMARY KEY AUTOINCREMENT, \u0026#34;choice_text\u0026#34; varchar(200) NOT NULL, \u0026#34;votes\u0026#34; integer NOT NULL, \u0026#34;question_id\u0026#34; bigint NOT NULL REFERENCES \u0026#34;polls_question\u0026#34; (\u0026#34;id\u0026#34;) DEFERRABLE INITIALLY DEFERRED); CREATE INDEX \u0026#34;polls_choice_question_id_c5b4b260\u0026#34; ON \u0026#34;polls_choice\u0026#34; (\u0026#34;question_id\u0026#34;); COMMIT;     그러면 migrations을 실행하여 생성되는 table에 대해 알아보자.\n table name은 polls와 model name의 소문자 이름 question, choice를 조합하여 자동적으로 생성된다. Primary key는 자동적으로 더해진다. foreign key field name에는 _id가 더해진다.    sqlmigrate 명령어는 실제로 migrate를 하는 게 아닌, 단지 django가 생각하기에 요구되는 SQL 문이 무엇인지 볼 수 있도록 화면에 출력하는 용도다. 그래서 django가 무엇을 할 것인지 확인하고 싶으면 이 명령어를 사용한다.\n   4. Playing with the API   python manage.py shell 입력\n  from polls.models import Choice, Question 입력\n  Question.objects.all() : system에 아직 question이 없기 때문에, 새로운 question을 생성한다.\n \u0026lt;QuerySet []\u0026gt; 생성    # 내가 작성한 model classes를 import \u0026gt; from poll.models import Choice, Question  # 시스템에는 아직 question이 존재하지 않는다. \u0026gt; Question.objects.all()  \u0026lt;QuerySet []\u0026gt;  # 새로운 Question을 생성한다.  \u0026gt; from django.utils import timezone \u0026gt; q = Question(question_text = \u0026#34;What\u0026#39;s new?\u0026#34;, pub_date = timezone.now())  # 객체 q를 db에 저장한다. \u0026gt; q.save()  # 저장해서 q는 ID를 가진다. \u0026gt; q.id 1  # 파이썬 속성들을 통해서 model field 값에 접근한다. \u0026gt; q.question_text \u0026#34;What\u0026#39;s new?\u0026#34;  \u0026gt; q.pub_date  datetime.datetime(2022, 7, 5, 2, 54, 11, 538368, tzinfo=datetime.timezone.utc)  # 속성 값을 변경한다. \u0026gt; q.question_text = \u0026#34;What\u0026#39;s up?\u0026#34; \u0026gt; q.save()  # object.all() 은 db에 있는 모든 question 을 보여준다. \u0026gt; Question.objects.all() \u0026lt;QuerySet [\u0026lt;Question: Question object (1)\u0026gt;]\u0026gt;  그런데 \u0026lt;QuerySet [\u0026lt;Question: Question object (1)\u0026gt;]\u0026gt;은 객체의 정보가 잘 드러나지 않는다. 그래서 magic method __str__를 model class에 추가하자.  # polls/models.py \u0026gt; class Question(models.Model):   ... \u0026gt; def __str__(self) -\u0026gt;str: \u0026gt; return self.question_text   \u0026gt; class Choice(models.Model):   ... \u0026gt; def __str__(self) -\u0026gt;str: \u0026gt; return self.choice_text  또한 class Question에서 변수 pub_date를 알아보기 쉽게 바꿔보자.  # polls/models.py  \u0026gt; import datetime  \u0026gt; from django.db import models \u0026gt; from django.utils import timezone  \u0026gt; class Question(models.Model):  #... \u0026gt; def was_publiced_recently(self): \u0026gt; return self.pub_date \u0026gt;= timezone.now() - datetime.timedelta(days = 1)  그러면 어떻게 변했을지 shell을 다시 열어서 실행해보자.  \u0026gt; from polls.model import Choice, Question  \u0026gt; Question.object.all() \u0026lt;QuerySet [\u0026lt;Question: What\u0026#39;s up?\u0026gt;]\u0026gt;  \u0026gt; q = Question.objects.get(id = 1) \u0026gt; q.was_publisehd_recently() True  \u0026gt; q.choice_set.create(choice_text = \u0026#39;Not much\u0026#39;, votes = 0) \u0026lt;Choice : Not much\u0026gt;  \u0026gt; q.choice_set.objects.all() \u0026lt;QuerySet [\u0026lt;Choice: Not much\u0026gt;]\u0026gt;  \u0026gt; q.choice_set.count() 1  5. Introducing the Django Admin admin user 만들기  python manage.py createsuperuser 를 실행하여 뜨는 입력란에 정보를 다 입력하는데, 이 정보들은 admin user의 ID와 Password가 된다.  배포 서버 실행하기  python manage.py runserver  local server 주소는 http://127.0.0.1:8000/ 이지만, admin은 http://127.0.0.1:8000/admin/ 다.    Question 등록하기  admin index page에는 poll app이 보이지 않아서 아래 명령어를 입력해줘야 한다.  admin.site.register(Question)     Reference  Django at a glance  ","permalink":"http://jeha00.github.io/post/django/doc_tutorial_02/","summary":"class를 사용하여 model을 만들면서 Field를 적용해본다. application을 활성화하기 위해 settings.py에 INSTALLED_APPS 에 등록한다. 그리고, migration file을 만든 후, DB에 적용해본다.","title":"Django study: Document tutorial Part 2 따라해보기"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 을 통해서 공부한 내용입니다.   이번 단원에서는 git에 추적되지 않는 파일들 즉, 관리되지 않는 파일들을 삭제하는 git clean에 대해 알아본다.   git clean option  아래 옵션들을 조합하여 사용하자.     옵션 설명     -n 삭제될 파일들 보여주기   -i interactive mode 시작   -d 폴더 포함   -f 강제로 바로 지워버리기   -x .gitignore에 등록된 파일들도 삭제      git clean -x의 경우, git clean은 기본적으로 .gitignore에 등록된 파일은 삭제하지 않기 때문에 존재하는 명령어다.\n  interactive mode는 관리하지 않은 파일들에 대해 하나하나 체크하고 싶을 때 사용하는 모드다.\n  git clean -x는 함부로 사용하지 않는다.\n  실습 상황 구현해보기  아래 3개의 파일을 생성하자.  toClean1.txt toClean2.txt dir/toClean3.txt    \u0026gt; $ git clean -n Would remove toClean1.txt Would remove toClean2.txt   \u0026gt; $ git clean -dn \u0026gt; $ git clean -nd Would remove dir/ Would remove toClean1.txt Would remove toClean2.txt  # 폴더를 포함시켜서 interactive mode를 시작한다. \u0026gt; $ git clean -id \u0026gt; $ git clean -di Would remove the following items:  dir/ toClean1.txt toClean2.txt *** Commands ***  1: clean 2: filter by pattern 3: select by numbers  4: ask each 5: quit 6: help # select by numbers mode를 선택한다. What now\u0026gt; 3  # 어떤 것을 선택할지 선택하세요.  1: dir/ 2: toClean1.txt 3: toClean2.txt Select items to delete\u0026gt;\u0026gt; 1, 3  # * 으로 선택된 파일들을 확인할 수 있다. * 1: dir/ 2: toClean1.txt * 3: toClean2.txt Select items to delete\u0026gt;\u0026gt; Would remove the following items:  dir/ toClean2.txt  *** Commands ***  1: clean 2: filter by pattern 3: select by numbers  4: ask each 5: quit 6: help  # 삭제될 것으로 선택된 파일들에 대해 각각 물어봐달라 What now\u0026gt; 4 Remove dir/ [y/N]? y Remove toClean2.txt [y/N]? N Removing dir/  # 결국 \u0026#39;dir/\u0026#39; 만 삭제된 걸 알 수 있다.   그런데, 각 파일이 어떻든 상관 없이 폴더까지 포함하여 삭제하고 싶다면 아래 명령어를 사용한다.\n$ git clean -fd Removing toClean1.txt Removing toClean2.txt Removing /dir    Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  ","permalink":"http://jeha00.github.io/post/git/lec_chapter08-01/","summary":"이번 단원에서는 git에 추적되지 않는 즉, 관리되지 않은 파일들을 삭제하는 \u0026lsquo;git clean\u0026rsquo;에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 08 - git clean"},{"content":"0. Introduction   django 공식 문서를 번역하는 작업을 통해 튜토리얼을 진행하여 이해해본다.\n  이번 tutorial을 통해서 기본적인 설문조사 애플리케이션을 만들 수 있다.\n 이 애플리케이션은 다음 2가지로 구성된다.  사람들이 설문조사를 보고 투표할 수 있는 \u0026lsquo;public site\u0026rsquo; 설문조사를 더하고, 수정하고, 삭제하는 \u0026lsquo;admin site\u0026rsquo;       1. Creating a project Django가 설치되어 있어야 하며, 해당 튜토리얼은 Django 4.0 과 Python 3.8 이후로 진행된다.\nDjango가 설치되어 있다면 버전을 확인할 수 있다.\npython -m django --version django가 설치되었다면 새로운 하나의 Django project를 세우기 위한 코드를 자동 생성할 필요가 있다.\n- 이 코드는 Django의 인스턴스에 대한 세팅들, DB 배치, 애플리케이션의 구체적인 설정들까지 포함한다.  코드를 저장하기 원하는 directory로 이동하여 아래 명령어를 입력한다.\n# django-admin startproject \u0026lt;project명\u0026gt;  django-admin startproject mysite 이 명령어로 생성된 파일 구성은 다음과 같다.\n\u0026gt; mysite/ \u0026gt; manage.py \u0026gt; mysite/ \u0026gt; __init__.py \u0026gt; settings.py \u0026gt; urls.py \u0026gt; asgi.py \u0026gt; wsgi.py   mysite/: 여기서 외곽 root directory인 mysite는 프로젝트의 컨테이너인데, 이 컨테이너의 이름은 장고에서 중요하지 않으므로 원하는 방식대로 이름을 바꿔도 된다.\n  manage.py: 다양한 방식으로 생성된 이 django 프로젝트와 상호작용할 수 있도록 하는 커맨드라인 유틸리티다.\n django-admin and manage.py. 에서 이 파일에 대한 모든 세부사항들을 읽을 수 있다.    /mysite: 내부 mysite는 생성된 프로젝트의 실제 파이썬 패키지다. 그래서 이 패키지 name을 사용하여 import하므로 수정하면 안된다.\n  mysite/__init__.py: Python에게 이 directory는 Python package라고 말해주는 file이다.\n __init__.py 가 존재하는 이유    mysite/settings.py: 생성된 django project에 대한 settings와 configuration을 의미한다.\n Django settings가 이 settings 파일이 어떻게 작동되는지 설명되어 있다.    mysite/urls.py: 생성된 프로젝트의 URL declarations로서, django에 의해 생성된 사이트의 콘텐츠 표이다.\n URL dispatcher에서 URLs에 대해 더 읽을 수 있다.    mysite/asgi.py 와 mysite/wsgi.py: How to deploy with ASGI 와 How to deploy with WSGI를 나중에 참고해보자.\n   2. The development server django 프로젝트가 작동하는지 보이기 위해 외부 mysite directory로 이동하여 아래 명령어를 입력한다.\npython manage.py runserver 그러면 아래와 같은 command line이 뜬다.\nPerforming system checks...  System check identified no issues (0 silenced).  You have unapplied migrations; your app may not work properly until they are applied. Run \u0026#39;python manage.py migrate\u0026#39; to apply them.  July 02, 2022 - 15:50:53 Django version 4.0, using settings \u0026#39;mysite.settings\u0026#39; Starting development server at http://127.0.0.1:8000/ Quit the server with CONTROL-C. ❗ 기본적으로 runserver 명령어는 port 8000번에서 서버가 시작하도록 하는 명령어다. 포트 번호를 바꾸고 싶다면 python manage.py runserver \u0026lt;원하는 포트 번호\u0026gt; 를 입력한다. IP 주소까지 바꾸고 싶으면 python manage.py runserver 0:8000 로 입력한다. 여기서 0은 0.0.0.0의 약어다.\n이처럼 django가 자동적으로 한 가지 app의 기본적인 directory 구조를 생성하기 때문에, 디렉토리들을 어떻게 생성할지보다 코드를 작성하는 것에 집중할 수 있게 된다.\n 3. Creating the Polls app  Projects vs. apps\napp이란 어떤 것을 수행하는 웹 애플리케이션을 의미한다. 그리고, 하나의 프로젝트에는 여러 개의 app들이 포함되어 있다. 또한, 한 가지 app은 다양한 프로젝트에 존재할 수 있다.\n app을 만들기 위해서 manage.py가 존재하는 directory 경로로 이동한다.\n# 경로: /mysite  # project 생성은 python manage.py startproject \u0026lt;project 명\u0026gt; $ python manage.py startapp polls  $ cd polls  # 경로: mysite/polls  $ dir __init__.py admin.py apps.py migrations models.py tests.py views.py  $ cd migrations $ dir __init__.py 즉, 다음과 같은 구조를 가진다.\n\u0026gt; polls/ \u0026gt; __init__.py \u0026gt; admin.py \u0026gt; apps.py \u0026gt; migrations/ \u0026gt; __init__.py \u0026gt; models.py \u0026gt; tests.py \u0026gt; views.py  4. Write your first view polls/views.py 를 열어 아래 코드를 입력하자.\n\u0026gt; from django.http import HttpResponse  \u0026gt; def index(request): \u0026gt; return HttpResponse(\u0026#34;Hello, world. You\u0026#39;re at the polls index.\u0026#34;) 이 view를 호출하기 위해서는 이 뷰를 URL에 mapping 해야 하며, 이를 위해서 URLconf가 필요하다.\npolls directory에 URLconf를 만들기 위해서 polls에 urls.py를 생성한 후, 밑에 코드를 입력하자.\n# 경로: polls/urls.py  \u0026gt; from django.urls import path  \u0026gt; from . import views  # path에 `index`란 이름으로 views.index를 추가한다.  \u0026gt; urlpatterns = [ \u0026gt; path(\u0026#39;\u0026#39;, views.index, name=\u0026#39;index\u0026#39;), \u0026gt; ]  URLconf란 URL configuration의 약어로서 python module의 이름으로, URL path 표현식들을 파이썬 함수 즉, view에 연결시킨다. from Django 공식문서 - URL dispatcher\n 다음 단계는 app의 urls module을 project 폴더의 urls에 추가하여, 다른 URLconfs도 인식되도록 하는 단계다.\nmysite/urls.py 에 추가하기 위해서, django.urls.include 를 import하고 urlpatterns에 include()를 삽입한다.\n# 경로: mysite/urls.py  \u0026gt; from django.contrib import admin \u0026gt; from django.urls import include, path  \u0026gt; urlpatterns = [ \u0026gt; path(\u0026#39;polls/\u0026#39;, include(\u0026#39;polls.urls\u0026#39;)), \u0026gt; path(\u0026#39;admin/\u0026#39;, admin.site.urls), \u0026gt; ] ❗ include() 는 다른 경로에 있는 URL patterns를 포함시키고자할 때, 반드시 사용해야한다. 이 function을 통해서 URLs를 손쉽게 추가하고, 사용할 수 있다.\nindex view를 URLconf로 엮었기 때문에, 이제 아래 명령어로 확인해보자.\n만약 page를 확인할 수 없다고 뜬다면 http://localhost:8000/polls/ 또는 http://localhost:8000/. 을 입력해보자.\n\u0026gt; python manage.py runserver  path() argument: 4가지  path(route, view, kwargs, name): route와 view는 필수이고, kwargs와 name은 선택이다.\n   route\n 한 개의 URL pattern을 포함하고 있는 문자열 요청이 처리될 때, django는 urlpatterns의 첫 번째 패턴을 시작하여 각 patten과 요청된 URL을 비교하면서 매칭되는 것을 찾을 때까지 밑으로 내려간다. Patterns 은 GET, POST 또는 도매인 이름을 찾지 않는다.  https://www.example.com/myapp/ 또는  https://www.example.com/myapp/?page=3 으로 요청이 들어온다면 URLconf는 myapp/을 찾을 것이다.      view\n 매칭되는 패턴을 장고가 찾을 대, HttpRequest 객체와 함께 지정된 view fuction을 첫 번째 인자로서 호출하고, route로부터 포착한 값을 키워드 인자로서 호출한다.    kwags\n tutorial에서 사용되지 않기 때문에 건너뛴다.    name\n URL을 django 어디에서든 name으로 참조하도록 한다.     Reference  Django at a glance  ","permalink":"http://jeha00.github.io/post/django/doc_tutorial_01/","summary":"django를 설치한 후, project와 application을 명령어를 통해 만들어보고, view와 URLconf에 대해 학습해본다.","title":"Django study: Document tutorial Part 1 따라해보기"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   이번 단원에서는 Commit에 tage를 다는 것에 대해 알아본다.   9.1 Commit에 tag 달기   Commit에 tage를 다는 이유는 다음과 같다.\n 특정 시점을 키워드로 저장하고 싶을 때 커밋에 버전 정보를 붙이고자 할 때    Github repository에 들어가보면 tage를 발견할 수 있다.\n branch를 선택하는 곳 옆옆에를 보면 현재 시점 기준 225 tags 임을 알 수 있다. 이 tags를 클릭하면 다음 이미지를 볼 수 있다.     9.1 tag 규칙  tags를 입력할 때는 이 문서의 규칙 Semantic Versioning 정보을 따른다.\n  요약하자면 다음과 같다.  주.부.수 숫자로 버전을 명시한다. 주: 기존 버전과 호환되지 않게 API가 바뀌면 \u0026lsquo;주 버전\u0026rsquo;을 올린다. 부: 기존 버전과 호환되면서, 새로운 기능이 추가되면 \u0026lsquo;부 버전\u0026rsquo;을 올린다. 수: 기존 버전과 호환되면서, 버그를 수정한 것이라면 \u0026lsquo;수 버전\u0026rsquo;을 올린다.    9.2 tag 종류  tag 종류는 lightweight와 annotated로 나눠진다.\n  lightweight: 단지 특정 커밋을 가리키는 용도 annotated: 작성자 정보와 날짜, 메시지, GPG 서명 포함 가능     tag 종류 lightweight tag annotated tag     마지막 커밋에 tag 달기 git tag v2.0.0 git tag -a v2.0.0    # lightweight tag $ git tag v2.0.0  # annotated tag # 아래 명령어를 입력 후, 뜨는 창에 메시지를 작성 $ git tag -a v2.0.0  또는 아래와 같이 메시지를 같이 입력한다.  $ git tag v2.0.0 -m \u0026#39;(message)\u0026#39;  그리고 tag 명령어 종류는 다음과 같다.     tag 명령어 종류 설명     git tag 현존하는 태그 확인   git show v2.0.0 원하는 태그의 내용 확인   git tag -d v2.0.0 태그를 삭제    # 현재 tag가 version 몇인지 보여준다. $ git tag v2.0.0  # 해당 태그가 달린 커밋에 무슨 변화가 있는지 보여준다. $ git show v2.0.0. Tagger: --- Date: ---  # 위에 입력한 메세지 tag   # 해당 태그 삭제 $ git tag -d v2.0.0 Deleted tag \u0026#39;v2.0.0\u0026#39; (was 3d75f7f)  원하는 방식으로 태그를 달거나, 필터링, checkout 할 수 있다.     tag 명령어 설명     git tag (태그명) (커밋 해시) -m (메시지) 원하는 커밋에 태그 달기   git tag -l \u0026lsquo;v1.*\u0026rsquo; 원하는 패턴으로 필터링하기   git checkout v1.2.1 원하는 버전으로 체크 아웃    $ git tag v1.2.3 (커밋 해시) -m \u0026#39;Second version\u0026#39;  $ git tag -l \u0026#39;v1.*\u0026#39; v1.2.3  9.2 원격의 태그 관리 특정 태그 원격에 올리기  git push (원격명) (태그명)\n $ git push origin v1.0.5  위 명령어를 입력한 후, GitHub 원격 저장소를 들어가면 tag의 수가 늘어난 걸 알 수 있다.  특정 태그 원격에서 삭제  git push \u0026ndash;delete (원격명) (태그명)\n $ git push --delete origin v1.0.5  tag의 갯수가 다시 줄어든 걸 확인할 수 있다.  로컬의 모든 태그 원격에 올리기  git push \u0026ndash;tags\n  tag의 갯수가 다시 늘어난 걸 알 수 있다. tag 버전명을 따로 적지 않으면 모든 tag에 원격에 올라간다.  GitHub의 release 기능  GitHub의 올라간 tag들 중, 배포하는 버전인 배포버전들을 의미하는게 Releases 다.\n   이에 대해 보다 이해하기 위해서 네이버 나눔고딕 코딩글꼴 예시를 참고해보자.\n 17개의 tags가 있지만, Releases는 14개다. 즉, tags 중에서 배포버전을 정하는 것이다.    tags에 들어가서 원하는 태그의 오른쪽을 보면 점이 3개 있다. 이를 클릭하여 Create release를 클릭한다.\n  그러면 배포하기 원하는 title과 그 내용을 markdown 명령어로 입력한다.\n  Pubishing을 클릭하여 배포한다.\n   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chpater09/","summary":"v0.0.0 에서 각 자리가 무엇을 의미하는지, commit에 tag를 다는 명령어인 git tag, 그리고 여러 버전들 중 일부를 release하는 것을 배운다.","title":"[TIL] Git study: Lecture Chapter 09 - git tag"},{"content":"0. Introduction   해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.\n  이번 단원에서는 git stash, git commit --amend 그리고, git rebase -i 명령어를 학습해본다.\n   7-3. git stash  커밋하기 애매한 변화를 치워두는 명령어\n  Stash 사용법 정리     명령어 설명 비고     git stash 현 작업들 치워두기 끝에 save 생략   git stash apply 치워둔 마지막 항목(번호 없을 시) 적용 끝에 번호로 항목 지정 가능   git stash drop 치워둔 마지막 항목(번호 없을 시) 삭제 끝에 번호로 항목 지정 가능   git stash pop 치워둔 마지막 항목(번호 없을 시) 적용 및 삭제 apply + drop   git stash branch(브랜치명) 새 branch를 생성하여 pop 충돌사항이 있는 상황 등에 유용   git stash clear 치워둔 모든 항목들 비우기       변경사항을 먼저 만들어보자.\n Tigers의 members에 Stash를 추가한다. tomcats.yaml을 추가한 후, git add를 실행 여기서 git add를 한 이유는 git stash라는 명령어를 실습하기 위해서는 먼저 tracked 상태여야 한다.    git stash 실행: git add 했던 변화들이 사라진다.\n 사라진 변화들은 sourcetree에서 스태시 란에서 확인할 수 있다.    git stash pop 을 입력하여 원하는 시점, 브랜치에 다시 적용한다.\n 다른 branch를 만들고 전환 후, 이 명령어로 적용해보자.    git add -p처럼 원하는 것만 stash 할 수 있다.\n Leopards의 members에 Stash2를 추가한다. Jaguars의 members에 Stash3를 추가한다. git stash -p로 Stash2만 선택하여 스태시한다.    메시지와 함께 스태시를 할 수도 있다.\n  git stash -m 'Add Stash3'\n$ git stash -m \u0026#39;Add Stash3\u0026#39; Saved working directory and index state On remote-branch: Add Stash3     스태시 목록 보기\n-git stash list\n$ git stash list  stash@{0}: On remote-branch: Add Stash3  stash@{1}: WIP on remote-branch: 1b2bbcb Edit Leopards and Tigers   스태시된 항목 삭제: git stash drop\n$ git stash drop stash@{0} Dropped stash@{0}  $ git stash list stash@{0}: WIP on remote-branch: 1b2bbcb Edit Leopards and Tigers    7-4. git commit \u0026ndash;amend  Commit message 변경하기\n   커밋 메시지를 변경하거나, 커밋에 변화를 추가 또는 커밋 메시지를 한 줄로 변경할 수도 있다.\n  커밋 메시지 변경\n 파일에 변화를 준 후, 커밋 메세지를 와웅 으로 입력해보자. git commit --amend 를 입력하여 편집창을 띄운다. Commit message: Add a member to Panthers 를 입력 후, :wq를 입력하여 저장 종료한다. git log로 확인해보자.    커밋에 변화 추가: 지난 커밋에 줘야할 변화를 깜빡했을 경우\n 파일들에 변화를 준 후, staging area에 올린다. git commit --amend로 마지막 커밋에 포함시킨다.    위에 처럼 git commit --amend를 실행한 후, 편집기가 뜨면 그 때 메세지를 수정하는 것 외에도 단 한 줄로도 수정할 수 있다.\n git commit --amend -m '(커밋 메세지)'    또한 바로 staging area에 올리면서 한 번에 커밋메세지를 수정하는 방법도 있다.\n git commit -a --amend -m '(커밋 메세지)'     7-5. git rebase -i  _i란 interactive를 의미하며, 과거의 커밋 내역들을 다양한 방법으로 수정 가능하다. _\n  git rebase -i를 입력했을 때, 사용되는 명령어들     명령어 설명     p, pick 커밋 그대로 두기   r, reword 커밋 메세지 수정   e, edit 수정을 위해 정지   d, drop 커밋 삭제   s, squash 이전 커밋에 합치기     git log로 커밋 내역들을 확인한다. git rebase -i \u0026lt;commit 해시 번호\u0026gt;를 입력하며 다음과 같이 뜬다.  $ git rebase -i  pick 1c799ad pick ff00ad8 pick f35344a pick b9d4eb7 pick 8605c74 pick 59b42f3   다음 수정사항들을 진행해보자.\n  hash number가 1c799ad인 커밋 메세지를 버그 수정으로 변경한다.\n r 명령어를 사용한다.    hash number가 ff00ad8인 커밋은 삭제\n d 명령어 사용    hash number가 b9d4eb7을 f35344a에 합치기\n 첫 항목 뒤로 s명령어 사용하기 메시지 수정 후 저장  커밋 메세지는 하나만 있으면 되므로, 두 개중 하나의 커밋 메세지를 삭제한다.      위 명령어들을 입력하면 다음과 같다.\n$ git rebase -i  r 1c799ad d ff00ad8 pick f35344a s b9d4eb7 pick 8605c74 pick 59b42f3   한 커밋 안에 두 작업이 있으므로, 2개의 커밋으로 나누는 작업을 진행해보자.\n git rebase -i \u0026lt;나눌려고 하는 commit의 이전 commit 해시 번호\u0026gt; 입력  pick에서 e 로 수정하고 :wq   git reset HEAD~ 변화들을 따로 스테이지 및 커밋 git rebase --continue       Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-030405/","summary":"커밋하기 애매한 변화를 치워두는 명령어인 git stash, commit message를 수정하는 git commit \u0026ndash;amend, commit 과거 내역들을 수정하는 git rebase -i 를 학습한다.","title":"[TIL] Git study: Lecture Chapter 07 -  git stash \u0026 git commit --amend \u0026 git rebase -i"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   7-2. 보다 꼼꼼히 staging 하기 staging 환경 만들기   Tigers 변경\n manager: Thanos coach: Ronan new members: Gamora, Nebula    Leopards 변경\n manager: Peter coach: Rocket new members: Drax, Groot    hunk 별로 staging 진행하기   hunk란 code가 수정되는 부분에서 수정되지 않는 부분까지를 의미한다.\n 위에 Tigers를 기준으로 보자면 manager와 coach는 연달아 있으므로 한 hunk에 해당하지만, members까지 수정안되는 부분이 있기 때문에 끊어지고, 추가되는 members가 별도의 hunk가 된다.    이 hunk 단위로 staging area에 올리고 싶으면 git add -p 이고, -p는 patch의 약자다.\n   team: Leopards  -manager: Dooli +manager: Peter  -coach: Lupi +coach: Rocket   members:  - Linda  (1/2) Stage this hunk [y,n,q,a,d,j,J,g,/,s,e,?]?   위와 같이 뜬다.\n 각 옵션 설명을 보려면 ? 입력 후, 엔터 y 또는 n으로 각 헝크를 선택한다. 일부만 staging 하여 진행해보고, git status와 소스트리로 확인해보자.    $ git status Changes to be committed:  (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  modified: leopards.yaml  modified: tigers.yaml  Changes not staged for commit:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed)  (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)  modified: leopards.yaml  modified: tigers.yaml  부분적으로 staging area에 올렸기 때문에, 위와 같이 뜬다. 그러면 아래 명령어를 입력하여 부분적으로 나눠서 commit 하자.  $ git commit -m \u0026#39;Edit Tigers and Leopards\u0026#39; $ git add . $ git commit -m \u0026#39;Edit Leopards and Tigers\u0026#39;   마지막으로 git diff --staged와 비교해보자.\n 이 명령어는 이번 commit에서 변경된 사항을 확인하는 명령어다.    이 git commit -v는 커밋과 이 git diff --staged를 같이하는 명령어라고 생각하면 된다.\n   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-02/","summary":"변경사항을 보다 쪼갠 hunk 크기로 나눠 staging area에 올리는 명령어인 git add -p 와 커밋하는 명령어인 git commit -v 에 대해 학습해본다.","title":"[TIL] Git study: Lecture Chapter 07 - git add -p \u0026 git commit -v"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   7-1. Commit message 작성 시, 유의사항 7-1.1 작업 커밋할 때 권장사항 Commit message 작성 시 유의사항\n  어떤 작업이 이뤄졌는지 다른 누가 보더라도 알아볼 수 있는 내용이 담겨져야 한다.\n 왜냐하면 혼자서만 프로젝트를 진행하는 게 아니기 때문이다.    하나의 커밋에는 한 단위의 작업을 넣는다.\n  한 작업을 여러 버전에 걸쳐 커밋하지 않는다.\n  여러 작업을 한 버전에 커밋하지 않는다.\n    합의된 방식을 잘 준수하여 \u0026lsquo;일관된 형태의 커밋\u0026rsquo;을 작성해야 한다.\n  7-1.2 Commit message convention  \u0026lsquo;Commit message convention\u0026rsquo;이란 commit message를 작성하는 방식인데 전세계 개발자들 사이에 많이 공유되고 권장되는 방식을 알아보겠다.\n   Convention: 팀원들끼리 어떤 것의 작성하는 방식을 합의를 해 놓은 것을 말한다.\n 정해진 답이 아닌, 각 팀과 그 업무에 가장 적합한 걸 택한 것    Commit message 방식\ntype: subject  body (optional) ... ... ...  footer (optional)  예시   feat: 압축파일 미리보기 기능 추가   사용자의 편의를 위해 압축을 풀기 전에  다음과 같이 압축파일 미리보기를 할 수 있도록 함  - 마우스 오른쪽 클릭  - 윈도우 탐색기 또는 맥 파인더의 미리보기 창   Closes #125   그러면 type, subject, body, footer에 대해 알아보자.\n  type\n   type explanation     feat 새로운 기능 추가   fix 버그 수정   docs 문서 수정   style 공백, 세미콜론 등 스타일 수정   refactor 코드 리팩토링   perf 성능 개선   test 테스트 추가   chore 빌드 과정 또는 보조 기능 수정      subject\n 커밋의 작업 내용 간략히 설명    body\n 길게 설명할 필요가 있을 시 작성    footer\n breaking point 가 있을 때 특정 이슈에 대한 해결 작업일 때      7-1.3 Gitmoji Commit message에 이모지를 넣어서 입력하는 방식도 있다.\n이는 Chapter 12에서 학습할 예정이다.\n Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter07-01/","summary":"commit message를 작성할 때 권장사항들과 commit message convention에 대해 학습하여 commit message를 보다 체계적으로 작성해본다.","title":"[TIL] Git study: Lecture Chapter 07 - Commit message 권장사항과 convention "},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. Git help   git 명령어가 기억나지 않을 때, git 명령어의 상세한 옵션이 기억나지 않을 때 이에 대한 도움 받을 수 있는 git help에 대해 알아보자.\n  git의 전체 명령어가 궁금할 때 사용하는 명령어\n  git help : git의 여러 명령어를 간략히 보여준다.\n  git help -a: git의 모든 명령어를 보여준다.\n j: 내리기 k: 올리기 :q : 닫기      특정 명령어에 대해 궁금할 때 사용하는 명령어\n  git (명령어) -h: 해당 명령어의 설명과 옵션 보기\n ex) git commit -h    git help (명령어) or git (명령어) --help: 명령어에 대한 설명을 웹에서 자세한 설명을 보고 싶을 때\n 웹에서 열리지 않을 시 끝에 -w를 붙여 명시       2. Git config   Git을 설정하는 git config에 대해서 보다 자세히 알아보자.\n  global 설정과 local 설정\n config를 --global과 함께 지정하면 전역으로 설정된다.  ex) git config --global user.name      현재 모든 설정값 보기\n git config (global) --list 전역으로 모든 설정값을 볼 때랑 아닐 때랑 출력이 다르다.    설정값을 에디터에서 보기\n 기본 설정값은 Vim editor git config -e 기본 에디터인 Vim에서 Visual studio code 등 IDE로 보고 싶으면 아래 명령어를 입력한다.  git config --global core.editor \u0026quot;code --wait\u0026quot; code 자리에 원하는 편집 프로그램의 .exe 파일 경로를 연결해도 변경할 수 있다. 이 명령어를 실행한 후, git config -e를 실행한다. 이와 같이 설정하면 커밋 메시지 입력창도 해당 에디터에서 열리게 된다. --wait: 에디터에서 수정하는 동안 CLI를 정지한다.      에디터 설정을 되돌리고 싶으면?\n git config --global -e로 편집기를 연 뒤, [core] 란에 excludesfile 과 editor 부분을 삭제하고 저장하면 된다.    이외의 유용한 설정들   줄바꿈 호환 문제 해결\n git config --global core.autocrlf (윈도우: true / 맥: input)    pull 기본 설정을 merge 또는 rebase로 설정\n git config pull.rebase false 또는 git config pull.rebase true    기본 브랜치명 설정\n git config --global init.defaultBranch main    push 시, 로컬과 동일한 브랜치명으로 설정\n git config --global push.default current    단축키 설정 2.7 Git의 기초 - Git Alias 를 참고한다.\ngit config --global alias.(단축키) \u0026quot;명령어\u0026quot; 를 사용한다.\n예를 들어 git config --global alias.cam \u0026quot;commit -am\u0026quot; 로 사용한다.\n하지만, 이 방식은 나중에 사용하는 게 낫다고 판단된다. 전반적인 명령어를 안보고 사용할 수 있는 수준에 이르면 사용하자.\n Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter06/","summary":"git 명령어가 기억나지 않아 설명서가 필요한 경우 사용하는 \u003ccode\u003egit help\u003c/code\u003e 명령어와 \u003ccode\u003egit config\u003c/code\u003e를 사용한 git 설정에 대해 자세히 알아본다.","title":"[TIL] Git study: Lecture Chapter 06 - git help \u0026 git config"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. Git의 장점: Snapshot과 DVCS Git의 장점인 Snapshot 방식과 DVCS에 대해 알아보자.\nWhat is git?에 대한 요약버전이다.\n1.1 Snapshot 방식 Snapshot 방식에 대해 알아보기 전에 git의 이전 버전들이 사용한 **델타 방식**에 대해 알아보자.\n  델타 방식\n  델타방식은 해당 파일 전체가 처음 시점을 기준으로 이어져서 그 이후 변경지점만 누적되어 저장된다.\n 버전 5시점에서는 델타1, 델타2, 델타 3이 저장되는 것이다.      snapshot 방식\n  스냅샷 방식은 새로운 버전이 만들어질 때, 해당 버전에서의 각 파일이 최종 상태 그대로 저장되어 있다.\n 버전 5에서 A는 변화가 없으니까 버전 4에서 가져온다. 이 저장도 용량을 별로 차지하는 방식으로 저장된다.      그렇다면 이 2가지의 차이점을 이해하기 위해 한 상황을 가정해보자.\n만약 VSC 프로젝트처럼 커밋이 몇 만개가 있는 레포지토리를 델타버전으로 다룬다면 어떨까??\n델타 방식은 Git에서 뭘 할 때마다 각 파일들을 그거가 처음 만들어진 시점부터 변경사항들을 쭈욱 더해서 현재 내용을 계산해야하니 관리역사가 길수록 되게 느려진다.\n반면에 스냅샷은 그냥 현 시점에 각 파일들이 풀로 저장되어 있으니까 아주 빠르다.\n1.2 DVCS CVCS는 원격 저장소에 의존적이라서 인터넷 연결이 끊기면 로컬에서 할 수 잇는 게 제한적이다.\n밑에 이미지가 CVCS(Central Version Control System)다.\n반면에 Git은 clone 명령어로 가져오면 전체 Git 커밋과 branch까지 가져오기 때문에 인터넷 연결 상태와 상관없이 로컬에서 자유롭게 작업할 수 있다.\n밑에 이미지가 DVCS(Distributed Version Control System, 분산 버전 관리 시스템)이다.\n 2. Git의 3가지 공간   Git의 3가지 공간: Working directory, Staging area, Repository 각 공간을 이동하는 git 명령어: Working directory == (git add) ==\u0026gt; Staging area == (git commit) ==\u0026gt; Repository Working directory = Untracked state + Tracked state commit되어 레포지토리에 들어간 후 수정사항이 발생하면 tracked 상태로 staging을 기다린다.   Git basics을 참고한다.\n  Working directory\n Untracked: Add된 적 없는 파일, ignore된 파일  Add된 적 없는 파일이란? git이 관리한 적이 없는 파일, 새로 생긴 파일을 말한다.   Tracked: Add된 적 있고, 변경내역이 있는 파일 git add 명령어에 의해서 Working directory에서 Staging area로 올라온다.    Staging area\n 커밋을 위한 준비 단계  ex) 작업을 위해 선택된 파일들   git commit 명령어로 repository로 이동 Staging area에서 working directory로 CLI로 이동하기  git restore --staged (파일명)   --staged를 빼면 working directory에서도 제거 = 변화를 제거한다.   소스트리로는 단지 스테이지에서 내리기를 클릭한다.      Repository\n .git repository라고도 불린다. 커밋된 파일들이 들어간 곳     3. git 명령어로 파일 삭제, 이동   파일 삭제\n  삭제 후 area 위치 확인: git status로 확인\n   삭제 방법 우클릭 삭제 git rm     area 위치 working directory Staging area   복원 방법 git reset --hard git reset --hard     git rm으로 삭제한 것을 바로 staging area에 있는 걸 알 수 있다. git rm은 바로 git add 명령어를 적용한 것이다.  # 우클릭 삭제 후, 상태 확인  $ git status  Changes not staged for commit:  deleted: tigers.yaml  no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;)  # git rm으로 삭제 후, 상태 확인 $ git status  Changes to be committed:  deleted: tigers.yaml     파일 이동\n  tigers.yaml를 zzamtigers.yaml로 이름 변경 뒤, git status로 살펴보기\n   변경 방법 우클릭 변경 git mv     area 위치 working directory Staging area   복원 방법 git reset --hard git reset --hard     git mv는 바로 git add 명령어를 적용한 것이다.  # 우클릭 변경 $ git status  Changes not staged for commit:  deleted: tigers.yaml  Untracked files:  zzamtigers.yaml  # git mv 사용 $ git status  Changes to be committed:  renamed: tigers.yaml -\u0026gt; zzamtigers.yaml      4. reset의 세 가지 옵션  --soft: repository에서 staging area로 이동. staging area에 남겨놓는다. --mixed (default): repository에서 working directory로 이동. working directory에 남겨놓는다. --hard: 수정사항 내역을 완전히 삭제. 즉, working directory에서조차 삭제한다.  그러면 실습 해보자. 단, --hard는 생략한다.\n파일 일부를 변경한 후, 아래 명령어를 실행한다.\n\u0026gt; git reset --soft 1c1037862c2a5919f31ecf0f55874c8bf236fea5 \u0026gt; $ git status  Changes to be committed:  modified: panthers.yaml  modified: tigers.yaml --soft를 사용하니 staging area로 이동된 걸 확인했다.\n 5. Git의 HEAD  HEAD: 현재 위치를 나타내기 위해 임의로 만든 branch\n history, 시간선은 그대로 두고, 파일들의 상태만 이동하는 방법에 대해 알아보자.\n5.1 git checout HEAD^~ 바로 git checkout을 사용하는 것이다.\n  git checkout HEAD^ 또는 git checkout HEAD~에서 ^와 ~의 갯수만큼 이전으로 이동하기\n git checkout HEAD^^^ git checkout HEAD~5    실습상황을 만들어보자. 현재 브랜치와 커밋 상황은 다음 이미지와 같다.\n  현재 위치는 branch c의 HEAD에 위치한다.\n  여기서 git checkout HEAD~을 입력하면 c second commit으로 이동된다.\n  git status로 현재 commit 위치를 확인할 수 있다.\n$ git status HEAD detached at b99000a     aa branch의 HEAD 지점으로 이동하기 위해서 git checkout HEAD~2 를 입력한 후, git status로 확인하여 잘 이동된 걸 알 수 있다.\n$ git status HEAD detached at d8a94fb   5.2 git checkout -  한 단계 되돌리기\n   이동을 한 단계 되돌리고 싶으면 git checkout - 을 입력한다.\n 되돌아간 걸 확인하기  $ git status HEAD detached at b99000a   5.3 git checkout 커밋해시   이번에는 커밋 해시를 사용해서 이동해보자.\n b 1st commit 으로 이동해보자.  $ git checkout 57386f752a27a3dc953361091d7a384e0fb6d3ea $ git status HEAD detached at 57386f7   위 이미지를 확인하면 HEAD의 위치가 현재 위치임을 알 수 있다.\n 이 상태에서 git branch를 입력해보자.  $ git branch * (HEAD detached at 57386f7) a aa b c   git switch (branch 명): branch의 최신 위치로 이동   우리가 만든 branch가 아닌 익명의 branch가 만들어져서 현재 위치를 나타낸다. 즉, 위에 HEAD는 또 하나의 branch라는 것이다. 그렇다면 해당 브랜치의 최신 버전으로 이동하고 싶다면 git branch (branch 명)으로 이동할 수 있다는 걸 알 수 있다.\n$ git switch c   그리고, 소스트리를 업데이트하면 현재 위치가 이동한 브랜치의 최신 위치임을 알 수 있다. 즉 기존 브랜치로 돌아오면 자동적으로 최신 커밋 위치로 온다.\n  그러면 현재 위치에서 새로운 branch를 만들고, 새 commit을 만들어보자.\n  $ git switch -c d $ git commit -am \u0026#39;d first commit\u0026#39;  이처럼 다른 branch로 이동해서 분기된 branch에서 다시 새로운 branch를 만들 수 있다.  5.4 HEAD 사용하여 reset 하기  git reset HEAD(원하는 단계) (옵션)\n  c branch에서 실행해보자.  $ git switch c $ git reset --hard HEAD~2  6. fetch와 pull의 차이  - fetch: 원격 저장소의 최신 커밋을 로컬로 가져와서 내용만 보고 싶을 때 사용한다.\n- pull: 원격 저장소의 최신 커밋을 로컬로 가져와 merge 또는 rebase를 실행하는 것으로서 fetch 과정을 포함한다.\n   fetch한 내역 적용 전 살펴보기\n  원격의 main branch에 commit을 추가하자. 추가 후, git checkout origin/main으로 원격의 브랜치로 이동하기.\n  원격의 변경사항을 fetch로 확인하기\n git checkout origin/main으로 확인해보기. 아무것도 변화된 게 없다. -\u0026gt; 다시 git checkout main으로 로컬 branch로 돌아오기 다음으로 git fetch 입력하기 그리고, 아직 main branch에 적용하고 싶지 않고 살펴만 보고 싶다. 그러면 git checkout origin/main을 입력하여 확인 후, 다시 git switch main으로 돌아와 서 git pull을 적용한다. pull로 적용      원격의 새 브랜치 확인\n  git checkout origin/(branch명)\n  git switch -t origin/(branch명)\n git fetch -\u0026gt; git branch -a 하면 확인가능 -\u0026gt; 이 branch를 확인만 하고 싶으면 git checkout origin/branch명 입력 -\u0026gt; git checkout main -\u0026gt; git switch -t origin/remote-local  #원격에 remote-local branch를 만든다.  $ git fetch  $ git branch -a * main remotes/origin/main remotes/origin/remote-local  $ git checkout main $ git switch -t origin/remote-local      Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter05/","summary":"첫 번째, Git의 장점. 두 번째, Git의 3가지 공간. 세 번째, git rm과 git mv 명령어. 네 번째, reset의 3가지 옵션. 다섯 번째, Git의 HEAD를 이동하기 위해서 git checkout 명령어. 마지막으로 fetch와 pull의 차이를 학습한다.","title":"[TIL] Git study: Lecture Chapter 05 - deep dive"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. Github이란? Github이란 Gitlab, Bitbucket과 같이 코드 공유 및 협업 서비스\n보다 더 자세히 설명하자면 Git으로 관리하는 모든 프로젝트들을 온라인 공간에 공유해서 프로젝트 구성원들이 협업하는데 도와주는 서비스이다.\n그런데, 일반 클라우드 서비스와의 차이점은 무엇일까??\n일반 클라우드 서비스로 협업을해야한다면 같은 파일을 공유해서 수정할 경우, 일반적인 공유 방법으로는 답이 없다. 왜냐하면 계속해서 덮어씌워지는 문제가 발생하기 때문이다.\n하지만, Github을 사용하면 모든 업로드와 다운로드를 커밋 단위로 주고받기 때문에, 서로의 작업을 덮어씌울 걱정할 필요 없이 협업하는데 문제점을 해결해준다.\n즉, 협업 시의 교통정리를 해준다.\n 2. 토큰 만들기 Personal access token 만들고, 이 토큰을 컴퓨터에 저장하고자 한다면,\n또한, 새로운 Repository를 생성 후 협업할 팀원을 추가하고 싶으면\n아래 링크를 참고한다.\nSection 4. Github 사용하기 - Lesson 2. GitHub 시작하기\n위 링크에서 토큰을 컴퓨터에 저장하고자 할 때, 윈도우 컴퓨터의 경우,\nWindow 자격 증명 관리자 란 제어판 홈에 있는 메뉴를 의미한다.\nWindow menu bar에 이를 검색하면 바로 뜰 것이다.\n지금은 바로 필요하지 않으니 자세한 설명보다 링크를 통해 나중에 더 자세히 보자.\n 3. 원격 저장소 만들기   Github repository를 생성 후, 이 링크 주소를 복사한다.\n 새로운 repository를 생성하여 들어가면 Code tab 란에 |HTTPS|SSH| 칸이 있는데, 이중 HTTPS를 선택한다.    local의 Git 저장소에 원격 저장소를 연결하기 위해서 아래 명령어를 입력한다.\n 이 방식으로 hugo를 사용하여 gitub 기술 블로그를 만들었다.  Window에서 Hugo로 Github page 만들고 배포하기    # 원격 저장소를 추가하는 명령어  git remote add origin (복사한 링크 주소 즉, 원격 저장소 주소)  origin은 원격 저장소의 이름이다. 흔히 origin을 사용한다. 하지만, 다른 것으로도 사용 가능하다.  git branch -M main   local 저장소의 commit 내역들을 원격으로 push (업로드) 한다.\ngit push -u origin main   -u 또는 --set-upstrea: 현재 브랜치와 명시된 원격 브랜치의 기본 연결을 origin main으로 하겠다는 의미다. 이 명령어를 입력한 이후에는 git push만 해도 이와 동일한 의미로 받아들인다.\n  하지만, 업로드 branch를 여러 개로도 할 수 있다.\n    💡 2번과 3번을 직접 입력해도 되지만, repository를 만들어서 클릭 후 들어가면 위 3가지 명령어 line을 한 번에 복사할 수 있도록 해놨다. 2. 토큰 만들기 가 잘 되었다면 순탄하게 진행될 것이다.\n 원격으로 연결된 목록을 보고 싶으면 git remote 또는 자세히 보고 싶으면 git remote -v를 입력한다.\n  원격으로 연결된 것을 지우고 싶다면 git remote remove (origin 등 원격 이름) 을 입력한다.\n 이 때 Github repository가 삭제되는 것이 아니다. 단지 로컬과 Github의 연결만을 지운다.     4. GitHub에서 프로젝트 다운받기  GitHub에서 다른 동료의 프로젝트를 다운받으려고 할 때 몇 가지 방식이 있다.    Download ZIP 으로, ZIP 파일로 다운받아 원하는 폴더에 푸는 방식이다. 하지만 이 방식은 파일들만 다운 받고, .git은 다운받지 않기 때문에 Git 관리내역은 제외되어 추천하지 않는다.\n  다운받기 원하는 폴더에서 터미널이나 Git Bash를 열은 후, 그 경로에서 git clone (원격 저장소 주소) 를 입력하는 것이다. 그러면 .git도 다운받기 때문에, Git 관리 내역까지 포함된다. 그래서 이 방식을 추천한다.\n   5. push와 pull 5.1 원격으로 커밋 push \u0026amp; pull 5.1.1 원격으로 커밋 밀어올리기(push)   Leopards의 members에 Evie 추가\n Commit message: Add Evie to Leopards    git push\n 이미 git push -u origin main으로 대상 원격 브랜치가 지정되었기 때문에 가능하다.    GitHub page에서 확인 가능하다.\n  5.1.2 원격의 커밋 당겨오기(pull)   local이 아닌 Github에서 Leopards의 members에 Dongho 추가\n Commit message: Add Dongho to Leopards    git pull\n  local에서 file과 log 살펴보기\n  5.2 pull할 것이 있는데, push를 하면?? 이 상황은 local에서 수정한 것과 GitHub에서 동일한 것을 다르게 수정했을 경우, 충돌이 일어났을 때 pull을 먼저 하고 나서야 push를 할 수 있다.\n이 상황을 만들어보자.\n  local에서 Leopards의 manager를 Dooli로 수정\n commit message: Edit Leopards manager    GitHub에서 Leopards의 coach를 Lupi로 수정\n commit message: Edit Leopards coach    push 해보기\n 이 때 오류가 뜰 것이다. pull 해서 GitHub에서의 버전을 받아온 다음 push 가능하다.    push 할 것이 있을 시, pull하는 두 가지 방법\n  git pull --no-rebase: merge 방식\n 3번에서 push 전에 하는 pull 과 동일하다. git pull을 하면 자동적으로 git pull --no-rebase로 입력한다. 소스트리에서 확인해보기 reset으로 되돌린 다음 아래 방식도 해보기     git pull --rebase : rebase 방식\n pull 상의 rebase는 다르다. (협업 시, 사용 OK) GitHub에 시간선을 맞춘다. pull 상의 rebase는 일반 rebase와 상황이 다르므로, 협업시 사용해도 괜찮다.\n      push 하기\n  5.3 협업상 충돌 발생 해결하기   Local에서 Panthers의 members에 Maruchi 추가\n commit messge: Add Maruchi to Panthers    원격에서 Panthers의 members에 Arachi 추가\n commit message: Add Arachi to Panthers    pull 하여 충돌상황 마주하기\n  --no-rebase 와 --rebase 모두 해볼 것\n  git pull --no-rebase 한 결과   git pull --rebase 한 결과       5.4 local의 내역 강제 push하기   언제 사용하는가?\n local 상의 내용이 원격보다 내용이 뒤쳐지면 push를 할 수 없을 때 그리고, 원격에서의 내용이 잘못되서 강제로 local에서의 내용으로 맞춰야할 때    하지만, 사용하기 전 미리 합의 후 실행해야 한다. 왜냐하면 다른 사람이 한 것이 날라갈 수 있기 때문이다.\n  git push --force 로 덮어씌울 수 있다.\n   6. 원격의 브랜치 다루기 6.1 로컬에서 브랜치 만들어 원격에 push 해보기   from-local branch 만들기\n  아래 명령어로 원격에 push\n  git push\n  위 명령어를 입력하면 원격 저장소의 대상을 명시 하라는 메시지가 나타난다.\nfatal: The current branch from-local has no upstream branch. To push the current branch and set the remote as upstream, use   git push --set-upstream origin from-local   그 때 이 명령어를 입력하여 원격 브랜치 명시 및 기본 설정한다.\n git push -u origin from-local 이 명령어로 원격 저장소의 브랜치에 from-local이 생긴다.      원격 저장소의 from-local branch의 jaguars.yaml를 편집한다.\n manager를 Cheolsu로 수정한다. Commit message: Edit Jaguars Manager    branch 목록 살펴보기\n  GitHub에서 목록 보기\n  아래 명령어로 local과 원격의 branch 확인\n git branch --all : git branch는 local만 확인한다.  from-local main remotes/origin/from-local remotes/origin/main     6.2 원격의 브랜치 로컬에 받아오기   GitHub에서 from-remote branch 만들기\n GitHub에서 branch를 선택하는 곳의 빈칸에 입력하면 Create branch: from-remote from 'main'이 뜬다. git branch -a에서 현재는 보이지 않는다.    아래 명령어로 원격의 변경사항 확인\n git fetch    아래 명령어로 로컬에 같은 이름의 브랜치를 생성하여 연결하고 switch\n  git switch -t origin/from-remote\n  소스트리에서 origin/branch 명 인 걸 확인할 수 있다. 이는 원격에 있는 branch를 의미한다.\n    Local에서 jaguars의 manager를 cheolsu로 바꾼다.\n commit message: Edit Jaguars Manager    6.3 원격의 브랜치 삭제 아래 명령어를 입력하여 원격 저장소의 브랜치를 삭제한다.\n git push (원격 이름) --delete (원격의 브랜치명)  git push origin --delete from-local git push origin --delete from-remote    위 명령어를 입력하면 다음과 같이 뜬다.\n$ git push origin --delete from-local To https://github.com/JeHa00/git-practice.git - [deleted] from-local  $ git push origin --delete from-remote To https://github.com/JeHa00/git-practice.git - [deleted] from-remote 6.4 Sourcetree로 진행하기  원격 추가하기: 원격에 새로운 repository를 만든 후, 새 repo.에 해당하는 HTTPS 주소를 복사한다.  2번부터 7번은 소스트리로 push와 pull을 해보는 단계다.\n 소스트리의 위 메뉴들 중 저장소(R) -\u0026gt; 원격 저장소 추가 -\u0026gt;추가 -\u0026gt; 원격 이름에 origin2 입력 \u0026amp; URL에 복사한 주소 입력\n  Push 클릭 -\u0026gt; 다음 저장소에 푸시: origin2로 설정\n  로컬의 Pumas의 members에 Pororo 추가\n Commit message: Add Pororo to Pumas    소스트리에서 커밋 클릭 -\u0026gt; 스테이지에 올라가지 않은 파일을 클릭한 다음, 모두 스테이지에 올리기를 클릭합니다.\n  Commit message를 입력 후, origin/main에 바뀐 내용 즉시 푸시 를 체크한 다음 커밋 실행\n  마지막으로 소스트리를 사용하여 브랜치를 만들어 푸시한다.\n 소스트리에서 브랜치 클릭 -\u0026gt; Push 클릭 -\u0026gt; from-local에도 체크 후 푸시 실행\n  원격에도 from-local branch가 생긴 걸 확인할 수 있다.\n  이번에는 원격에서 branch from-remote 를 만든 후, 소스트리에서 fetch(패치)를 실행하면 소스트리의 origin에 추가된 걸 확인할 수 있다.\n  추가된 from-remote를 사용하는 브랜치에 추가하고 싶으면, 원격 \u0026gt; origin \u0026gt; from-remote 에서 오른쪽 클릭하여 체크아웃을 클릭한다.\n   Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코 Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter04/","summary":"GitHub에 원격 저장소를 만들고, 원격과 로컬에서 branch를 새롭게 만들어보면서 원격 저장소로부터 pull, push를 사용하여 프로젝트를 동기화 해본다. 마지막으로 이 과정을 소스트리로 실행해본다.","title":"[TIL] Git study: Lecture Chapter 04 - 원격 사용하기"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. 여러 branch (다른 차원) 만들어보기  아래의 모든 것을 하나의 프로젝트 폴더에서 진행할 수 있도록 여러 branch를 만든다.\n 언제 branch를 여러 개 만들어서 작업을 할까??\n  프로젝트를 하나 이상의 모습으로 관리해야할 때\n 예) 실배포용, 테스트 서버용, 새로운 시도용    여러 작업들이 각각 독립되어 진행될 때\n 예) 신기능 1, 신기능 2, 코드개선, 긴습 수정 \u0026hellip; 각각의 차원에서 작업한 뒤, 확정된 것을 메인 차원에 통합한다.    1.1 브랜치 생성 / 이동 / 삭제하기 / 이름 바꾸기   branch 생성: add-coach란 이름의 브랜치 생성\n git branch add-coach    branch 목록 확인\n git branch *은 현재 branch를 의미한다.    \u0026gt; $ git branch add-coach \u0026gt; $ git branch  add-coach * main   생성된 branch로 이동\n git switch add-coach *가 add-coach로 옮겨진 걸 알 수 있다. checkut 명령어가 Git 2.23버전부터 switch와 restore로 분리되었다.    \u0026gt; $ git switch add-coach Switched to branch \u0026#39;add-coach\u0026#39;  \u0026gt; $ git branch * add-coach  main   💡 branch 생성과 동시에 이동하기\n git swtich -c new-teams 기존의 git checkout -b (새 브랜치명)이 이를 의미한다.    \u0026gt; $ git switch -c new-teams Switched to a new branch \u0026#39;new-teams\u0026#39;  \u0026gt; $ git branch  add-coach * main  new-teams   브랜치 삭제하기\n git branch -d (삭제할 브랜치명) to-delete란 branch 만들고, 삭제해보기    브랜치 이름 바꾸기\n git branch -m (기존 브랜치명) (새 브랜치명)    \u0026gt; $ git branch  add-coach * main  new-teams  to-delete  \u0026gt; $ git branch -m to-delete to-eraser  \u0026gt; $ git branch  add-coach * main  new-teams  to-eraser  \u0026gt; $ git branch -m to-eraser to-delete  \u0026gt; $ git branch -d to-delete Deleted branch to-delete (was 1589712).  \u0026gt; $ git branch  add-coach * main  new-teams   💡 브랜치 강제 삭제\n 지워질 브랜치에만 있는 내용의 커밋이 있을 경우, 다른 브랜치로 가져오지 않은 내용이 있는 브랜치를 지울 때는 -d 대신 -D (대문자)로 강제 삭제해야 한다.    1.2 각각의 브랜치에서 서로 다른 작업해보기  총 3개의 branch: main, add-coach, new-teams branch에서 작업한다.\n 각 작업을 실행할 때, git add를 실행한 후 git commit -m'()'을 해야 반영된다.\nChapter 02에서 알아봤듯이 모두 다 tracked file일 때, git commit -am'(commit message)' 로 한 번에 할 수 있다.\n1.2.1 main branch   Leopards의 members에 Olivia 추가\n 커밋 메시지: Add Olivia to Leopards    Panthers의 members에 Freddie 추가\n 커밋 메시지: Add Freddie to Panthers    1.2.2 add-coach branch   Tigers의 매니저 정보 아래 coach: Grace 추가\n 커밋 메시지: Add Coach Grace to Tigers    Leopards의 매니저 정보 아래 coach: Oscar 추가\n 커밋 메시지: Add Coach Oscar to Leopards    Panthers의 매니저 정보 아래 coach: Teddy 추가\n 커밋 메시지: Add Coach Teddy to Panthers    1.2.3 new-teams branch   pumas.yaml 추가\n 커밋 메세지: Add team Pumas    jaguars.yaml 추가\n 커밋 메세지: Add team Jaguars    1.3 결과 살펴보기 git log로도 볼 수 있지만 git log로 볼 경우에는 현재 branch 와 갈라지기 전 main일 때의 log만 볼 수 있다.\n별표는 하나의 줄기다.\n$ git log --all --decorate --oneline --graph * 672d65f (HEAD -\u0026gt; new-teams) Add team Jaguars * af9742d Add team Pumas | * 2641114 (add-coach) Add Coach Teddy to Panthers | * e22aa3c Add Coach Oscar to Leopards | * f91d19a Add Coach Grace to Tigers |/ | * 7618a7e (main) Add Freddle to Panthers | * a9fe922 Add Olivia to Leopards |/ * 1589712 (to-eraser) replace cheetas with Panthers * f86046e Add team Cheetas * 679d1f1 add George to tigers * 3183106 Replace Lions with Leopards * ed807a6 first commit 하지만 이런 흐름을 볼 때는 실무에서는 CLI보다 source tree로 본다.\nsource tree로 보면 다음과 같다.\n 2. branch를 합치는 두 가지 방법 branch를 합치는 실습을 해보기 전에, 위 실습과정을 이미지로 보자면 다음과 같다.\n주요 branch는 main branch다.\n그리고 양 옆에 add-coach branch, new-teams branch에서 실험적인 시도를 하고 있다.\n그리고 이 두 branch를 아래 이미지처럼 main branch로 합칠려고 한다.\n이를 위해서 2가지 방법으로 진행할 것이다.\n merge vs rebase\n   merge: 두 브랜치를 한 커밋에 이어붙이는 방식으로, 두 branch의 끝 가지를 이어붙힌다.\n 브랜치 사용 내역을 남길 필요가 있을 때, 적합한 방식 main과 add-coach branch를 합칠 방식      rebase: 브랜치를 다른 브랜치에 이어붙이는 방식으로, 곁가지들을 싹 다 잘라다가 몸통 줄기에 이어 붙여서 히스토리를 한 줄로 유지가능하다.\n 한 줄로 깔끔히 정리된 내역을 유지하기 원할 때 적합하다. 이미 팀원과 공유된 커밋들에 대해서는 사용하지 않는 것이 좋다. 즉, 있던 거를 없애다가 딴 데 이어붙이는 거인 만큼 같이 일하는 도중에 이러면 문제가 발생할 수 있다. main 과 new-teams branch를 합칠 방식    ❗ 이 두 가지 중 무엇을 사용하냐는 프로젝트의 성격에 달려있다. 브랜치의 사용 내역들을 남겨둘 필요가 있으면 Merge를, 그보다는 히스토리를 깔끔하게 만드는게 중요하면 Rebase를 사용한다.\n2.1 Merge로 합치기  main branch로 먼저 이동 git merge add-coach 명령어로 병합  $ git merge add-coach ❗ 위 과정에서 충돌이 났을 경우, 3. 충돌해결하기를 참고한다.\n 병합된 브랜치는 아래 명령어로 삭제한다.  삭제 전 소스트리에서 add-coach 위치 확인한다.    git branch -d add-coach 💡 Rebase와의 차이점: merge는 reset으로 되돌리기 가능하다.\n merge 도 하나의 커밋이기 때문에, merge 하기 전 해당 브랜치의 마지막 시점으로 되돌리는 게 가능하다.  Merge한 결과는 다음 이미지와 같다.\n2.2 Rebase로 합치기  new-teams 브랜치를 main 브랜치로 rebase  💡 Merge와의 차이점: merge와는 반대로 new-teams로 이동하여 아래 명령어로 병합한다.\n$ git rebase main  소스트리에서 상태를 확인하면 아래 이미지처럼 main 브랜치가 뒤쳐져있다.   main 브랜치로 이동 후, 아래 명령어로 new-teams의 시점으로 앞으로 이동한다.  $ git merge new-teams 위 이미지와 달리 앞으로 이동된 걸 알 수 있다.\n그리고 new-teams 브랜치를 삭제한다.\n 3. 충돌 해결하기 3.1 충돌 상황 만들기   conflict-1, conflict-2 브랜치 생성\n  main branch\n   Tigers의 manager를 Kenneth로 변경 Leopards의 coach를 Nicholas로 변경 Panthers의 coach를 Shirley로 변경 커밋 메시지: Edit Tigers, Leopards, Panthers  conflict-1 branch   Tigers의 manager를 Deborah로 변경 커밋 메시지: Edit Tigers  conflict-2 branch   Leopards의 coach를 Melissa로 변경 커밋 메시지: Edit Leopards  conflict-2 branch   Panthers의 coach를 Raymond로 변경 커밋 메시지: Edit Panthers  3.2 merge 충돌 해결하기   main 브랜치에서 git merge conflict-1 로 병합을 시도하기\n 그러면 아래와 같은 충돌이 발생한다.  $ git merge conflict-1 Auto-merging tigers.yaml CONFLICT (content): Merge conflict in tigers.yaml Automatic merge failed; fix conflicts and then commit the result.  그러면 VSC에서 해당 파일 옆에 !로 뜬다. 해당 파일을 클릭하면 Accept Current Change, Accept Incoming Changes 등을 선택라고 한다. 이 때, 해당 파일은 일반 폴더에서 더블 클릭하여 열면 단순 text로 나타난다. 이를 VSC에서 보기 좋게 표현한 것이다. 충돌되는 부분만 찾고 싶다면 VSC 검색에서 \u0026lt;\u0026lt;\u0026lt;\u0026lt;\u0026lt; 을 입력하여 찾을 수 있다.    Accept Current Change, Accept Incoming Changes 등을 선택하여, 충돌 부분을 수정한 뒤, git add. -\u0026gt; git commit으로 병합을 완료한다.\n 하지만, 당장 충돌 해결이 어려울 경우, 아래 명령어로 merge를 중단한다.  git merge --abort   3.3 rebase 충돌 해결하기   conflict-2에서 git rebase main으로 rebase 시도하면 충돌 발생한다.\n 오류 메시지와 git status 확인한다.   $ git rebase main  Auto-merging leopards.yaml  CONFLICT (content): Merge conflict in leopards.yaml  error: could not apply f8bddeb... Edit Leopards  hint: Resolve all conflicts manually, mark them as resolved with  hint: \u0026#34;git add/rm \u0026lt;conflicted_files\u0026gt;\u0026#34;, then run \u0026#34;git rebase --continue\u0026#34;.  hint: You can instead skip this commit: run \u0026#34;git rebase --skip\u0026#34;.  hint: To abort and get back to the state before \u0026#34;git rebase\u0026#34;, run \u0026#34;git rebase --abort\u0026#34;.  Could not apply f8bddeb... Edit Leopards    $ git status  interactive rebase in progress; onto 528ecc7  ...  Unmerged paths:  (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage)  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to mark resolution)  both modified: leopards.yaml  VS Code에서 해당 부분을 확인한다.    Accept Current Change, Accept Incoming Changes 등을 선택하여, 충돌 부분을 수정한 뒤, git add. -\u0026gt; git commit으로 병합을 완료한다.\n 하지만, 당장 충돌 해결이 어려울 경우, 아래 명령어로 merge를 중단한다.  git rebase --abort   해결 가능 시,\n 충돌 부분을 수정한 뒤 git add .를 입력한다. 아래 명령어를 입력한다.  git rebase --continue  충돌이 모두 해결될 때까지 반복한다.      main에서 git merge conflict-2로 마무리한다.\n main을 앞으로 이동    conflict-1 과 conflict-2를 삭제한다.\n 다 사용한 branch는 바로 바로 지워서 혼란스럽게 만들지 말자.     Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter03/","summary":"branch를 만든 후, 다른 branch로 이동해본다. 또한, 각 branch끼리 합치는 git merge와 git rebase를 실행하면서 CLI 와 Source tree로 branch 변화를 시각적으로 확인해본다. 마지막으로 병합 시 충돌을 해결해본다.","title":"[TIL] Git study: Lecture Chapter 03 - branch"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. 프로젝트의 변경사항을 타임캡슐(버전)에 담고, 묻기 파일을 저장해야 git이 변경사항을 인식할 수 있다.\n1.1 git add   untracked state -\u0026gt; tracked state git add 개별 파일 추가와 전체 파일 추가   git status로 확인하면 Untracked files가 뜬다.\nOn branch master  No commits yet  Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)  .gitignore  lions.yaml  tigers.yaml 이 Untracted files란 **Git의 관리에 들어간 적 없는 파일**을 의미한다.\ntigers.yaml 파일을 수정한다.\ngit add tigers.yaml 로, tigers.yaml의 변경사항을 stage 상태로 올린다.\nOn branch master  No commits yet  Changes to be committed:  (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage)  new file: tigers.yaml  Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)  .gitignore  lions.yaml 이렇게 git add로 개별 파일을 tracked 상태로 바꾼다.\n또한, 모든 파일이 git 관리에 들어가기 위해서는 git add .를 입력한다.\n그러면 아래와 같은 의문이 들 수 있다.\n\u0026lsquo;처음부터 git add . 으로 모든 file을 tracked 상태로 만들면 되지 않느냐?\n여러 file 중 A file만 A project에 필요하고, B file은 B project에 필요하다면 한꺼번에 하는 것이 아닌 개별적으로 해야 한다.\n위와 같은 경우를 제외하고는 통상적으로 한 프로젝트에 관련된 모든 것을 git add .로 추가한다.\n1.2 git commit 다음으로 아래 명령어를 사용하여 타임캡슐을 묻어보자.\ngit commit 이 명령어를 입력하면 밑에 이미지와 같은 Vim 입력모드로 진입한다.\nVim mode에서 명령어는 다음과 같다.\n   작업 Vi 명령어 상세     입력시작 i 명령어 입력 모드에서 텍스트 입력 모드로 전환   입력 종료 ESC 텍스트 입력 모드에서 명령어 입력 모드로 전환   저장 없이 종료 :q    저장 없이 강제 종료 :q! 입력한 것이 있을 때 사용   저장하고 종료 :wq 입력한 것이 있을 때 사용   위로 스크롤 k git log 등에서 내역이 길 때 사용   아래로 스크롤 j git log 등에서 내역이 길 때 사용    출처: 제대로 파는 Git \u0026amp; GitHub - by 얄코 \nFIRST COMMIT 을 입력한 뒤, 저장하고 종료한다.\nFIRST COMMIT은 보통 통상적으로 프로젝트의 첫 버전이 만들어질 때 쓰는 메세지다.\nCOMMIT와 Message를 같이 입력하고 싶으면 아래와 같이 입력한다.\ngit commit -m \u0026#39;FIRST COMMIT\u0026#39; 아래 명령어와 소스트리로 확인한다.\n 종료는 :q를 사용한다.  git log  2. 변경사항 만들기 다음 소단원에서 과거로 돌아가는 실습을 수행하기 위해 몇 가지 변경사항을 만들어보자.\n그 결과, 소스트리의 히스토리에 다음과 같이 결과가 뜰 것이다.\n위로 올라갈수록 최근 commit message다.\n2.1 첫 번째 변경사항   변경사항\n lions.yaml 파일 삭제 tigers.yaml의 manager를 Donald 로 변경 leopards.yaml 파일 추가    git status로 확인\n  On branch master Changes not staged for commit:  (use \u0026#34;git add/rm \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed)  (use \u0026#34;git restore \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)  deleted: lions.yaml  modified: tigers.yaml  Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)  leopards.yaml  no changes added to commit (use \u0026#34;git add\u0026#34; and/or \u0026#34;git commit -a\u0026#34;)  그리고 message와 함께 commit 한다.  git commit -m \u0026#34;Replace Lions with Leopards\u0026#34;  commit과 함께 add를 한 번에 하는 방법도 있다.  하지만 이 경우, 새로 추가된(untracked) 파일이 없을 때만 가능하다.    git commit -am \u0026#34;(메세지)\u0026#34; 2.2 두 번째 변경사항   변경사항\n Tigers의 members에 George 추가 커밋 메세지: Add George to Tigers    add 및 commit\n  git add .  # commit message를 구분한다. git commit -m \u0026#39;add George to tigers\u0026#39; 2.3 세 번째 변경사항  변경사항  cheetas.yaml 추가    git add .  # commit message를 구분한다. git commit -m \u0026#39;Add team Cheetas\u0026#39; 2.4 네 번째 변경사항  변경사항  cheetas.yaml 삭제 Leopards의 manager를 Nora로 수정 panthers.yaml 추가    git add .  # commit message를 구분한다. git commit -m \u0026#39;Replace Cheetas with Panthers\u0026#39;  3. 과거로 돌아가는 두 가지 방법 커밋을 묻어놓은 타임캡슐을 버전이라고 생각하면 다음과 같은 순서로 버전들이 만들어졌다.\n그리고, 안에 무엇이 있는지를 알기 위해서 캡슐마다 작업한 것을 적어서 꼬리표를 달아놓은 것이다.\nGit에서 과거로 돌아가는 방법은 2가지 방법이 있다.\n Reset vs Revert\n- reset: 원하는 시점으로 돌아간 뒤 이후 내역들을 지운다.\n- revert: 되돌리기 원하는 시점의 커밋을 거꾸로 실행한다.\n revert 에 대해 더 설명하자면\n해당 과거 이후의 행적을 삭제하는 것이 아니라, 이 행적을 거꾸로 수행하는 commit을 하나 넣음으로서, 결과적으로 reset과 동일한 결과를 갖는 것이다. 하나 하나를 기록으로 남길 때 사용한다.\n우리가 한 남긴 commit message를 기준으로 Add team Cheetas로 돌아간다고 하자.\nreset은 다음과 같이 움직인다.\n하지만 revert는 이와 다르게 움직인다.\nReplace Cheetas with Panthers, Add team cheetas, Add Georage to Tigers는 그대로 두고, Replace Lions with Leopards만 삭제할려는 상황에서 revert를 사용한다.\n만약 협업 시에 reset으로 특정 history를 삭제하면 이 history를 기반으로 작업한 다른 개발자와 심각한 충돌을 일으킨다. 그래서 한 번 공유된 commit들은 revert를 이용해서 되돌려야 한다.\n 4. 과거로 돌아가기 실습 먼저 .git을 백업 후, 원래 폴더에 있던 .git을 삭제한다.\n그러면 VSC에서 git status를 하면 fatal: not a git repository라는 오류가 발생하겠고, Sourcetree에서도 저장소 없음 이라는 에러가 발생한다.\n다시 원래 폴더에 .git 을 복사 붙여넣기하면 위 에러들은 다 사라진다.\n위 이미지들에서 commit message를 순서대로 확인할 수 있듯이, git log를 통해서도 순서대로 볼 수 있다. git log에서 나가기 위해서는 :q를 입력한다.\n그러면 Add team Cheetas message를 남긴 시점의 과거로 돌아가보자.\n돌아가기 위해서는 위 message를 남긴 시점의 hash 번호가 필요하다.\n$ git log commit 1589712e4324d8a017a8bbc5945e8f98a8085aad (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:30:06 2022 +0900  commit 1589712e4324d8a017a8bbc5945e8f98a8085aad (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:30:06 2022 +0900   replace cheetas with Panthers  commit f86046e7549dde524f3be3729bd9d43281d2a486 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:29:13 2022 +0900   Add team Cheetas hash 번호란 위 log에서 commit 옆에 있는 알파벳과 숫자가 섞인 것을 의미한다.\n4.1 reset 4.1.1 reset으로 돌아가기  git reset \u0026ndash;hard (돌아갈 커밋 해시)\n $ git reset --hard f86046e7549dde524f3be3729bd9d43281d2a486  $ git log commit f86046e7549dde524f3be3729bd9d43281d2a486 (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:29:13 2022 +0900   Add team Cheetas  commit 679d1f1788575666f8b368c67dfbb14f69c6a637 Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:28:44 2022 +0900   add George to tigers git log를 통해 원하는 시점으로 돌아간 것을 알 수 있다.\n이번에는 \u0026lsquo;첫 커밋 시점\u0026rsquo; 으로 돌아가보자.\n$ git reset --hard ed807a60e49db810008b8fcb5fd4deddf4f200ec  $ git log commit ed807a60e49db810008b8fcb5fd4deddf4f200ec (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Wed Jun 22 18:22:01 2022 +0900   first commit 위에서 git log로 확인했듯이 첫 커밋 시점으로 돌아간 걸 알 수 있다.\n소스트리에서도 first commit message만 남겨진 걸 확인할 수 있다.\n4.1.2 reset 전 시점으로 복원하기 실무해서 하는 방식은 아니지만, .git 을 이해해보자는 차원으로 공부한다. 실무에서는 .git 폴더를 직접 건드리는 일은 없다.\n  백업해둔 .git 폴더를 복원\n  git log와 git status로 상태 확인\n .git을 복원하면서 현재 git은 맨 처음 상태에서 파일에 새롭게 변화가 된 것이라고 인식한다. 그래서 아래 명령어로 초기화하자.    git reset --hard로 현 커밋 상태로 초기화\n 커밋 해시가 없으면 마지막 커밋을 가리킨다.    lions.yaml 삭제\n 3번 명령을 실행한 후, git status로 확인해보면 달라진 것을 알 수 있다. lions.yaml은 추가된 것이므로, 삭제해보자.    4.2 revert로 돌아가기 4.2.1 add George to tigers 시점으로 돌아가기 source tree로는 해당 커밋 메세지를 클릭하면 바로 commit hash를 구할 수 있지만, git log를 입력하여 찾아보자.\ngit revert 679d1f1788575666f8b368c67dfbb14f69c6a637 # :wq로 저장 4.2.2 Replace Lions with Leopards의 커밋으로 되돌려보기 이번에는 Replace Lions with Leopards 시점으로 돌아가려고 했으나, 다음과 같이 Error가 발생했다.\n또한, 이 다음 명령 창에는 (master|REVERTING) 로, revert가 진행 중임을 알 수 있다.\n\u0026gt; rudtl@DESKTOP-R1USJ9D MINGW64 ~/Desktop/Dev/GitHub/Git-practice (master) $ git revert 3183106276f5315380d6722971159db9d72e7fd1 CONFLICT (modify/delete): leopards.yaml deleted in parent of 3183106 (Replace Lions with Leopards) and modified in HEAD. Version HEAD of leopards.yaml left in tree. error: could not revert 3183106... Replace Lions with Leopards hint: After resolving the conflicts, mark them with hint: \u0026#34;git add/rm \u0026lt;pathspec\u0026gt;\u0026#34;, then run hint: \u0026#34;git revert --continue\u0026#34;. hint: You can instead skip this commit with \u0026#34;git revert --skip\u0026#34;. hint: To abort and get back to the state before \u0026#34;git revert\u0026#34;, hint: run \u0026#34;git revert --abort\u0026#34;.  \u0026gt; rudtl@DESKTOP-R1USJ9D MINGW64 ~/Desktop/Dev/GitHub/Git-practice (master|REVERTING) 이처럼 에러가 뜨는 것은 컴퓨터가 결정할 수 없기 때문에, 내가 결정을 하라고 알려준 것이다. 그래서 어떻게 해결하면 되는지 hint를 알려주고, 그 후에 git revert --continue 를 하라고 안내해준다.\ngit rm \u0026lt;pathspec\u0026gt; 이란 에 있는 파일을 삭제하라는 명령어다.\n$ git rm leopards.yaml rm \u0026#39;leopards.yaml\u0026#39;  $ git revert --continue  :wq  $ git log commit e27e462a65904a4f3ea890c6389c988423b40990 (HEAD -\u0026gt; master) Author: Jeha00 \u0026lt;rudtls0611@naver.com\u0026gt; Date: Thu Jun 23 11:22:12 2022 +0900   Revert \u0026#34;Replace Lions with Leopards\u0026#34;   This reverts commit 3183106276f5315380d6722971159db9d72e7fd1. 4.2.3 commit을 동반하지 않은 revert revert는 기본적으로 commit을 동반한다. commit 없이 하고 싶다면 아래와 같이 명령어를 입력한다.\ngit revert --no-commit (되돌릴 커밋 해시) 그래서 원하는 다른 작업을 추가한 후, 커밋을 별도로 해야 한다.\n마무리로 reset을 사용해서 revert 전으로 되돌아가보자.\n Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter02/","summary":"git add 와  git commit 으로 변경사항을 stage에 올리고, 저장해본다. 이 과정에서 vim의 몇 가지 명령어를 알아본다.  git reset \u0026ndash;hard / git revert 를 학습하여 과거 시점으로 돌아가는 걸 학습한다.","title":"[TIL] Git study: Lecture Chapter 02 - resest vs revert"},{"content":"0. Introduction  해당 내용은 제대로 파는 Git \u0026amp; GitHub - by 얄코 를 중심으로 Pro git : Second editions을 참고하여 공부한 내용입니다.   1. Git을 배워야 하는 이유  Git을 통해서 내가 만들고 있는 프로젝트의 시간과 차원을 종횡으로 넘나들 수 있다.\n  시간: 프로젝트의 버전을 과거로 되돌리거나 특정 내역을 취소할 수 있다. 차원: 프로젝트의 여러 모드(버전)를 쉽게 전환하고 관리할 수 있다.  1.1 시간 관점에서 Git 장점 모든 버전을 백업하면 프로젝트가 진행될수록 차지하는 용량이 커진다.\nv1 -\u0026gt; v2 -\u0026gt; v3 -\u0026gt; v4 -\u0026gt; v5 순서로 프로젝트가 진행되고 각 버전마다 백업할 때, v2에 잘못된 것을 찾았을 경우 v2부터의 버전을 다 수정해야 한다.\n매우 큰 cost를 지불해야하지만, git은 손쉽게 가능하다.\n1.2 차원과 관련된 Git 장점 회사에 현재 진행되고 있는 프로젝트에 나의 아이디어를 적용하고 싶다면??\n그런데, 회사 프로젝트에 멋대로 논의되지 않는 코드를 추가할 수 없다.\n이런 경우, 메인 프로젝트의 폴더를 복사해서 작업을 하면 되지만, 그러면 용량을 많이 차지할 것이다.\n또한, 이 모든 안들의 변경사항을 모두 메인 프로젝트로 가져와야 한다면 어떻게 해야할까?\n다른 버전의 프로젝트들의 변경사항을 하나 하나 확인해서 가져와야 하는데, 같은 파일에 다른 수정이 되어 있으면 어떻게 해야할까??\n이런 문제 역시 Git에서 쉽게 해결할 수 있다.\n 2. Git과 Sourcetree 설치 Git과 sourcetree 설치 관련 설명은 이 링크 Git, Sourcetree 설치 를 참고한다.\n잘 설치되었는지를 확인하기 위해서 아래 명령어로 확인한다.\n\u0026gt; git --version Git bash를 사용하는 이유 Git bash를 설치하고 사용하는 이유는 Git 사용에 적합한 터미널이고, Linux/Mac(Unix)에서 사용되는 CLI 명령어들을 윈도우에서 사용 가능 하다.\n그래서 VSC 에서 git bash를 사용하도록 다음과 같이 설정한다.\nVSC의 여러 터미널 중 하나를 Git bash로 설정한다.\nVScode에서 Ctrl + Shift + P 를 입력하여, Select Default Profile을 검색하여 선택한다.\nGit bash를 선택한 후, VSC의 termianl에서 + 로 새 창을 열어서 기본으로 Git Bash가 설정된 것을 확인한다.\nCLI vs GUI 실무에서 GIt을 매일 사용하는 사람으로서 이 2가지를 다 사용하는데, 어떻게 나눠서 사용하면 될까???\nGit에서 뭔가를 실행하기 위한 어떤 명령들을 사용 할 때는 CLI 를 사용한다.\n프로젝트의 상태를 Git상에서 자세히 살펴볼 때 는 Source Tree 를 사용한다.\n하지만, 학습자로서는 CLI를 먼저 학습한다.\nGUI는 편하지만 Git의 기능을 모두 사용할 수 없다.\n그래서 CLI로 다 익혀놓은 후, Git을 잘 알게되면 GUI와 혼용해서 사용하는 방식으로 학습한다.\n 3. Git 설정 vs 프로젝트 관리 시작하기 3.1 Git 최초 설정 3.1.1 Git 전역으로 사용자 이름과 이메일 주소를 설정 이 설정은 Github 계정과는 별개로 나중에 나중에 협업할 때 이 작업을 누가했는지 알아서 연락하기 위함이다.\nWhat Is Git 을 참고한다.\n\u0026gt; git config --global user.name \u0026#34;(본인 이름)\u0026#34;  \u0026gt; git config --global user.email \u0026#34;(본인 이메일)\u0026#34;  \u0026gt; git config --global user.name  \u0026gt; git config --global user.email 3.1.2 기본 branch명 변경 기본 branch명이 master 였지만, 이 용어가 옛날에 흑인 노예의 주인을 연상시켜서 main으로 변경하고 있다.\n그래서 Github 또한 기본 branch 명을 master로 바꿨다.\n\u0026gt; git config --global init.defaultBanch main 3.2 프로젝트 생성 \u0026amp; Git 관리 시작 git basics_1을 참고한다.\n 4. Git에게 맡기지 않을 것들 Git의 관리에서 배제할 파일/폴더들은 어떠한 이유로 배제하고, 어떻게 배제할까??\n  Git의 관리에서 특정 파일/폴더를 배제해야 할 경우\n  포함할 필요가 없을 때\n 자동으로 생성 또는 다운로드 되는 파일들 (빌드 결과물, 라이브러리)    포함하지 말아야 할 때\n 보안상 민감한 정보를 담은 파일      배제하는 방법으로 .gitignore 파일을 사용하여 배제할 요소들을 지정할 수 있다.\n각 언어의 framework에도 이 파일로 무시해도 되는 파일들이 적혀있다.\n.gitignore 형식 자세한 형식은 https://git-scm.com/docs/gitignore 을 참조한다.\n프로젝트 때마다 위 사이트를 참조하여 작성한다.\n# 이렇게 #을 사용해서 주석을 단다.  # 모든 file.c를 무시 file.c  # 최상위 폴더의 file.c를 무시 /file.c  # 확장자가 .a인 모든 파일 무시 *.a  # 확장자가 .a 여도 lib.a는 무시하지 않는다. !lib.a  # logs란 이름의 파일 또는 폴더와 그 내용들 무시 logs  # logs란 이름의 폴더와 그 내용들을 무시 logs/  # logs 폴더 바로 안의 debug.log와 .c 파일들 무시 logs/debug.log logs/*.c  # doc directory 아래의 모든 .pdf 파일을 무시 doc/**/*.pdf  # logs 폴더 바로 안, 또는 그 안의 다른 폴더(들) 안의 debug.log 무시 log/**/debug.log \\ .gitignore 사용해보기 폴더에 secrets.yaml 을 생성한다.\n다음과 같은 내용을 가진다.\nid: admin pw: 1234abcd git status로 상태를 확인한다.\nOn branch master  No commits yet  Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)  lions.yaml  secrets.yaml  tigers.yaml .gitignore을 생성하여, 그 안에 secrets.yaml 을 입력한다.\n다시 git status로 상태를 확인한다.\nOn branch master  No commits yet  Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)  .gitignore  lions.yaml  tigers.yaml secrets.yaml이 없다는 걸 확인할 수 있다.\n이처럼 .gitignore.yaml을 통해서 git의 관리 하에 두지 않을 것들을 정할 수 있다.\n다음 chapter 내용은 위 상태에서 이어서 진행된다.\n Reference  제대로 파는 Git \u0026amp; GitHub - by 얄코  Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/lec_chapter01/","summary":"Git을 배워야하는 이유와 Git의 관리에서 벗어나도록 하는 .gitigonre에 대해 알아본다.","title":"[TIL] Git study: Lecture Chapter 01"},{"content":"2.1 Git 저장소 만들기  Git 저장소를 만드는 방법에는 2가지가 있다.  기존 directory를 Git 저장소로 만들기 기존 저장소를 clone 하기    2.1.1 기존 directory를 Git 저장소로 만들기  git init\ngit add\ngit commit -m \u0026lsquo;message\u0026rsquo;\n  기존 project를 Git으로 관리하고 싶을 때, 프로젝트의 directory 경로로 이동해서 아래 명령을 실행한다.  \u0026gt; git init \u0026gt; git add . \u0026gt; git commit -m \u0026#39;Initial project version\u0026#39;  git init은 .git 이라는 하위 directory를 만든다. .git directory 안에는 저장소에 필요한 뼈대 파일이 존재한다. 하지만 .git이 있다고 프로젝트의 파일을 관리하지 않는다. Git이 프로젝트를 관리하기 위해서는 저장소에 파일을 추가하고, 커밋해야 한다.   주의사항: .git 폴더를 지우면 Git 관리내역이 삭제되어 과거의 내역으로 돌아갈 수 없다. (현 파일들은 유지)\n 2.1.2 기존 저장소를 clone 하기  git clone [url]\n  언제 clone하는가?  다른 project에 참여하려거나 (contribute) Git 저장소를 복사하고 싶을 때     git clone은 project history를 전부 복사한다.  그래서, 서버의 디스크가 망가져도 client 저장소 중에서 아무거나 하나 가져와 복구하면 된다. (서버에만 적용하는 설정은 복구 불가능)     git-practice 코드를 복사하려는 상황이라면  \u0026gt; git clone https://github.com/git-practice/git-practice  이 명령으로 git-practice라는 directory를 만들고, 그 안에 .git directory를 만든다. 그리고, 저장소의 데이터를 모두 가져와서 최신 버전으로 checkout 해놓는다.   2.2 수정하고 저장소에 저장하기   \u0026lsquo;2.1 저장소 만들기\u0026rsquo; 를 통해서\n Git 저장소를 하나 만들었다. 만든 Git 저장소를 Working directory에 checkout 했다.    Chapter 2.2 내용을 들어가기에 앞서 한 가지 내용을 정리하겠다.\n  Working directory 의 모든 파일은 Tracked 와 Untracked 로 나눠진다.\n Tracked 파일은 Unmodified , Modified 그리고, Staged 로 나눠진다. 나머지 파일은 다 Untracked 상태다. Untracked 상태는 snapshot에도, staging area에도 포함되지 않은 파일이다.    처음 저장소를 clone 하면 이 저장소 안에 있는 파일은 checkout 하고 나서 아무것도 수정하지 않았기 때문에, Tracked 상태이면서 Unmodified 상태다.\n     다음으로 \u0026lsquo;2.2.1 파일의 상태 확인하기\u0026rsquo; ~ \u0026lsquo;2.2.3 Modified 상태의 파일을 Stage 하기\u0026rsquo; 내용을 정리하겠다. \u0026lsquo;2.2.1 파일의 상태 확인하기\u0026rsquo; 에서는 git status 명령어를 배운다. \u0026lsquo;2.2.2 파일을 새로 추적하기\u0026rsquo; 와 \u0026lsquo;2.2.3 Modified 상태의 파일을 Stage 하기\u0026rsquo; 에서는 git add 명령어를 배운다.  2.2.1 git status  git status 명령어로 파일의 상태를 먼저 확인하자.  \u0026gt; git status On branch master nothing to commit, working directory clean   위 코드의 의미는 다음과 같다.\n 현재 branch는 기본 branch인 master다. 현재 Tracked 나 Modified 상태인 파일이 없다.    만약 .git을 삭제한 후, git status를 입력하면, 다음과 같은 안내문이 뜬다.\n  \u0026gt; fatal: not a git repository (or any of the parent directories): .git  git이 관리하지 않는다는 의미다. 그래서 .git을 삭제하면 안된다.   git status는 현재 파일의 상태를 확인하기 위해 사용되는 명령어다.\n 2.2.2 git add  git add 개념을 설명해보겠다.  \u0026gt; echo \u0026#39;My project\u0026#39; \u0026gt; README.md \u0026gt; git status On branch master Untracked files:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to include in what will be committed)   README.md  nothing added to commit but untracked files present (use \u0026#34;git add\u0026#34; to track)  echo 'My project' \u0026gt; README.md 명령어는 \u0026lsquo;My project\u0026rsquo;라는 내용을 가진 README.md 파일을 만들라는 명령어다. 파일을 만든 후, git status 실행하면 Untracked files 안에 새로 만든 파일이 있다는 걸 확인할 수 있다. 이는 README.md파일이 Untracked 상태임을 말한다. Git은 Untracked 상태의 파일을 아직 snapshot에 존재하지 않는 파일로 인식한다. 그러면 Untracked 상태를 Trancked상태로 바꿔보자.  \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed:  (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage)   new file: README.md  새로 생긴 파일의 상태가 Changes to be committed 안으로 들어왔다. 이는 Staged 상태임을 의미한다. 위에 개념에서 언급했듯이 Staged는 Tracked 상태에 포함되므로, Tracked 상태이면서 Staged 상태다. 이 상태에서 커밋을 하면 git add를 실행한 시점의 파일이 커밋되어, snapshot이 저장되어 저장소 히스토리에 남는다.   git add 명령어는 새로운 파일을 추적할 때 사용되는 명령어다. 그리고, Untracked상태에서 Tracked 상태로 이동된다.\n  Tracked 상태인 README.md 파일을 수정한 후, git status 를 입력해보자.  \u0026gt; git status On branch master  Changes not staged for commit:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed)  (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)   modified: README.md  README.md 파일은 Changes to be committed: 에 있다가 Changes not staged for commit: 으로 옮겨졌다. 이는 수정한 파일이 Tracked 상태이지만, Staged 상태는 아니라는 것이다. 즉, 수정된 파일이므로 Modified 상태임을 말한다. Modified 상태에서 Staged 상태로 바꿔보자.  \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed:  (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage)   modified: README.md  Changes to be committed: 로 옮겨졌다. Tracked 상태이면서 Staged 상태로 되었다. 이는 커밋을 실행할 때 이 파일이 포함된다는 걸 의미한다. 하지만, 아직 더 수정해야 한다는 걸 알게 되어 바로 커밋하지 못하는 상황이라고 생각해보자. 수정하고 나서 git status를 입력했다.  \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed:  (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage)   modified: README.md  Changes not staged for commit:  (use \u0026#34;git add \u0026lt;file\u0026gt;...\u0026#34; to update what will be committed)  (use \u0026#34;git checkout -- \u0026lt;file\u0026gt;...\u0026#34; to discard changes in working directory)   modified: README.md  Staged 상태이면서 Unstaged 상태로 동시에 나온다. 이게 가능한 이유는 git add 명령을 실행하면 바로 Staged 상태로 만든다는 걸 위 예시를 통해 알았다. git add 했을 때의 시점에서의 파일이 Staged에 오른다. git add 후에 다시 수정을 했고, 수정한 후 git add를 하지 않았기 때문에 unstaged 상태로도 나온다. 즉, git add 명령을 실행한 후에 또 파일을 수정하면 git add 명령을 다시 실행해서 최신 버전을 Staged 상태로 만들어야 한다.  \u0026gt; git add README.md \u0026gt; git status On branch master Changes to be committed:  (use \u0026#34;git rest HEAD \u0026lt;file\u0026gt;...\u0026#34; to unstage)   modified: README.md  Changes not staged for commit:에서 Changes to be committed:로 옮겨졌다. 최신 상태가 Staged에 올랐다는 걸 확인할 수 있다.   git add 명령어는 새로운 파일을 추적할 때 뿐만 아니라, 수정한 파일을 Staged상태로 만들 때에도 사용된다.\ngit add 명령어는 프로젝트에 파일을 추가하는 라기보다는, 다음 커밋에 추가하는 명령어다.\n  Reference  Pro git : Second editions  ","permalink":"http://jeha00.github.io/post/git/1_gitbasics/","summary":"첫 번째, git 저장소 만들기. 두 번째, git add 와 git status 명령어를 통해서 Git introduction에서 알아본 git의 3가지 상태와 3가지 단계를 이해해본다.","title":"[Pro git 2/E study] Git basics"},{"content":"0. Introduction  Pro git : Second editions 자체 스터디 내용이다. 이번 장은 Git을 처음 접하는 분들에게 필요한 내용이다. 이 챕터를 통해서 Git 탄생 배경, 사용 이유를 알 수 있다. 지속적인 복습을 위해 만든다.   1. What is Version Control System ??? Version Control System이란 무엇이고, 왜 필요할까??\n 버전 관리 시스템(VCS) : 파일의 변화를 시간에 따라 기록했다가, 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템\n VCS를 통해서 큰 노력 없이\n 각 파일을 이전 상태로 되돌릴 수 있다. 프로젝트를 통째로 이전 상태로 되돌릴 수 있다. 시간에 따라 수정 내용을 비교할 수 있다. 누가 문제를 일으켰는지 추적할 수 있다. 누가 언제 만들어낸 이슈인지 알 수 있다. 파일을 잃어버리거나 잘못 고쳤을 때도 쉽게 복구할 수 있다.   VSC의 종류에는 LVCS, CVCS, DVCS가 있다.\n 각 종류에 대해 알아보자.\n1.1 Local Version Control System (LVCS, 로컬 버전 관리) [LVCS 탄생 계기]\n 많은 사람은 버전을 관리하기 위해 directory로 파일을 복사하는 방법을 사용한다. 하지만 이러한 방식은 잘못되기 쉽기 때문에, Local Version Control System을 만들었다. 간단한 DB를 사용해서 파일의 변경 정보를 관리했다.  [LVCS의 한 예: RCV]\n 많이 사용하는 VCS 중 RCS (Revision Control System)가 오늘날까지도 많은 회사에서 사용하고 있다. RCS는 Mac OS에서도 개발 도구를 설치하면 함께 설치되며, 기본적으로 Patch Set(: 파일에서 변경되는 부분)을 관리한다. Patch Set을 통해 모든 파일을 특정 시점으로 되돌릴 수 있다.  1.2 Central Version Control System (CVCS, 중앙 집중식 버전 관리) [CVCS 탄생 계기]\n 위의 LVCS의 장점에도 불구하고, LVCS는 다른 개발자와 협업 시에 사용할 때에는 적절한 tool이 아니었다. 그래서 중앙 집중식 버전 관리 (CVCS, Central Version Control System) 를(을) 개발했다.  [CVCS 특징과 장점]\n CVCS는 LVCS에 비해 장점이 많다. 파일을 관리하는 서버가 별도로 있고, 클라이언트가 이 중앙 서버에 파일을 받아서 사용(checkout)하기 때문에,  누가 무엇을 하고 있는지 알 수 있다. 관리자의 입장에서는 누가 무엇을 할지 꼼꼼히 관리할 수 있다. 모든 client의 local DB를 관리하는 것보다 VCS 하나를 관리하기가 훨씬 쉽다.    [CVCS 단점]\n 파일을 관리하는 중앙 서버가 별도로 있고, client가 checkout 방식으로 사용하고, 저장소를 전부 복제하는 게 아니기 떄문에,  서버가 다운되는 동안, 다른 사람과 협업할 수 없고, 백업할 방법도 없다. 중앙 DB가 있는 하드디스크에 문제가 생기면 project의 모든 history를 잃는다. (client가 가진 snapshot 제외)      checkout: git checkout으로 사용되는 것처럼 사용할 branch를 지정하여 연결하는 걸 의미한다. snapshot: 특정 시점에서 파일, 폴더 또는 워크스페이스의 상태   1.3 Distributed Version Control System (DVCS, 분산 버전 관리 시스템) [DVCS 장점]\n 첫 번째, Git과 같은 DVCS는 단순히 파일의 마지막 스냅샷을 checkout하지 않고, 저장소를 전부 복제한다.  그래서 서버에 문제가 생기면 작업을 할 수 없었던 CVCS와는 달리, 이 복제물로 다시 작업을 시작할 수 있다. Client 중에서 아무거나 골라도 서버를 복원할 수 있다. 모든 checkout이 모든 데이터를 가진 백업이라는 의미다.   두 번째, 대부분의 DVCS 환경은 remote repository가 존재한다.  그래서, 사람들은 동시에 다양한 그룹과 방법으로 협업이 가능하다. 계층 모델 같은 CVCS으로는 할 수 없는 workflow를 다양하게 사용할 수 있다.     2. Histroy summaries of Git  리눅스(Linux) kernel은 굉장히 규모가 큰 open source project였다. 1991~2002년 단순 압축 파일로만 관리하다가 2002년 BitKeeper라 불리는 DVCS를 사용하기 시작했다. 그러다 2005년에 BitKeepr가 유료화가 되었다. Linux는 커뮤니티이고, BitKeeper는 이익을 추구하는 회사이기 때문에 이해관계가 달랐다. 이 계기로 Linux 개발 커뮤니티가 자체 도구를 만들었다. 그 도구가 Git이다. Git은 아래와 같은 목표로 세워져서 지금도 유지하고 있다.  빠른 속도 단순한 구조 비선형적인 개발 (동시다발적인 branch) 완벽한 분산 속도나 데이터 크기 면에서 대형 proejct에도 유용할 것    3. Key point of Git : 데이터를 다루는 방식의 차이 3.1 Snapshots, Not Differences VCS들과 Git의 가장 큰 차이점은 데이터를 다루는 방식에 있다.\n VCS는 각 파일의 변화를 시간 순으로 관리하면서 파일들의 집합을 관리한다. Git은 데이터를 파일 시스템 스냅샷으로 취급하여, 각 파일의 변화가 아닌 파일 전체를 스냅샷으로 찍어낸다.  그래서 Git은 데이터를 snapshot stream처럼 취급한다. 그래서 Git은 프로젝트의 상태를 저장할 때마다, 파일이 존재하는 그 순간을 중요하게 여긴다. 그래서 Git은 파일이 달라지지 않으면 성능을 위해 새로 저장하지 않는다.     3.2 거의 모든 명령을 로컬에서 실행 Git은 거의 모든 명령이 저장소 전체를 복사해서 로컬 파일과 데이터만 사용하는 방식이기 때문에,\n 네트워크의 속도에 영향을 받는 다른 CVCS보다 매우 빠른 속도를 가진다. project의 history를 조회할 때, 서버 없이 local DB에서 조회하기 때문에 매우 빠르다. 어떤 파일의 현재 버전과 한 달 전의 상태를 비교하고 싶을 때도 이 두 상태를 로컬에서 찾는다. 오프라인 상태거나 네트워크와 연결할 수 없어도 막힘 없이 일할 수 있다.  3.3 Git의 무결성: checksum 방식 체크섬(checksum)이란\n 40자 길이의 16진수 문자열인 SHA-1 해시를 사용하여 만든다. Git에서 사용하는 가장 기본적인(atomic) 데이터 단위이다. Git의 기본 철학이다.   SHA-1: 24b9da6552252987aa493b52f8696cd6d3b00373 같은 40자 길이의 16진수 문자열이다.\n 그래서 Git은 checksum을 사용하여 (중심으로)\n 데이터를 저장하고 관리한다. 그래서 체크섬 없이는 어떠한 파일이나 디렉터리도 변경 할 수 없다. 모든 것을 식별한다. 파일을 저장하고, 파일 이름으로 저장하지 않는다.  3.4 Git은 데이터를 추가할 뿐 Git은 무엇을 하든 Git database에 데이터를 추가한다.\n 그래서 데이터를 되돌리거나 삭제할 방법이 없다. 또한, 다른 VCS처럼 commit하지 않으면 변경사항을 잃어버릴 수 있다. 하지만, commit 하면 데이터를 잃기 어렵다.  3.5 Git의 3가지 상태와 3가지 단계  이 부분에 대한 자세한 내용은 Chapter 2를 참고한다.\n   Git 파일은 3가지 상태(: Commited, Modified, Staged) 로 관리한다.\n Commited: 데이터가 local database에 안전하게 저장된 상태 Modified: 수정한 파일을 아직 local database에 커밋하지 않은 상태 Staged: 현재 수정한 파일을 곧 커밋할 것이라고 표시한 상태    - 이 3가지 상태는 Git project의 3가지 단계(: Working directory, Staging Area, .git Directory(Repository)와 연결된다.\n  Git directory는\n Git의 핵심이다. Git이 project의 meta data와 객체 datebase를 저장하는 곳이다. 다른 컴퓨터에 있는 저장소를 clone할 때 만들어지는 곳이다. 파일들이 commited된 상태다.    Working directory는\n project의 특정 버전을 checkout한 것이다. Git directory 안에 압축된 database에서 파일을 가져와서 만든 것이다. 파일을 수정하는 공간이므로, checkout하고 나서 수정했지만, 아직 staging area에 추가하지 않은 상태다.    Staging Area는\n Git directroy에 있다. 단순한 파일이고 곧 커밋할 파일에 대한 정보를 저장한다. 파일들이 Staged 상태다.    위 개념들을 토대로 Git으로 하는 기본적인 일은 아래와 같다.\n working directory에서 파일을 수정한다. Staging area에 파일을 stag해서 커밋할 snapshot을 만든다. Staging Area에 있는 파일들을 커밋해서 Git directroy에 영구적인 snapshot으로 저장한다.     4. CLI  Git은 CLI (Command Line Interface)와 GUI (Grapic User Interface)로 사용할 수 있다. 하지만, Git의 모든 기능을 지원하는 것은 CLI 뿐이다. CLI를 사용할 줄 알면 GUI를 사용할 수 있지만, 반대는 성립되지 않는다.   5. Git initail setup   사용자 정보 등록은 다음 명령어로 한다.\n --global 은 전역 설정하는 명령어로, 딱 한 번만 하면 된다. git config --global user.name \u0026quot;user-name\u0026quot; git config --global user.email \u0026lt;user-email\u0026gt; 만약, 프로젝트마다 다른 이름과 이메일 주소를 사용하고 싶으면 --global전역 명령어를 빼고 입력한다.    설정 확인 방법은 git config --list 명령을 실행한다.\n Git은 같은 키를 여러 파일에서 읽기 때문에 같은 키가 여러 개 있을 수 있다. 그러면 Git은 나중값을 사용한다. git config \u0026lt;key\u0026gt; 명령으로 특정 Key에 대해 어떤 값을 사용하는지 확인할 수 있다. git config user.name    명령어 도움말 이 필요할 때는 방법은 3가지다.\n git help \u0026lt;verb\u0026gt; git \u0026lt;verb\u0026gt; --help main git-\u0026lt;verb\u0026gt; 예를 들어 git help config를 실행하면 config 명령에 대한 도움말만 볼 수 있다.     Reference  Pro git : Second editions 더북(TheBook:Git 교과서) git snapshot  ","permalink":"http://jeha00.github.io/post/git/0_whatisgit/","summary":"Git이란 무엇이고, Git이 탄생하기까지의 VCS의 histroy에 대해 간략히 알아본다. 또한, Git의 3가지 상태와 3가지 단계를 학습한다. 마지막으로 Git의 사용자 등록 방법과 화인 방법을 알아본다.","title":"[Pro git 2/E study] What is Git ?"},{"content":"0. Introduction  해당 내용은 생활코딩 - DB 와 갖고노는 MySQL 데이터베이스 by 얄코를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 데이터는 왜 중요할까???  데이터를 가공해서 다양한 일을 할 수 있기 때문이다.\n 점점 시간이 흘러가면서 데이터의 중요성은 커지고 있다. 왜 데이터는 중요할까?? 이 데이터를 가공해서 매우 다양한 일들을 할 수 있기 때문이다. 하지만, 크게 2가지로 나눌 수 있다고 생각한다.\n 인터넷에 연결된 앱과 웹을 통한 지식 전파 빅데이터나 인공지능 기술을 통해서 데규모 데이터로부터 통찰력 있는 데이터 추출  그러면 이 데이터 정보의 저장 과정 histroy를 알아보자.\n 2 데이터 정보의 저장 과정 history 2.1 자유로운 형식의 file 데이터 정보의 저장 형태인 file은 자유로운 형식 이란 장점이 있지만, 이 장점이 단점으로서 작용된다.\nfile은 운영체제마다 파일 기능을 제공하기 때문에, 어디에서나 사용할 수 있고, 배우기 쉽고, 입력과 읽는 속도도 매우 빠르다.\n즉, 자유롭다.\n하지만, 이런 자유로운 형식으로 인해 SW를 안정적으로 관리하기가 어렵다.\n예를 들어서 각 데이터의 형식이 달라서 항목명이 서로 다르기 때문에, 관리하기가 어렵다. 이 데이터의 형식이 다르다는 문제로 인해 예기치 못한 다양한 오류들이 발생한다.\n2.2 일정한 형식의 spreadsheet 이 한계를 극복하기 위해 나타난 게 바로 table로 된 spread sheet 다.\n형식이 일정하기 때문에, 여러 사람들이 공유해도 문제가 생기지가 않는다.\nspreadsheet의 예로는 우리가 알고 있는 마이크로소프트의 엑셀, 구글의 구글 시트가 있다.\n2.3 DB와 DBMS 이 table 형식의 data들을 특정 소프트웨어나 프로그램에 종속되지 않고 독립되어 정보를 저장하는 장소를 바로 DB(DataBase) 라 한다. 이 DB는 단지 데이터 저장소이므로 별다른 기능이 없다.\n그리고, 이 DB에 여러 기능들을 넣어서 만들어 **DB를 관리 및 운영하도록 만든 소프트웨어**를 DBMS(DataBase Management System, 데이터베이스 관리 시스템) 라 한다.\nDBMS에서 DB로부터 다른 정보를 넣고, 빼는 등 조작하여 손쉽게 사용되도록 하는 도구가 구조화된 질의 언어인 SQL(Structured Query Language) 다. DBMS에서 DB를 관리하는 방식이 SQL이라고 생각하면 된다.\n이 SQL은 자바, 파이썬, 자바스크립트 같이 범용 프로그래밍 언어가 아닌 HTML처럼 특정 영역에 사용되는 Domain-specific language 로, 도메인 특화 언어다.\n이 DBMS 소포트웨어의 종류에는 MySQL, Oracle, SQL Server, PostgreSQL, MongoDB 등이 있다.\n2.4 관계형과 비 관계형 DBMS 이 DBMS는 관계형 데이터베이스(RDBMS, Relational DataBase Management System) 과 비관계형 데이터베이스(Non-relational DBMS) 로 나눠진다. 여기서 비관계형 데이터 베이스는 NoSQL 이라고도 불린다.\nRDBMS 란 하나의 table이 아닌 여러 개의 table로 나눠 데이터 중복을 방지하고, 자신이 원하는 데이터 정보를 추출하기 하기 위해 SQL을 사용하여 여러 table에 있는 정보들을 조작하여 새로운 테이블을 만드는 데이터 베이스 관리 시스템을 말한다.\nNoSQL 은 일정한 형식은 없지만, 매우 빠르게 관리할 수 있다고 한다.\nRDBMS 의 종류에는 대표적으로 Oracle, MySQL, PostgreSQL 등이 있고, NoSQL 에는 대표적으로 MongoDB가 있다.\n 3. 데이터 베이스의 본질: CRUD  DB의 본질은 CRUD다.\n 어떤 데이터베이스를 만나든 제일 먼저 해야 할 것은 데이터베이스의 데이터를 어떻게 입력하고 어떻게 출력하는가를 따져봐야한다.\n즉 입력(Input: 데이터의 생성(Create), 수정(Update), 삭제(Delete)) 과 출력((Output) : 데이터의 읽기(Read)) 이다.\n이 입출력을 합쳐서 CRUD(Create, Read, Update, Delete) 라 한다. 그 외 복잡한 기능들은 CRUD를 보좌하는 부가적인 기능들에 불과하다.\n 4.어떤 DB로 시작할 것인가?  결론: MySQL부터 시작 후, MongoDB를 학습해보자.\n 생활코딩에 따르면 비관계형 데이터베이스를 먼저 학습하기보다는 먼저 RDBMS에서 하나 배운 후, RDBMS가 아닌 것을 배우기를 강하게 추천한다고 한다. 그리고, 비관계형 데이터 베이스를 꼭 배우라고 한다.\n그래서 관계형 데이터베이스부터 학습하기로 결정했다. 그러면 여러 종류의 RDBMS에 대해 정리해보자.\n아래 내용은 생활 코딩에서 언급한 것을 단순 정리한 내용이다.\n  Oracle\n 아주 오랫동안 데이터베이스 시장에서 절대강자로 군림해왔던 데이터베이스 주로 관공서, 큰 기업, 정부에서 많이 사용한다.  이유 : 비싸다. 데이터베이스 기술 지원 : 컨설턴트의 컨설팅 비용도 비싸다. 자금력 있는 기업이나 정부에서 많이 사용한다.   개인적으로 사용하고 싶거나 작은 회사에서 쓰려고 하거나 큰 회사라고 하더라도, 금융 같이 신뢰성이 굉장히 높은 데이터를 다루는 경우 가 아니라면 오라클 사용을 비추한다고 한다.    MySQL\n 무료, 오픈소스 관계형 데이터베이스를 이용하고 싶으면서 자금이 많지 않아서 개인적으로 사용하고 싶거나 작은 회사, 또는 SNS와 같이 대규모의 데이터가 생성이 되지만 데이터의 신뢰성은 아주 중요하지는 않은 기업에서는 아주 좋은 선택사항이다. 초심자에게 추천    MongoDB\n 2010년부터 RDBMS가 아닌 데이터베이스들이 쏟아져 나왔다.  RDBMS의 여러 가지 장점으로 인해 RDBMS를 사용했다.  개발자 입장에서는 어떤 회사를 가던 RDBMS를 알고 있으면 새로 배울 필요가 없다. 자연스럽게 RDBMS를 쓸 줄 아는 수많은 개발자들이 생겨났고 회사 입장에서는 인력을 구하기 쉬운 RDBMS 선택한다.   하지만, 다음과 같은 변화가 일어났다.  SNS와 IoT의 등장, 많은 사람들이 프로그래밍을 할 줄 알면서, 수 많은 데이터들와 다양한 종류의 데이터들이 쏟아진다. RDBMS에 모든 데이터베이스가 낑겨 들어가게 되면 거기에 잘 맞지 않는 데이터베이스 입장에서는 RDBMS가 일종의 억압으로서 작용할 수도 있다. 그래서 2010년부터 NoSQL이라는 흐름이 나타났고 NoSQL이라는 흐름에서의 가장 중요한 특징은 RDBMS가 아닌 다양한 데이터베이스가 폭발적으로 만들어지고 있고 성장하고 있다는 것         Reference  생활코딩 - DB 갖고노는 MySQL 데이터베이스 by 얄코  ","permalink":"http://jeha00.github.io/post/db/db_introduction/","summary":"DB, SQL, RDBMS, NoSQL이란 각각 무엇이고, 앞으로 DB를 무엇부터 학습할지에 대한 이유를 서술했다.","title":"[TIL] DB Introduction"},{"content":"0. Introduction  이번 chapter의 학습은 Do it! 자료구조와 함께 배우는 알고리즘 입문로부터 학습했습니다. 더 자세한 내용과 관련 내용의 코드는 위 서적의 출판사 사이트에서 확인하실 수 있습니다.   1. 재귀 알고리즘 이번에는 재귀 알고리즘에 대해 알아보겠다.\n여기서 재귀란 **어떠한 이벤트에서 자기 자신을 포함하고 다시 자기 자신을 사용하여 정의되는 경우**로서, recursion 이라 합니다.\n이 관점에서 자연수를 재귀적 관점에서 다음과 같이 정의할 수 있다.\n\u0026lsquo;1은 자연수이고, 자연수의 바로 다음 수도 자연수다.\u0026rsquo;\n무한히 존재하는 자연수를 재귀적 정의(recursive definition) 를 사용하여 간단히 정의했다.\n이처럼 재귀 를 사용하며 프로그램을 간결하고 효율성 좋게 작성할 수 있다.\n대표적인 예로 factorial이 있다.\n10! = 10 x 9 x 8 x 7 x 6 x 5 x 4 x 3 x 2 x 1\n코드로는 다음과 같다.\n\u0026gt; def factorial(n: int) -\u0026gt; int: \u0026gt; if n \u0026gt; 0: \u0026gt; return n * factorial(n-1) \u0026gt; else: \u0026gt; return 1 이렇게 자신과 똑같은 함수를 호출하는 걸 재귀 호출(recursive call) 이라 한다.\n 파이썬에서는 팩토리얼 값을 구하는 표준 라이브러리로 math 모듈에서 factorial() 함수를 제공한다. math.factorial(x)를 하면 정수 x의 팩토리얼 값을 제공한다.\n 1.1 직접 재귀와 간접 재귀 하지만, 이 재귀도 두 가지로 나눠지는데 직접(direct) 재귀 와 간접(indirect) 재귀 로 나눠진다. 직접 재귀는 자신과 똑같은 함수를 반복해서호출하는 방식이며, 간접 재귀는 자신이 아닌 다른 함수를 호출하지만 이 다른 함수를 통해서 자신을 다시 호출하는 함수다. 아래 이미지를 참고하자.\n1.2 유클리드 호제법(Euclidean algorithum) 재귀 알고리즘을 통해서 최대 공약수(GCD, Greater Common Divisor)를 재귀적으로 구하는 방법도 있다.\n두 정수 x와 y의 최대 공약수를 구하는 함수를 gcd(x, y)라고 할 때, 최대 공약수는 다음과 같이 구별할 수 있다.\ny가 0이면 x 이고, y가 0이 아니면 gcd(y, x % y)이다. 이 알고리즘을 유클리드 호제법이라 한다.\n 파이썬에서는 최대 공약수를 구하는 표준 라이브러리로 math module에서 gcd() 함수를 제공한다. math.gcd(a, b)는 a와 b의 최대 공약수를 반환한다.\n  2. 재귀 알고리즘 분석 2.1 재귀 알고리즘의 2가지 분석 방법 \u0026gt; def recure(n:int) -\u0026gt; int: \u0026gt; \u0026#34;\u0026#34;\u0026#34;순수한 재귀 함수 구현\u0026#34;\u0026#34;\u0026#34;  \u0026gt; if n \u0026gt; 0: \u0026gt; recur(n-1) \u0026gt; print(n) \u0026gt; recur(n-2)  \u0026gt; x = int(input(\u0026#39;정숫값을 입력하세요. : \u0026#39;))  # 예를 들어 3을 입력했다고 하자. \u0026gt; recure(x)  1 2 3 1 이처럼 함수 안에서 재귀 호출을 2번 이상하는 함수를 순수한(genuinely) 재귀 라고 하는데, 이 함수를 아래 2가지 방법으로 분석해보겠다.\n하향식 방법(top-down) 방법과 상향식(bottom-up) 방법으로 분석하는 방법이다.\n\u0026lsquo;하향식 방법\u0026rsquo;에 대해 먼저 이야기 해보자.\n**하향식 방법**이란 아래 이미지처럼 함수의 제일 첫 번째 호출부터 시작하여 계단식으로 자세히 조사해 나가는 방법 을 말한다.\n이렇게 같은 함수를 여러 번 호출할 수 있으므로, 하향식 방법은 결코 효율적인 방법이 아니다.\n다음으로 \u0026lsquo;상향식 방법\u0026rsquo;으로 분석해보자.\n위에 recure 함수를 예로 들어 분석하자면 다음 이미지와 같다.\n어디가 제일 바닥인지 알고, 이 밑에서부터 최초 호출 방향인 위로 접근하는 방법이다.\n2.2 재귀 알고리즘의 비재귀적 표현 재귀 알고리즘을 재귀적 표현 없이 구현하기 위해서는 2가지 방법이 있다.\n꼬리 재귀(tail recursion)를 제거하든가 또는 완전히 재귀를 제거하든가 이다.\n2.2.1 꼬리 재귀 제거 꼬리 재귀를 제거하는건 끝 부분의 재귀를 제거하는 것이다.\nrecur(n-2)의 의미는 n의 값을 (n-2)로 업데이트하고, 시작 지점으로 돌아간다는 의미다.\n\u0026gt; def recur(n: int) -\u0026gt; int \u0026gt; \u0026#34;\u0026#34;\u0026#34;꼬리 부분을 제거했기 때문에, while문을 사용\u0026#34;\u0026#34;\u0026#34; \u0026gt; while n \u0026gt; 0: \u0026gt; recur(n-1) \u0026gt; print(n) \u0026gt; n = n - 2  \u0026gt; recur(5)  1 2 3 1 4 1 2 5 1 2 3 1 만약 while문으로 하지 않고, 그대로 if 문을 사용했을 경우 결과는 다음과 같다.\n1 2 3 4 5 꼬리 부분을 제거하고, if 문을 유지했기 때문에 n = n - 2 로, n이 재할당되어도 반복되지 않았기 때문이다.\n즉, 재귀함수의 꼬리 재귀를 제거하기 위해서는 if 문에서 while 문으로 바꿔야 한다는 걸 알 수 있다.\n2.2.2 완전히 재귀를 제거 그러면 다음으로 완전히 재귀를 제거 해보자.\n여기서 문제점이 있다.\n앞 부분에 있는 recur(n-1) 을 꼬리 재귀를 제거했듯이 동일하게 간단히 제거할 수 없다. 그렇게 하면 n이 바로 출력되기 때문이다. n은 별도로 저장되었다가 나중에 출력되어야 한다.\n이를 해결하기 위해서 stack  data structure를 사용한다.\n이전에 학습했던 method로는 pop(), push(), is_empty() 다.\n여기서 직접 구현해보지 않겠다.\n다음 이미지를 참고하여 구현해보자.\n 3. 하노이의 탑(Towers of Hanoi) 주어진 조건들은 다음과 같다.\n 총 3개의 기둥이 있다. 3개의 기둥 중 첫 번째 기둥에 n개의 원반이 있다. 이 원반은 아래로 내려갈수록 면적이 커진다.  위 조건들을 바탕으로, 다음과 같은 규칙을 준수하면서 최소 이동 횟수 를 구하는 문제다.\n 한 번에 한 개의 원반만 이동할 수 있다. 큰 원반은 작은 원반 위에 쌓을 수 없다.  3개의 원반을 이동시킨다고 할 때, 다음과 같이 흘러간다.\nrecur과 동일하게 재귀함수 2개와 print 출력문 1개의 구성과 순서가 동일하다.\n 4. 8퀸 문제(8-Queen problem) 8퀸 문제는 다음과 같다.\n 64칸(8 x 8) 안에서 8개의 퀸이 서로 공격하여 잡을 수 없도록 배치하기\n 결론부터 말하자면 92가지 해결 방법이 나온다고 한다.\n퀸을 배치할 수 있는 경우의 수는 64 x 63 x 62 x \u0026hellip;. x 57 = 178,462,987,637,760 이다. 이를 8퀸 문제의 조건에 만족하는지 알아보는 건 비현실적이다.\n그래서 먼저 이 문제에 숨겨진 규칙을 찾아보자.\n 퀸은 같은 열에 있는 다른 퀸을 공격할 수 있으므로, 첫 번째 규칙, 각 열에 퀸을 1개만 배치한다. 또한, 퀸은 같은 행에 있든 다른 퀸을 공격할 수 있으므로, 두 번째 규칙, 각 행에 퀸을 1개만 배치한다.  첫 번째 규칙을 적용하면 8 x 8 x 8 x 8 x 8 x 8 x 8 x 8 = 16,777,216 가지로 줄어든다.\n여기서 두 번째 규칙을 적용하면 더 줄어든다는 건 계산해보지 않아도 알 수 있다.\n분기 작업과 한정 작업을 합친 분기 한정법(branching and bounding method)을 통해서 접근한다.\n- 분기(branching) 작업: 가지가 뻗어 나가듯이 배치 조합을 열거하는 방법\n- 위에 하노이 탑이나 8퀸 문제처럼 큰 문제를 작은 문제로 분할하고, 작은 문제 풀이법을 결합하여 전체 풀이법을 얻는 방법을 **_분할 해결법(divide and conquer)_** 이라 한다. 이 때 주의할 점은 문제를 분할할 때, 작은 문제 풀이법에서 원래의 문제 풀이법을 쉽게 도출할 수 있도록 설계해야 한다.  - 한정 작업(bounding): 필요한 조합을 열거하지 않는 방법\n Reference  Do it! 자료구조와 함께 배우는 알고리즘 입문 재귀 알고리즘 상향식 하노이의 탑  ","permalink":"http://jeha00.github.io/post/algorithum/chapter05_%EC%9E%AC%EA%B7%80%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/","summary":"재귀 알고리즘(recursive algorithum)에서 재귀의 의미를 이해하여 재귀 알고리즘이란 무엇이고, 재귀 알고리즘 분석 방법 2가지와 제거하는 방법을 알아본다. 또한, 재귀 알고리즘으로 유명한 문제인 하노이의 탑, 8퀸 문제에 대해 알아본다.","title":"[TIL] Alogorithum Chapter 05: Recursive algorithum"},{"content":"0. Introduction  이번 chapter의 학습은 Do it! 자료구조와 함께 배우는 알고리즘 입문로부터 학습했습니다. 더 자세한 내용과 관련 내용의 코드는 위 서적의 출판사 사이트에서 확인하실 수 있습니다.   1. 스택(Stack)  데이터를 임시 저장할 때 사용하는 자료 구조로, 데이터의 입력과 출력 순서는 후입선출(LIFO: Last In, First Out) 방식이다.\n 이 스택에 데이터를 넣는 작업을 푸시(push) 라 하며, 스택에서 데이터를 꺼내는 작업을 팝(pop) 이라 한다.\n회전 초밥 집에서 먹은 후, 쌓인 접시를 생각해보자. 마지막에 먹는 초밥 접시가 맨 위에 있고, 이 접시들을 꺼낸다고 하면 마지막에 먹은 초밥 접시가 제일 먼저 꺼내진다.\n이렇게 쌓인 스택 자료 구조에서 쌓인 데이터의 윗 부분, 아랫 부분을 별도로 부르는 명칭이 있다.\n윗 부분은 꼭대기(top), 아랫 부분은 바닥(bottom) 이라 한다.\n1.1 스택: list형 배열 이 스택(stack, stk)은 list형 배열이다.\nlist의 index가 0으로 갈수록 위의 바닥(bottom) 과 가까워지고, 바깥쪽으로 갈수록 꼭대기(top) 에 가까워진다고 생각하자.\n또한, 이 스택의 크기는 capacity 단어가 의미하며, 스택에 쌓여 있는 데이터의 개수를 나타내는 정수값을 스택 포인터(stack pointer, ptr) 라 한다.\n그래서, stk가 비어 있으면 ptr은 0이 되고, stk가 가득 차면 capacity와 동일한 값이 된다.\n1.2 고정 길이 스택을 구현하기 위한 클래스와 메서드 종류 그러면 고정 길이 스택을 구현하기 위한 클래스와 메서드를 알아보자.\n아래와 같이 정리하는 이유는 이 스택을 구현하기 위한 기본 틀을 정립하기 위함이다.\n메서드 명이 정확히 일치하지 않을지라도 다음과 같은 기능을 구현할 필요가 있다는 걸 알기 위함이다.\n  초기화 __init__ method\n 스택 배열을 생성하는 준비 작업을 수행하는 함수로서, capacity 만큼으로 스택 크기가 결정된다. 첫 모든 원소는 None이 list가 생성된다.    데이터 갯수를 알 수 있는 __len__ method\n stack에 쌓여 있는 데이터 개수를 반환한다.    stack이 비어 있는지 판단하는 is_empty() method\n stack이 비어 있는지 판단하여, 비어있으면 True, 그렇지 않으면 False를 반환한다.    stack이 가득 차 있는지를 판단하는 is_full method\n stack이 가득 차 있는지 판단하여, 가득차면 True, 그렇지 않으면 False를 반환한다.    예외 처리 클래스 Empty와 Full\n Empty class는 pop() 함수를 호출할 때, 비어있으면 내보내는 예외처리 class다. Full class는 push() 함수를 호출할 때, 가득 차 있으면 내보내는 예외처리 class다.    데이터를 푸시하는 push() method\n stack에 데이터를 추가한다.    데이터를 팝하는 pop() method\n stack의 top에서 데이터를 꺼내어 그 값을 반환한다.    데이터를 들여보는 peek() method\n stack의 꼭대기 data를 들여다본다.    스택의 모든 데이터를 삭제하는 clear() method\n stack에 쌓여 있는 데이터를 모두 삭제하여 빈 스택을 만든다.    스택의 데이터를 검색하는 find() method\n 스택 본체의 배열 stk 안에 value와 값이 같은 데이터가 포함되어 있는지 확인    데이터 갯수를 세는 count() method\n stack에 쌓여 있는 데이터의 갯수를 구한다.    데이터가 포함되어 있는지 판단하는 __contains__ method\n   2. 큐(Queue)  데이터를 임시 저장할 때 사용하는 자료 구조로, 데이터의 입력과 출력 순서는 선입선출(FIFO: First In, First Out) 방식이다.\n 스택과 동일하게 list형 배열이며, 은행 창구에서 차례를 기다리거나, 마트에서 계산을 기다리는 줄을 생각하면 된다.\n데이터를 꺼내는 쪽을 프런트(Front) 라고 하며, 맨 앞 원소를 가리킨다.\n데이터를 넣는 쪽을 리어(rear) 라고 하며, 맨 끝 원소를 가리킨다.\n리어 에 데이터를 추가하는 작업을 인큐(enqueue) 라고 하며, 프런트 에서 데이터를 꺼내는 작업을 디큐(dequeue) 라고 한다.\n스택과는 달리 데이터를 추가하고 꺼내는 작업의 방향이 다르다는 걸 아래 이미지로 볼 수 있다.\n이미지 상의 차이로 큐는 디큐를 하면 전체 배열을 위로 하나씩 올려야 하는 비용이 들고 복잡도로 판단하자면 O(n) 이다.\n그래서 이를 해결하는 방법이 링 버퍼(ring buffer) 다. 이 방식은 인큐와 디큐에 따라 시작 원소와 끝 원소가 달라지는 상황에 맞춰서 전체 원소를 옮기는 것이 아닌 프런트(Front) 와 리어(Rear)의 각 인덱스를 계속해서 바꾸는 것이다. 이런 경우 복잡도는 O(1) 이다. 아래 이미지를 참조하자.\nfrom: RingBuffer aka Circular Queue\n그러면, 이 큐를 구현하기 위한 클래스와 메서드에는 무엇이 필요할까???\n고정 길이 큐를 구현하기 위한 클래스와 메서드 종류는 위에 스택과 동일하므로, 스택을 참고하자.\n Reference  Do it! 자료구조와 함께 배우는 알고리즘 입문 RingBuffer aka Circular Queue  ","permalink":"http://jeha00.github.io/post/algorithum/chapter04_%EC%8A%A4%ED%83%9D%EA%B3%BC%ED%81%90/","summary":"stack과 queue에 대해 알아보고, 직접 구현하여 해당 자료 구조에 대해 알아보고, 이 두 자료구조의 차이점에 대해 이해해보자.","title":"[TIL] Alogorithum Chapter 04: Stack and Queue"},{"content":"0. Introduction  이번 chapter의 학습은 Do it! 자료구조와 함께 배우는 알고리즘 입문로부터 학습했습니다. 더 자세한 내용과 관련 내용의 코드는 위 서적의 출판사 사이트에서 확인하실 수 있습니다.   1. 검색 알고리즘이란? 알고리즘이란 어떠한 문제를 해결하기 위해 정해 놓은 일련의 절차를 말하며, 올바른 알고리즘은 어떠한 경우에도 실행 결과가 똑같이 나오는 알고리즘을 말한다.\n검색이란 어떤 특정 조건을 만족하는 데이터를 찾아내는 것이다.\n그렇다면 검색 알고리즘이란 어떤 특정 조건을 만족하는 데이터를 찾아내기 위한 일련의 정해놓은 절차를 말한다는 걸 알 수 있다.\n이 검색 알고리즘의 종류에는 다음과 같이 3가지가 있다.\n 배열 검색 연결 리스트 검색 이진 검색 트리 검색  이 중에서 배열 검색에 대해 먼저 알아볼 것이고, 이 배열 검색 또한 3가지 검색법이 있다.\n 배열 검색  선형 검색: 무작위로 늘어놓은 데이터 집합에서 검색을 수행한다. 이진 검색: 일정한 규칙으로 늘어놓은 데이터 집합에서 아주 빠른 검색을 수행한다. 해시법: 추가 삭제가 자주 일어나는 데이터 집합에서 아주 빠른 검색을 수행한다.  체인법: 같은 해시값 데이터를 연결 리스트로 연결하는 방법 오픈 주소법: 데이터를 위한 ㅐ시값이 충돌할 때, 재해시하는 방법      그러면 검색은 무조건 빠르게 수행하면 좋은 걸까??\n그렇지 않다.\n용도, 목적, 실행 속도, 자료 구조 등 여러 사항을 고려해서 선택해야 한다.\n이제 배열 검색부터 알아보자.\n 2. 선형 검색(Linear search)  선형으로 늘어선 배열에서 원하는 키값을 찾을 때까지 맨 앞부터 스캔하여 순서대로 검색하는 알고리즘\n 이 선형 검색이 종료가 될라면 검색이 실패하든가 성공해야 한다.\n검색할 값을 찾지 못하고, 배열의 맨 끝을 지나가면 실패한 경우다.\n검색할 값과 같은 원소를 찾았다면 당연히 성공한 경우다.\n그러면 이 성공한 경우와 실패한 경우를 간단히 코드로 구현해보자.\n# 배열 a에서 검색하는 프로그램 \u0026gt; i = 0 \u0026gt; while True: \u0026gt; if i == len(a): # 검색 실패 \u0026gt; if a[i] == key: # 검색 성공 하지만 이 검색 종료를 판단하기 위한 횟수도 줄일 수록 오버헤드가 줄어드는 것이다.\n이 오버헤드 비용을 반으로 줄이는 방법이 보초법(sentinel) 이다.\n원래의 배열 맨 끝에 찾으려는 key 값을 추가한다. 그러면 위 코드에서 검색 실패에 해당하는 과정을 수행할 필요 없이, 검색 성공에 해당하는 경우만 판단하면 된다.\n 3. 이진 검색(Binary search)  배열을 내림차순 또는 오름차순으로 정렬한 후, 검색 범위의 중간 위치에 있는 값이 key 값보다 작거나 크거나에 따라서 검색 범위를 점차 좁혀가는 검색하는 알고리즘으로, 선형 검색(순차 검색)보다 빠르다.\n [코들리] 알고리즘 - 이진검색 을 참고하자.\n글로 더 자세히 설명하자면 다음과 같다.\n배열 검색 범위의 맨 앞, 맨 끝, 중앙의 인덱스를 각각 pl, pr, pc 라고 하면, pl은 0, pr은 (n-1), pc는 (n-1) // 2로 초기화한다.\n중앙 값을 기준으로 key값보다 크고 작냐에 따라서 범위가 점점 줄어들기 때문에, 선형 검색보다 탐색 횟수가 적어서 빠르다.\n a[pc] \u0026lt; key: 중앙에서 오른쪽으로 한 칸 이동하여, 새로운 왼쪽 끝 pl로 지정하고, 검색 범위를 뒤쪽 절반으로 좁힌다. a[pc] \u0026gt; key: 중앙에서 왼쪽으로 한 칸 이동하며, 새로운 오른쪽 끝 pc로 지정하고, 검색 범위로 앞쪽 절반으로 좁힌다.  그래서 이진 검색은 다음과 같은 두 가지 조건일 때, 검색이 종료된다.\n a[pc] 와 key가 일치하는 경우 검색 범위가 더 이상 없는 경우  복잡도(Complexity)  알고리즘의 성능을 객관적으로 평가하는 기준\n 복잡도의 종류에는 다음 두 가지가 있다.\n 시간 복잡도(time complexity): 실행하는데 필요한 시간을 평가한다. 공간 복잡도(space complexity): 메모리(기억 공간)와 파일 공간이 얼마나 필요한지 평가한다.  복잡도는 _Order의 첫 글자 O로 표시한다. _\n실행 횟수가 1이면 복잡도를 O(1)로 표시한다. 하지만, 실행 횟수가 n에 비례하는 경우 복잡도는 O(n)으로 표시한다.\n그리고, 2가지 계산으로 구성된 알고리즘의 복잡도는 차원이 더 높은 쪽의 복잡도를 우선으로 하기 때문에, O(1)과 O(n)으로 구성되었다면 O(n)으로 여긴다.\n복잡도 O에 대한 더 자세한 설명은 이 블로그 알고리즘의 시간 복잡도와 Big-O 쉽게 이해하기를 보자.\n 4. 해시법(Hasing)  데이터의 추가, 삭제도 효율적으로 수행할 수 있는 검색법으로, 해시 함수(hash function)를 통해서 key를 해시값(hash value, key를 원소 갯수로 나눈 나머지)으로 데이터에 접근하는 방식\n 해시 테이블(hash table)에서 만들어진 원소를 버킷(bucket) 이라 한다.\n그리고, key와 hash value는 일반적으로 다 대 1 (n:1) 이라서, 저장할 버킷이 중복되는 현상을 충돌(collision) 이라 한다.\n이 충돌을 발생 시 대처 방법에는 아래와 같이 2가지가 있다.\n 체인법: 해시값이 같은 데이터 원소를 체인 모양의 연결 리스트롤 연결하는 방법을 말하며, 오픈 해시법(open hashing) 이라 한다. 오픈 주소법: 빈 버킷을 찾을 때까지 해시를 반복한다.   Reference  Do it! 자료구조와 함께 배우는 알고리즘 입문 [코들리] 알고리즘 - 이진검색 알고리즘의 시간 복잡도와 Big-O 쉽게 이해하기  ","permalink":"http://jeha00.github.io/post/algorithum/chapter03_%EA%B2%80%EC%83%89%EC%95%8C%EA%B3%A0%EB%A6%AC%EC%A6%98/","summary":"검색 알고리즘의 종류인 선형 검색, 이진검색, 해쉬법에 대해 알아본다.","title":"[TIL] Alogorithum Chapter 03: Search algorithum"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 다양한 caching 환경 1.1 caching 기법  한정된 빠른 공간(= 캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식\n   저장장치 계층 간의 속도 차이를 완충시켜주기 위해 컴퓨터 구조, 운영체제, DB 등의 분야에서 각각 다음과 같은 기법 등으로 사용되고 있다.\n  paging system 외에도 cache memory, buffer caching, Web caching 등 다양한 분야에서 사용된다.\n cache memory: CPU와 main memory 사이에 cache memory가 있다. 이 cache memory에 없는 file을 main memory에 요청한다. buffer caching: file system에 대한 read/write 요청을 memory에서 빠르게 서비스하는 방식 Web caching: web page를 server에서 가져오는데 동일한 url을 요청할 때를 대비해서 신속히 서비스를 제공하기 위해서, caching 기법으로 제공하는 방법    cache 운영의 시간 제약\n  교체 알고리즘에서 삭제할 항목을 결정하는 일에 지나치게 많은 시간이 걸리는 경우, 실제 시스템에서 사용할 수 없다.\n  Buffer caching이나 Web caching의 경우\n O(1)에서 O(log n) 정도까지 허용    Paging system인 경우\n page fault인 경우에만 OS가 관여한다. 페이지가 이미 메모리에 존재하는 경우, 참조시각 등의 정보를 OS가 알 수 없다. O(1)인 LRU의 list 조작 조차 불가능      1.2 웹캐싱이란?  웹 사용자에 의해 빈번히 요청되는 데이터를 사용자와 지리적으로 가까운 웹캐시 서버에 보관해, 빠른 서비스를 제공하여 서비스 지연시간을 줄이고 웹서버 부하도 줄이는 기법\n  2. 웹캐시의 교체 알고리즘(Cache replacement algorithum)  한정된 캐시 공간 안에서 사용자들의 지속적인 요청을 처리하기 위해서, 미래에 참조될 가능성이 높은 객체를 선별한 후, 한정된 캐시 공간 안에 보관할 객체를 온라인으로 결정하는 알고리즘\n   웹캐시는 객체를 가지고 있는 근원지 서버의 위치 및 특성에 따라 객체를 캐시로 읽어오는 비용이 다르다.\n  하나의 URL에 대응되는 파일 단위로 캐싱이 이뤄져서 캐싱 단위의 크기가 균일하지 않다.\n  2.1 교체 알고리즘의 성능 척도  캐시 교체 알고리즘의 목표는 참조 가능성이 높은 객체를 캐시에 보관해 \u0026lsquo;캐시적중률(Hit rate)\u0026lsquo;을 높이는 것\n   캐시 적중률\n 사용자의 총 요청 중 캐시에서 적중되어 서비스된 요청의 비율    하지만, 웹캐싱에서는 객체들의 크기와 인출 비용이 균일하지 않기 때문에 , 객체들의 참조 가능성과 이질성을 함께 고려해야 한다.\n  이런 경우, 비용절감률(Cost-Savings Ratio: CSR) 로 정형화시킨다.\n 객체 크기와 인출 비용이 모두 균일하면 비용절감률은 캐시 적중률과 동일한 의미를 가진다.    2.2 참조 가능성의 예측   캐시 교체 알고리즘은 전통적인 캐싱 기법인 LRU(Least Recently Used), LFU(Least Frequently Used) 등의 알고리즘처럼 최근 참조 성향과 참조 빈도에 근거해 미래의 참조 성향을 예측하는 방법을 사용한다.\n  그러면 전통적인 교체 알고리즘들의 구체적인 예를 살펴보고, 웹캐시의 교체 알고리즘은 이들 중 어떤 방법을 채택하는지 알아보자.\n  2.2.1 전통적인 교체 알고리즘   과거 참조 기록을 바탕으로 객체 A와 B를 평가한다고 하자.\n  LRU는 최근 참조 성향만을 고려한다.\n (a) 객체 B가 더 최근(t1)에 참조되었기 때문에, (a) B에 더 높은 가치를 부여한다. 하지만, 이 방법은 자주 참조되는 객체와 그렇지 않은 객체를 구분할 수 없다는 단점이 있다. (b)에서는 A의 가치가 더 높게 평가된다는 사실은 LRU의 문제점을 보여준다.    LFU는 참조 횟수만을 고려한다.\n (a) A의 참조 횟수가 (a) B보다 더 많기 때문에, (a) A에 더 높은 가치를 부여한다. 이 알고리즘의 문제점은 오래 전에 많이 참조된 객체에 높은 가치를 부여해, 새로 참조되기 시작한 객체를 캐시에서 쫓아낼 우려가 있다. 오히려 (c)에서 B의 가치가 더 높게 평가된다는 사실이 LFU의 문제점을 보여준다.    최근 참조 성향과 참조 횟수에 근거해 객체의 참조 가능성을 평가하는 방법은 최근에 참조된 객체가 다시 참조될 가능성이 높다는 점 ( 시간지역성, temporal locality )과, 참조 횟수가 많은 객체일수록 다시 참조될 가능성이 높다는 점 ( 인기도, popularity ), 이 두 가지 사실을 기본으로 가정한다.\n  위에 두 가지가 컴퓨터 프로그램의 참조 성향을 모델링하는데 널리 사용되는 요소다.\n  2.2.2 웹캐시의 교체 알고리즘   시간지역성 측면 -\u0026gt; 웹 캐시 알고리즘들은 객체의 직전 참조 시각을 활용\n  참조 인기도 측면 -\u0026gt; 객체 참조 횟수에 노화 기법을 추가하여, 캐시 오염(cache pollution)을 방지한다.\n 노화 기법: 오래전에 이루어진 참조에 대해 참조 횟수 계산할 때, 가중치를 줄이는 방법    2.3 객체의 이질성에 대한 고려  웹캐싱 같이 캐싱의 단위 객체들의 크기와 인출 비용이 균일하지 않은 환경에서는 이 특성을 고려한 합리적인 가치 평가를 해야 한다.\n   이 합리적인 평가를 하기 위해서는 객체의 참조 가능성 과 캐시 적중률 로 실제 절약할 수 있는 비용을 동시에 고려해야 한다.\n  캐시 적중률의 경우, 크기가 작은 객체에 높은 가치를 부여한다. 왜냐하면, 한정된 캐시 공간에 많은 객체를 보관하면 캐시 적중률이 높아지기 때문이다.\n  2.4 알고리즘의 시간 복잡도  캐시 교체 알고리즘이 실제 시스템에 유효하게 사용되기 위해서는 시간 복잡도 측면에서 현실성이 있어야 한다.\n   시간 복잡도 O(n): cache 내에 있는 객체의 수가 n개라고 할 때, 어떤 객체를 캐시에서 삭제할지 결정하기 위해 n에 비례하는 비교나 연산이 필요하다는 의미\n  proxy cache의 경우, 통상적으로 cache 내에 수백만 개의 객체가 존재하기 때문에 이들을 다 조사하는 시간 복잡도의 방법은 부담이 크기 때문에, 웹 환경에서는 이 알고리즘으로 사용하기 어렵다.\n  LRU\n 가장 최근에 참조된 시각을 기준으로 객체들의 가치를 일렬로 세워놓고 새롭게 참조된 객체만 가치가 가장 높은 위치로 옮기면 되므로, O(1)의 시간 복잡도 구현이 가능하다. O(1): 캐시 내에 존재하는 객체의 수 n이 커지더라도, 이에 관계없이 캐시에서 이루어지는 비교나 연산이 정해진 적은 횟수로 충분하다는 의미    나머지 알고리즘\n 힙(heap) 자료구조를 이용해 O(log n)의 시간 복잡도에 각종 캐시 연산을 구현하게 된다. 하지만, 최근 참조 시각을 이용하는 알고리즘에서는 객체의 가치가 시간과 비례하여 다르게 평가되기 때문에, 가치의 대소 관계가 변할 수 있다. 그래서, O(n)의 시간 복잡도가 필요하다.     3. 웹캐시의 일관성 유지 기법  cache에 보관된 웹 객체는 근원지 서버에서 변경될 수 있으므로 일관성 유지를 위한 기법으로, 특히 웹캐시의 일관성은 컴퓨터 시스템에서의 캐시와 달리 큰 문제를 야기하지 않으므로, 적응적 TTL(adaptive Time-To-Live) 기법과 같은 약한 일관성 유지 기법을 사용한다.\n   약한 일관성 유지 기법\n 사용자의 요청이 있을 때마다 서버에서 일일이 확인하는 게 아닌, 변경될 가능성이 높은 경우에만 확인하는 기법  예) adaptive TTL      강한 일관성 유지 기법\n 최신 정보가 사용자에게 전달되는 것을 보장하는 기법  예) polling-every-time, invalidation      웹서버와 네트워크의 부담이 커서 득보다 실이 많아 일반적으로 약한 일관성 유지 기법을 사용한다.\n   4. 웹캐시의 공유 및 협력 기법  웹캐싱 효과를 극대화 하기 위해 웹캐시 간의 공유 및 협력 기법이 필요하다.\n 4.1 ICP (Internet Cache Protocal, 인터넷 캐시 프로토콜)  동료 proxy cache 사이에서 웹 객체의 검색 및 전송을 지원하기 위한 protocol\n   사용자가 프락시서버에 웹 객체를 요구했는데, 프락시서버가 그 객체를 캐싱하고 있지 않은 경우, ICP에서 모든 동료 프락시들에게 ICP 질의를 멀티캐스트(multicast)해서 누가 요청된 웹 객체를 가지고 있는지 확인한다.\n  웹 객체를 가지고 있는 동료 프락시가 답신을 보낸다.\n 프락시 서버(Proxy server) : 클라이언트와 서버 사이에서 data를 중계하는 역할을 하는 서버    ICP 질의를 보냈던 프락시는 답신을 준 프락시에 HTTP 요청을 보내서 해당 객체를 받아온 후 사용자에게 전달한다.\n  HTTP와 ICP의 차이\n HTTP는 웹 객체의 전송을 위한 프로토콜인 반면, ICP는 공유 웹캐시들 간의 객체 위치를 확인하기 위한 프로토콜 HTTP에 비해 매우 부담이 적은 프로토콜    4.2 CARP (Cache Array Routing Protocol, 캐시 배열 간 경로지정 프로토콜)  공유 웹캐시들에 동일한 웹 객체들이 중복 저장되는 것을 막기 위해 URL 공간을 분할해, 각각의 캐시는 자신에게 배정되는 객체들만을 캐싱는 기법\n  5. 웹캐시의 사전인출 기법  웹 서비스의 응답 지연시간을 줄이기 위해, 사용자에 의해 아직 요청되지 않은 객체를 미리 받아오는 기법으로 2가지로 나눠진다.\n 5.1 예측 사전인출 기법(predictive prefetching)  웹페이지들 간의 관계 그래프 등을 구성해 하나의 웹 페이지가 참조되었을 때, 과거 참조 기록을 통해 새로운 웹페이지가 참조될 된 것을 기반으로 사전인출을 수행하는 방법  5.2 대화식 사전인출 기법(interactive prefetching)  사용자가 HTML 문서를 요청했을 때, 웹캐시는 캐싱하고 있던 HTML 문서를 미리 파싱(parsing)한다. 그래서 그 문서에 포함되거나 연결된 웹 객체를 미리 받아와서 사용자의 후속 요청에 곧바로 전달하는 기법   6. 동적 웹 객체의 캐싱 기법 6.1 정적 웹 페이지와 동적 웹 페이지의 차이   정적 웹 페이지\n 실시간으로 변하지 않고 서버에 저장되어 있는 HTML+CSS file 그대로 보여주는 방식    동적 웹 페이지\n 상황에 따라 서버에 저장되어 있는 HTML에 데이터 추가/가공하여 보여주는 방법으로, 실시간성 을 요구하는 콘텐츠를 처리하는 웹 페이지를 말한다.    6.2 동적 웹 객체의 캐싱 기법   동적 웹 페이지의 콘텐츠는 실시간성이 있어서, 결과물이 이전과 정확히 일치하지 않지만, 상당 부분 유사하다.\n  그래서 부분적으로 캐싱하여 추후 그 결과를 활용할 수 있다.\n   Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_13_%EC%9B%B9%EC%BA%90%EC%8B%B1/","summary":"캐싱이란 무엇이고, 웹에서 사용되는 캐싱은 무엇을 목적으로 하는지, 웹캐싱이 전통적인 캐싱 기법과 무엇이 다른지, ICP는 무엇인지, 정적 웹과 동적 웹이란 무엇인지 등을 알아본다.","title":"[TIL] OS Chapter 13: 웹캐싱 기법"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   6. Allocation of File data in disk  disk에 균일하지 않은 크기의 file을 저장할 때는 disk를 균일한 크기로 쪼갠 sector 단위로 저장한다.\n   disk에 file을 저장하는 방식 3가지 (paging 기법과 유사)\n Contiguous Allocation (연속 할당) Linked Allocation (연결 할당) Indexed Allocation (인덱스를 이용한 할당)    sector와 block의 차이\n sector: disk에서 물리적으로 저장하는 단위 block: file system에서 file이 저장되는 단위    6.1 Contiguous Allocation  하나의 file을 sector들에 Array 구조로 저장하여, 나누어진 각 블록들이 연속된 번호를 부여받아 저장된다.\n   directory를 설명하자면\n \u0026lsquo;count\u0026rsquo; file은 0부터 시작해서 총 2개의 sector를 차지한다. \u0026rsquo;tr\u0026rsquo; file은 14부터 시작해서 총 3개의 sector를 차지한다.    장점\n Fast I/O (시간 효율성 증가)  file이 모두 연속해서 붙어 있으므로 한 번의 seek / rotation으로 많은 양의 데이터를 받을 수 있다.  대부분의 접근 시간은 header가 움직이면서 읽어들이는 시간이기 때문에, 시간 효율성이 증가한다.   Realtime file 용 또는 이미 run 중이던 process의 swapping 용도로 사용된다.   Direct access (= random access) 가능  몇 번 sector부터 시작하는지 directory가 알기 때문에 가능하다.      단점\n External fragmentation (hole 발생) File grow가 어렵다. file grow를 해도 낭비 발생 (internal fragmentation)  file이 커져서 sector를 늘려 저장하려할 때, 다른 file이 옆 sector를 차지하고 있다면 늘릴 수 없다. 그래서 file이 커질 것을 대비하여 미리 할당했을지라도, 할당된 만큼만 커질 수 있다는 단점이 있다. 그리고 미리 할당된거면서 사용하지 않는 조각이기 때문에, 내부 조각이 발생된다.      6.2 Linked Allocation  sector들이 각각 node되어 linked list 구조로 파일을 저장한다.\n   장점\n 외부 단편화가 발생하지 않는다.    단점\n 첫 요소부터 차례대로 읽어야하므로, 직접 접근이 불가능하다.  또한, 각 sector로 header가 이동해야하므로, 시간이 더 걸린다.   신뢰성 문제  한 sector가 고장나 pointer가 유실되면 그 이후 모든 sector로 접근할 수 없다. pointer란 block 주소를 의미한다고 생각하자.   포인터를 위한 공간이 필요하므로 공간 효율성을 떨어뜨린다.  512 bytes/sector, 4 bytes/pointer      변형\n File-Allocation Table (FAT) 파일 시스템  pointer를 별도의 sector에 보관하여 신뢰성 문제와 공간 효율성 문제를 해결한다.      6.3 Indexed Allocation  directory에 file의 index block을 표시하여 이 index block을 통해서 직접 접근이 가능한 방식\n   index block이란??\n file이 어디에 나눠져 있는지 index를 적어 두는 block 하나    장점\n External fragmentation(외부 조각 hole) 발생 X 직접 접근 (= 임의 접근)이 가능하다.    단점\n 작은 파일의 경우, 공간 낭비가 심하며 실제로 많은 파일들이 사이즈가 작다.  index block을 위한 sector와 실제 file 저장을 위한 sector가 필요하기 때문에 공간 낭비가 심하다.   매우 큰 파일의 경우, 하나의 index block으로 커버할 수 없다.  해결 방안: linked scheme, multi-level index 전자는 index block을 여러 개 두는 것이고, 후자는 block의 마지막에 다음 index block을 가리키는 값을 설정하여 서로 연결하는 것이다.      이번 소챕터에서는 이론적으로 disk에 file을 어떻게 할당하는 지를 알아봤으니, 다음 소챕터에서는 실제로 어떠한지 알아보자.\n   7. UNIX 파일 시스템의 구조  Partition(= Logical Disk) 은 Boot block, Super block, Inode list, Data block으로 구성된다.\n 7.1 Boot block  Booting에 필요한 정보를 담고 있는 block\n  0번 block이며, bootstrap loader라고도 한다. 모든 file system에 존재하는 블록  7.2 Super block  file system에 관한 총체적인 정보를 담고 있는 블록\n  어느 부분이 비어 있는 블록인지, 어느 부분이 사용 중인 블록인지, 어디부터가 Inode 블록인지, data 블록인지 등을 알려주는 정보를 가지고 있다.  7.3 Inode list  파일 이름을 제외한 파일의 모든 \u0026lsquo;메타 데이터\u0026rsquo; 를 따로 저장하고 있는 list\n  파일 하나당 Inode가 하나씩 할당된다. 해당 Inode는 파일의 meta data를 가지고 있는데, 파일의 이름과 Inode 번호는 directory가 가지고 있다. direct blocks  파일이 존재하는 인덱스를 저장하는 index block 파일의 크기가 크지 않다면 이 블록을 이용하여 파일을 접근할 수 있다. direct blocks로 커버할 수 있는 크기보다 저장 용량이 큰 파일은 single indirect를 통해서 하나의 level을 두어 저장하는 방식을 취하고, 그보다 더 큰 파일은 double indirect, 더 큰 파일은 triple indirect 방식을 취한다.    7.4 Data block  파일의 실제 내용을 보관하는 블록\n  이 중 directory file은 자신의 directory에 속한 file의 이름과 inode 번호를 가지고 있다.  file의 이름은 실제로 data block이 가지고 있고, 나머지는 Inode 번호로 가진다.     8. FAT 파일 시스템  window 계열에서 주로 사용되는 file system 방식으로, Partition(= Logical Disk)은 Boot block, FAT, Root directory, Data block으로 구성된다.\n   구조: Boot block + FAT + Root directory + Data block\n  file의 metadata의 일부(위치 정보)를 FAT에 저장하고, 나머지 정보는 root directory가 가지고 있다. (file name, 접근 권한, 소유주, 파일의 첫 번째 위치 등)\n 위 사진에서 217번이 첫 번째 블록인데, 다음 블록의 위치를 FAT에 별도로 관리한다. 그래서 FAT을 통해서 직접 접근이 가능하다.    FAT table 전체를 메모리에 올려 놓았으므로 연결 할당(linked allocation)의 단점을 전부 극복하였다.\n  FAT는 중요한 정보이므로 복제본을 만들어 두어야 한다.\n   9. Free-space management  Sector가 할당되고 나서 발생하는 hole을 관리하는 디스크 자유 공간 관리방법으로, 아래 4가지가 있다.\n 9.1 Bit map or Bit vector  각 block 마다 bit를 둬서 bit가 0이면 free block이고, 1이면 sector에 저장된 block이다.\n   연속된 n개의 free block(빈 공간)을 찾기 효과적이지만, 0 또는 1을 저장할 부가적인 공간을 필요로 한다.\n  UNIX file system의 경우, super block에 정보를 저장한다.\n  9.2 Linked list  모든 free block을 link로 연결 (free list)한 방식\n   회색이 비어있는 공간\n  연속적인 가용 공간을 찾기 어렵지만, 공간의 낭비가 없다.\n  9.3 Grouping  Linked list의 변형으로, 첫 번째 자유 블록(free block)이 n개의 블록 주소(pointer)를 저장하는 방법\n  n개의 블록 주소 중, (n-1)개는 실제로 비어있는 블록의 주소다. 그러나 마지막 1개는 첫 번째와 마찬가지로, (n-1)개의 빈 블록 주소를 가지고 있는 또 다른 자유 블록을 가리킨다. linked list와 달리 비어있는 block을 한 번에 찾기에는 효율적이지만, 연속적인 free block을 찾기에는 효과적이지 않다.  9.4 Counting  free block의 위치를 가리키고, 거기서부터 몇 개가 비어 있는지 알려주는 방식\n  프로그램들이 종종 여러 개의 연속적인 block을 할당하고 반납한다는 사실에 착안했다. 모든 블록을 일일이 추적할 필요 없이, 자유 블록의 첫 번째와 연속된 계수만 유지하면 보다 효율적이다.   10. Directory Implementation   Linear list\n \u0026lt;file name, file의 메타 데이터\u0026gt;의 list 구현이 간단하다. 하지만, directory 내에 파일이 있는지 찾기 위해서는 선형 탐색이 필요하다.    해시 테이블\n 선형 리스트 + 해싱  hashing: 더 짧은 길이의 값이나 키로 변환하는 것   Hash table은 file name을 선형 리스트의 위치로 hashing한다. 탐색 시간이 O(1)이다. 해시 충돌이 발생할 수 있다. -\u0026gt; 자료 구조 관련 내용      파일의 메타 데이터 보관 위치\n Directory 내에 직접 보관 Directory 에는 포인터를 두고 다른 곳에 보관  UNIX에서는 대부분 Inode에서 저장, FAT file system에서는 다음 block 위치를 가지고 있었다.      Long file name의 지원\n \u0026lt;file name, file의 metadata\u0026gt;의 list에서 각 entry는 일반적으로 고정 크기다. 하지만 file name이 엔트리의 고정 길이보다 길어지는 경우, entry의 마지막 부분에 file name의 뒷 부분이 위치한 곳의 pointer를 둔다. file 이름의 나머지 부분은 동일한 directory file의 일부에 존재한다.     11. VFS와 NFS   Virtual File System (VFS)\n 서로 다른 다양한 파일 시스템에 대한 동일한 시스템 콜 인터페이스(API)를 통해 접근할 수 있게 해주는 OS의 layer    Network file System (NFS)\n 분산 환경에서 네트워크를 통해 파일이 공유되는 대표적인 공유 방법      어떤 파일 시스템을 쓰든 상관 없이 VFS interface를 사용한다.\n  client 입장에서 VFS interface를 거쳐서 file system이 없으면 NFS를 사용한다.\n  분산 시스템에서는 네트워크를 통해 파일을 공유하기 위해 NFS client와 NFS server가 이용된다.\n client와 server 모두에 NFS module이 있어서, 같은 약속으로 접근이 가능하다.     12. Page cache and buffer cache 12.1 Page cache  Virtual memory의 paging system에서 사용하는 page frame을 page cache라 부르는 것으로, cache의 관점에서 설명하는 용어다. 이 관점에서는 프로세스의 주소 공간을 구성하는 페이지가 swap area에 내려가 있는가, page cache에 올라와 있는가로 바라본다.\n  Memory-Mapped I/O 를 쓰는 경우, 파일의 I/O에서도 page cache를 사용한다. page cache는 운영체제에게 주어진 정보가 극히 제한적이라, clock 알고리즘을 사용한다.  12.2 Memory-Mapped I/O  디스크 파일의 일부를 가상 메모리에 매핑하여 사용하는 것으로, 매핑 후에는 system call을 하지 않고 메모리에서 사용자가 직접 읽고 쓴다.\n  매핑한 영역에 대한 메모리 접근 연산은 파일의 입출력을 수행하게 한다.  12.3 Buffer cache: File system 관점  프로그램이 I/O 시, disk의 file system에서 system call에 의해 OS가 대신 read() 작업을 수행하여, 읽어온 data를 kernel의 memmory 영역에 copy 하여 놓은 data를 buffer cache라 한다. 즉 이 관점에서는 disk에 있는냐 아니면 kernel의 memory 영역에 copy되어 있느냐로 바라본다.\n  파일 시스템을 통한 I/O 연산은 메모리의 특정 영역인 buffer cache를 사용한다. 한 번 읽어 온 블록에 대한 후속 요청 시, buffer cache에서 즉시 전달 모든 process가 공용으로 사용 교체 알고리즘 필요 (LRU, LFU 등)  12.4 Unified(통합) buffer cache  최근의 OS에서 기존의 buffer cache가 page cahce에 통합되어 사용되는 방식\n  별도의 구분 없이 필요할 때만 할당해서 사용하는 방식이다.  12.5 통합 buffer cache로 인한 차이점  13. 프로그램의 실행   프로그램이 실행되면 실행 파일이 프로세스가 되며, 프로세스만의 독자적인 주소 공간이 만들어진다.\n  이 공간은 code, data, stack으로 구분되며 Address translation을 통해서 당장 사용될 부분은 물리적 메모리에 올라가고, 당장 사용되지 않는 부분은 swap area로 내려간다.\n  이 때, 코드 부분은 이미 파일 시스템에 있고, 프로세스의 주소에 이미 mapping된 경우이기 때문에, swap area에 내리지 않고 필요 없으면 물리적 메모리에서 지운다. 나중에 필요하면 file system에서 가져오면 된다. 즉, 이 code 부분은 memory mapping된 대표적인 예다.\n  13.1 Memory Mapped I/O 수행   프로세스가 일반 데이터 파일을 I/O하고 싶을 수 있다.\n  이때 mmap()을 호출하면 Memory Mapped I/O 방식으로 파일을 I/O할 수 있고, mmap()은 시스템 콜이므로 운영 체제에게 CPU의 제어권이 넘어간다.\n    운영 체제는 데이터 파일의 일부를 프로세스 주소 공간에 매핑한다.\n  만약 데이터 파일이 매핑된 영역을 접근했을 때, 실제 물리적인 메모리에 페이지가 올라와 있지 않다면 페이지 부재가 발생한다. 그렇지 않으면 가상 메모리의 mapping된 영역은 물리적 메모리의 페이지 프레임과 일치가 되므로, 프로세스가 데이터 파일에 대해 I/O를 하고 싶을 때, 운영 체제의 도움 없이 독자적으로 I/O를 수행할 수 있다.\n  물리적 메모리에 올라간 데이터 파일과 매핑된 페이지 프레임을 쫓아내야 할 때는 swap area로 내리는 것이 아니라, 수정된 사항을 file system에 적용하고 물리적 메모리에서 지운다.\n  현재 process B가 데이터 파일에 대해 Memory Mapped I/O를 수행하여, 물리적 메모리에 페이지 프레임을 올려 두었는데도, 프로세스 A도 이 page frame을 공유하여 사용할 수 있다.\n  13.2 read() 수행   프로세스가 일반 데이터 파일을 I/O를 하는 방법으로, read() system call을 호출할 수도 있다.\n  read() system call을 호출하면 memory의 buffer cache를 확인해야 하는데, 통합 buffer cache 환경에서는 페이지 캐시가 buffer cache 역할을 동시에 수행한다. 그래서 Memory Mapped I/O 로 올라간 페이지 cache를 buffer cache로 사용할 수 있다.\n   운영 체제는 buffer cache에 있던 내용을 복사하여 process의 주소 공간에 할당한다.  13.3 Memory Mapped I/O vs read()   Memory Mapped I/O\n 가상 메모리에 올라 온 영역이 곧 파일이므로, system call 없이 I/O 작업을 할 수 있다. page cache에 있는 내용을 복사할 필요가 없다. 여러 프로세스가 mmap()를 사용하여 같은 영역을 공유하여 사용하면 일관성 문제가 발생할 수 있다.    read()\n 매번 운영체제의 중재를 받는다. page cache에 있는 내용을 복사해야 한다. 여러 프로세스가 read()를 사용해도 일관성 문제가 발생하지 않는다.     Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - 느리더라도 꾸준하게: [반효경 운영체제] File System Implementations 1\u0026amp;2 연결 리스트(Linked list)  ","permalink":"http://jeha00.github.io/post/os/os_chapter_12_%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C_2/","summary":"Disk의 할당방식 3가지, FAT file system이란 무엇인지, disk의 빈 공간을 어떻게 관리하는지, page cache와 buffer cache와의 차이점과 마지막으로 통합 buffer cache에서의 Memory mapped 방식에 대해 알아본다.","title":"[TIL] OS Chapter 12: 파일 시스템 2"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. File and File System   File\n A named collection of related information\n  저장 장소:  일반적으로 비휘발성의 보조기억장치(disk)에 저장   메모리는 주소를 통해서 접근하는 장치지만, disk에 일반적으로 저장되는 file은 이름을 통해서 접근한다. 운영체제는 다양한 저장 장치를 file이라는 동일한 논리적 단위로 볼 수 있고 관리한다.  운영체제의 관리 방법으로 사용되는 file을 \u0026lsquo;device special file\u0026rsquo; 이라 한다.   file 관련 Operation(연산):  create, delete,read, write, reposition(파일 내부의 위치 저장), open, close 등      File attribute(or metadata of file)\n 파일 자체의 내용이 아니라 파일을 관리하기 위한 각종 정보들\n  파일 이름, 유형, 저장된 위치, 파일 사이즈 접근 권한(읽기 / 쓰기 / 실행), 시간(생성 / 변경 / 사용), 소유자 등    File system\n 운영체제에서 파일을 관리하는 체계\n  파일 및 파일의 메타 데이터, 디렉토리 정보 등을 관리 파일의 저장 방법 결정 파일 보호 등    Directory\n 파일의 metadata 중 일부를 보관하고 있는 일종의 특별한 파일 그 디렉토리에 속한 파일 이름 및 파일 attribute들을 가지고 있다. directory로 정의되는 연산  file 찾기, 만들기, 지우기 list a directory, rename a file, traverse(탐색) the file system      Partition (= Logical Disk)\n 하나의 물리적 디스크 안에 여러 파티션을 두는 게 일반적이다.  쪼개진 파티션을 C drive, D drive라 불린다.   반대로 여러 개의 물리적인 디스크를 하나의 파티션으로 구성하기도 한다. (물리적) 디스크를 파티션으로 구성한 뒤 각각의 파티션에 file system을 설치하거나, 가상 메모리의 swapping 등 다른 용도로 크게 2가지로 나눠 사용할 수 있다.     2. open() 연산  system call을 통해서 OS가 물리적 디스크에 있는 file의 metadata를 memory로 올리는 연산으로, read와 write 같은 연산들 모두 system call을 통해서 수행한다.\n 2.1 open() 연산의 구체적인 과정   왼쪽: memory, 오른쪽: disk\n  open(\u0026rsquo;/a/b/\u0026rsquo;): Process A가 \u0026lsquo;/a/b/\u0026rsquo; 경로에 있는 file을 open하겠다.\n  system call 이므로, CPU 제어권이 OS에게 넘어간다.\n  disk로부터 파일 c의 metadata를 메모리로 가져오기 위해, directroy path를 search.\n  open 작업: 그 안에 있는 metadata를 memory에 올리는 것\n  read 작업: open 후, memory에 올린 metadata 안의 disk 상의 실제 위치를 얻는 것\n  root directory \u0026lsquo;/\u0026lsquo;의 metadata는 미리 알고 있다.\n  root directory \u0026lsquo;/\u0026lsquo;를 open하고, read하여 그 안(= disk 상의 실제 위치 안)에서 \u0026lsquo;a\u0026rsquo;의 metadata를 획득.\n  파일 \u0026lsquo;a\u0026rsquo;의 metadata를 open한 후, read하여 그 안에서 파일 \u0026lsquo;b\u0026rsquo;의 metadata를 획득.\n  파일 \u0026lsquo;b\u0026rsquo;의 metadata를 open한 후, read하여 그 안에서 원하는 data를 가져온다.\n    이런 tree 구조의 directory는 search에 너무 많은 시간을 소요한다.\n 한 번 open한 파일은 kernel의 메모리 영역 일부에 copy하여 두고 나서 동일한 경로의 파일에 관한 read / wrtie 시, kernel의 메모리 영역에 둔 file을 다시 copy해서 사용하기 때문에 directory search를 하지 않아도 된다. kernel memory 일부 영역에 copy하여 별도로 저장된 file을 buffer cache 라 한다. 그래서 LRU와 LFU 알고리즘을 자연스럽게 사용할 수 있다.      2.2 file system 연산의 두 종류 table   File descriptor table(fd) (file handle, file control block)\n 프로세스마다 존재하여 프로세스 별 open file table에 대한 위치 정보를 나타낸다.  위 이미지에서는 b file의 index 정보를 가지고 있다.      Open file table\n  현재 open된 file들의 metadata 보관소 (in memory)\n  디스크의 metadata보다 몇 가지 정보가 추가된다.\n Open한 process의 수 File offset: 파일 어느 위치 접근 중인지 표시 (별도 테이블 필요)       3. File Protection  각 파일에 대해 누구에게 어떤 유형의 접근(read / wrtie / execution)을 허락할 것인가?? Access Control 방법: 3가지  Access control Matrix, Grouping, Password     Access control Matrix로 하는 건 overhead가 커서 일반적인 OS에서는 Grouping 방법을 사용한다. Grouping 방식은 단 9 비트만 있으면 된다.   4. File System의 Mounting  Mounting 연산이란 A partition의 root file system에 있는 특정 directory 이름에다가 또 다른 파티션 B의 file system을 mounting 하여, A parition이지만 B partition과 연결하는 연산\n  5. Access Methods   시스템이 제공하는 파일 정보의 접근 방식\n  순차 접근 (sequential access)\n 카세트 테이프를 사용하는 방식처럼 접근 읽거나 쓰면 offset은 자동적으로 증가    직접 접근 (direct access, random access)\n LP 레코드 판과 같이 접근하도록 한다. 파일을 구성하는 레코드를 임의의 순서로 접근할 수 있다.       Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 - metadata  ","permalink":"http://jeha00.github.io/post/os/os_chapter_12_%ED%8C%8C%EC%9D%BC%EC%8B%9C%EC%8A%A4%ED%85%9C_1/","summary":"file이란 무엇이고, 이 file 관리하는 system은 무엇인지, operation은 memory와 disk 사이에서 어떤 순서로 이뤄지는지,  file protection은 어떻게 이뤄지는지, 순차 접근과 직접 접근이 무엇인지 알아본다.","title":"[TIL] OS Chapter 12: 파일 시스템 1"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 디스크의 구조  디스크(disk): 컴퓨터 시스템의 대표적인 2차 저장장치  memory는 volatile(휘발성) 저장장치이지만, disk는 영구 보관할 수 있는 2차 저장장치   디스크의 효율적인 관리를 위해 디스크 스케쥴링 기법 과 저전력 디스크 관리 기법 에 대해 알아보자. 또한, 엘리베이터 scheduling 문제를 통해 쉽게 이해해보자.  1.1 논리 블록(logical block) 단위  디스크 외부(=컴퓨터 host의 내부)에서 보는 디스크의 단위 정보 저장 공간들을 말한다. 내부에서는 sector로 바라본다.\n   주소를 가진 1차원 배열처럼 취급\n host에서 disk의 정보를 읽을 때, sector 몇 번지가 아니라 1차원 배열에서 몇 번째 있는 정보를 달라고 요청한다.    정보를 전송하는 최소 단위\n disk에 데이터 저장과 disk 외부로의 입출력은 논리 블록 단위로 저장 및 전송이 이뤄진다.    어떻게 논리 블록의 저장된 데이터에 접근하는가??\n 해당 블록의 index 번호를 disk controller에 전달 → disk controller가 대응되는 sector를 찾아 요청 데이터에 대한 입출력 작업을 수행    1.2 디스크의 물리적 구조   디스크의 물리적인 구조: 마그네틱의 원판 으로 구성\n  원판 = 트랙(track) 으로 구성\n 트랙(track) = 섹터(sector) 로 구성    논리블록 단위의 disk 내에 물리적인 위치 = 섹터(Sector)\n 논리 블록 하나가 섹터 하나와 1대1 매핑되어 저장되기 때문 sector 0: 최외곽 실린더의 첫 트랙에 있는 첫 번째 섹터    실린더(Cylinder)\n 상대적 위치가 동일한 트랙들의 집합 track과 거의 유사하게 사용    암(Arm) = disk의 data를 읽고 쓰기 위해서, 해당 섹터가 위치한 실린더로 이동하는 장치\n  헤드(head) = 암에 붙어있는 data를 읽고 쓰는 장치\n  Partitioning\n disk를 하나 이상의 실린더 그룹으로 나누는 과정 OS는 이것을 독립적인 disk 로 취급(logical disk)    1.3 Booting   Logical formatting\n 파일 시스템을 만드는 것  컴퓨터 전원을 키면 이 파일 시스템에 있는 운영체제가 메모리에 올라와서 booting   FAT, inode, free space 등의 구조 포함    Booting 의 간결한 절차 순서\n   disk에 CPU가 직접 접근하지 못 하는데 어떻게 접근하는가???\n  전원 on -\u0026gt; CPU가 ROM의 small bootstrap loader가 실행 -\u0026gt;  ROM: 전원이 나가도 기억하는 소량의 memory small bootstrap loader: booting을 위한 loader   small bootstrp loader의 지시에 의해 sector 0 (boot block)을 memory에 load하여 실행-\u0026gt;  이 sector 0은 어떤 파일 시스템이든 공통이기 때문에, 이 sector 0에 있는 boot block을 메모리에 올려서 실행한다.   OS를 disk에서 load하여 실행  boot block이 file system에서 OS의 kernel 위치를 찾아서 memory에 올려서 실행하라고 지시한다.     2. 디스크 스케쥴링 2.1 접근시간(Access time)의 구성  탐색시간(seek time), 회전지연시간(rotational latency), 전송시간(transfer time)으로 구분\n   탐색시간(seek time)\n disk head를 해당 실린더 위치로 이동시키는데 걸리는 시간    회전지연시간(rotational latency)\n 디스크가 회전해서 읽고 쓰려는 섹터가 헤드 위치에 도달하기까지 걸리는 시간    전송시간(transfer time)\n 해당 sector가 head 위치에 도달한 후, data를 실제로 sector에 읽고 쓰는 데 소요되는 시간    disk I/O에 소요되는 접근시간 최소화 ⇒ disk I/O 효율 상승\n 회전지연시간, 전송시간은 OS가 통제하기 힘들다. 그래서, 탐색시간 을 줄이기 위해 헤드의 움직임을 최소화하는 스케쥴링 작업을 실행한다.    2.2 Disk scheduling 작업  효율적인 disk I/O를 위해 여러 sector들에 대한 I/O 요청이 들어왔을 때, 이들을 어떤 순서로 처리할지 결정하는 mechanism\n  목표: disk head의 이동거리를 줄이는 것  seek time을 최소화하는 것과 유사    2.2.1 FCFS(First Come First Served) scheduling  디스크에 먼저 들어온 요청을 먼저 처리하는 방식\n  은행창구처럼 고정된 장소에서 이뤄지는 게 아니라, 데스크 헤드가 움직이면서 서비스를 하기 때문에, 비효율적 그룹화를 하지 않고 진행하기 때문.  2.2.2 SSTF(Shortest Seek Time First) scheduling  head의 현재 위치로부터 가장 가까운 위치에 있는 요청을 제일 먼저 처리하는 방식\n   문제점: 기아 현상(starvation)\n 헤드 위치에서 멀리 떨어진 곳의 요청은 무한히 기다려야 하는 문제가 발생    이동거리 측면에서 가장 우수한 알고리즘은 아니다.\n  2.2.3 SCAN algorithum  head가 disk 원판의 안쪽 끝과 바깥쪽 끝을 오가며, 그 경로에 존재하는 모든 요청을 처리\n   엘리베이터에서 사용하는 스케쥴링 알고리즘과 유사\n elevator scheduling algorithum 이라 불리기도 한다.    효율성과 형평성을 모두 만족하는 알고리즘\n FCFS처럼 불필요한 헤드의 이동 발생 X SSTF처럼 starvation 현상 발생 X    문제점\n 이동 거리 측면에서 효율적이나, 모든 실린더 위치의 기다리는 시간이 공평한 것 X 제일 안쪽과 바깥쪽 위치보다 가운데 위치가 기다리는 평균시간이 더 짧기 때문    2.2.4 C-SCAN algorithum  출발점에서 다른 쪽 끝으로 이동하며 가는 길목에 있는 모든 요청을 처리하는 것까지 SCAN과 동일하나, 다른 쪽 끝에 도달해 원래 출발점 방향으로 이동할 때, 요청을 처리하지 않고, 바로 이동만 한다.\n  SCAN algorithum을 개선한 것으로, circular-SCAN의 줄임말이다. 장점: 이동거리는 조금 길어지지만, 균일한 탐색시간을 제공  2.2.5 LOOK and C-LOOK algorithum  head가 한쪽 방향으로 이동하다가 그 방향에 더 이상 대기 중인 요청이 없으면 head의 이동 방향을 즉시 반대로 바꾸는 scheduling 방식\n  SCAN과 C-SCAN을 개선한 방식 진행 방향에 요청이 있는지 살핀 후, 이동하기 때문에 LOOK 이라 한다. 지금까지 살펴본 디스크 스케쥴링 기법들 중 LOOK 과 C-LOOK 등의 알고리즘이 많은 시스템에서 FCFS 와 SSTF에 비해 더 효율적인 것으로 알려져있다.   3. Swap-space management   Disk를 사용하는 두 가지 이유\n Memory의 volatile 특성 -\u0026gt; file system 프로그램 실행을 위한 memory 공간 부족 -\u0026gt; swap space (swap area)    Swap space\n Virtual memory system에서는 디스크를 memory의 연장 공간으로서 사용 파일 시스템 내부에 둘 수도 있으나, 별도 partion 사용이 일반적  공간 효율성보다는 속도 효율성이 우선  process가 끝나면 다 사라져버리는 내용이기 때문에, 공간효율성보다는 속도 효율성이 중요하다.   일반 파일보다 훨씬 짧은 시간만 존재하고 자주 참조된다. 따라서, block의 크기 및 저장 방식이 일반 파일 시스템과 다름       4. 다중 디스크 환경에서의 스케쥴링(RAID)   RAID(Redundant Array of Independent Disks)\n 여러 개의 disk를 묶어서 사용    어디서 다중 디스크를 사용하는가???\n 동시 사용자가 많은 서버에서는 다수의 disk를 함께 사용한다.    RAID의 사용 목적과 장점\n  디스크 처리 속도 향상\n 여러 disk에 block의 내용을 분산 저장 병렬적으로 읽어온다.    신뢰성(Reliability) 향상\n 동일 정보를 여러 디스크에 중복 저장 -\u0026gt; 동시 서비스 가능 하나의 디스크가 고장 시, 다른 디스크에서 읽어온다. 단순한 중복 저장이 아니라, 일부 디스크에 parity를 저장하여 공간의 효율성을 높일 수 있다.      다중 디스크의 문제와 스케쥴링 목적\n 다중 디스크 환경에서는 어느 디스크에서 요청을 처리할지 결정하는 스케쥴링 문제까지 포함 다중 디스크 환경에서의 스케쥴링 목적: 부하 균형(load balancing)을 이루면서 확장성 있는 서비스가 목표  일부 디스크가 과부하에 걸리지 않도록, 모든 디스크에 골고루 분배하도록 스케쥴링      다중 디스크 스케쥴링의 또 다른 목표: 전력 소모 감소\n 하나의 디스크로부터 요청을 충분히 감당할 수 있을 때, 다른 디스크들의 회전은 정지하는 게 효율적 유사한 예시: 그룹 엘리베이터  이웃한 여러 대의 엘리베이터가 독립적으로 운영되는 게 아니라, 동일한 제어 시스템에 의해서 공동으로 운영된다. 목표: 다수의 승객이 오래 기다리지 않고, 빠른 서비스를 받는 시스템의 확장성 사용자가 적을 경우, 한 대의 엘리베이터로 운행하는 게 효율적       5. 디스크의 저전력 관리 5.1 비활성화 기법   디스크의 상태는 전력소모를 기준으로 4가지 상태로 나뉜다.\n 활동(active) 상태: 현재 head가 data를 읽거나 쓰고 있는 상태 공회전(idle) 상태: disk가 회전 중이지만, data를 읽거나 쓰지 않는 상태 준비(standby) : disk 회전하지 않지만, interface가 활성화된 상태 휴면(sleep) 상태: disk 회전 X, interface 비활성화    활성 상태와 비활성 상태\n 활성 상태 = active + idle 비활성 상태 = standby + sleep    전력 소모 관점에서의 상태\n  전력 소모가 비활성 상태일 때, 더 적다.\n  각 상태로 전환 시, 부가적인 전력 및 시간 소모된다.\n  후속 요청까지의 시간 간격이 일정 시간 이상이어야만, 디스크의 회전을 정지시키는 것이 전력 소모 절감에 효과적\n  비활성화 시점을 결정하는 게 중요하다는 것\n    디스크 비활성화 시점 결정 방법\n 시간기반(timeout based): 일정 시간 동안 디스크가 공회전 상태이면 장치를 정지 → 요청이 들어오면 디스크 활성화 예측기반(prediction based): 과거 요청을 관찰하여, 다음 공회전 구간의 길이를 예측 후, 비활성화 시점 결정 확률기반(stochastic based): 확률분포를 사용    5.2 회전속도 조절 기법  디스크의 회전속도(RPM)를 가변적으로 조절하는 기법 OS는 시스템 자원과 부하를 포괄적으로 볼 수 있기 때문에, 하드웨어 혼자보다 더 많은 전력 절감 효과 얻음 멀티미디어 환경에서는 미래의 참조 예측이 비교적 정확해서 전력 소모를 줄일 수 있다.  5.3 디스크의 데이터 배치 기법  데이터의 복제본을 많이 만들어, 헤드 위치에서 가까운 복제본에 접근하여 빠른 응답시간과 전력 소모량 절감을 얻는 FS2 file 시스템(free space file system)  5.4 버퍼캐싱 및 사전인출 기법  전제:미래에 요청할 데이터를 미리 알거나, 어느 정도 예측할 수 있다면  활성 상태일 때 헤드 위치로부터 가까운 데이터를 사전 인출하여, 디스크의 비활성화 가능성을 높여 전력 소모를 줄임    5.5 쓰기전략을 통한 저전력 디스크 기법  디스크가 비활성화 상태일 때는 기다리다가, 활성 상태일 때 쓰는 방식으로 전력 소모를 줄이는 방안   Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_11_%EB%94%94%EC%8A%A4%ED%81%AC%EA%B4%80%EB%A6%AC/","summary":"디스크의 물리적인 구조는 어떻고, 이 디스크 스케쥴링이 왜 필요하고 어떤 알고리즘들로 스케쥴링되는지, disk의 역할 2가지는 무엇인지, 다중 디스크 상황의 장점은 무엇인지 알아본다.","title":"[TIL] OS Chapter 11: 디스크 관리"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.     운영체제는 보통 모든 프로그램들에 공평하게 같은 크기의 메모리를 할당하기보다는 몇몇 프로그램들에게 집중적으로 메모리를 할당한 후, 시간이 흐르면 이들로부터 메모리를 회수해서 다른 프로그램들에게 다시 집중적으로 메모리를 할당하는 방식을 채택한다.\n  왜냐하면 프로세스의 빠른 수행을 위해 프로그램마다 최소한 확보해야하는 메모리 크기가 존재 하기 때문이다.\n  하지만 그렇다고 프로세스의 주소 공간 전체가 메모리에 올라와 있어야 하는 것은 아니다. 운영체제는 CPU에서 당장 수행할 부분만을 메모리에 올려놓고, 그렇지 않은 부분은 disk의 swap area에 내려놓았다가 다시 필요해지면 메모리에 올라가 있는 부분과 교체하는 방식을 사용한다.\n  또한, 프로그램은 0번지부터 시작하는 자기 자신만의 메모리 공간을 가정한다. 이러한 공간을 Virtual memory(가상 메모리) 이라 한다. 이 가상 공간 중 일부가 swap area에존재하고, 일부는 물리적 메모리에 존재하는 것이다.\n  이 가상 메모리를 적재하는 단위에 따라 요구 페이징 또는 요구 세그먼테이션 방식으로 나눠진다. 전자는 대부분의 경우에 사용되며, 세부적인 구현에 특히 사용된다. 후자는 paged segmentation 기법을 사용하는 경우를 말한다.\n  그러면 요구 페이징에 대해 먼저 알아보자.\n   1. 요구 페이징  프로그램 실행 시 프로세스를 구성하는 모든 페이지를 한꺼번에 메모리에 올리는 게 아닌, 당장 사용될 페이지만을 올리는 방식\n   특정 페이지에 대한 CPU 요청이 들어온 후에야 해당 페이지를 메모리에 적재한다.\n  비유: 매 끼니마다 필요한 분량만큼 재료를 구입해서 보관하는 방식\n 냉장고: 물리적 메모리 식재료: 프로세스를구성하는 페이지 보관 행위: 페이지를 메모리에 적재    장점\n 필요한 부분만을 적재하기 때문에,  메모리 사용량 감소, I/O 양 감소 -\u0026gt; 응답시간 단축 프로세스 전체를 메모리에 올리는데 소요되는 입출력 오버헤드 감소 더 많은 프로세스 수용 물리적 메모리 용량 제약에서 벗어남      Problem\n 가상 메모리 중 어떤 페이지가 메모리에 존재하는지 유무를 구별하기 위한 방안 필요    Solution\n 유효-무효(Valid - Invalid bit)를 두어 page가 각 memory에 존재하는지 표시 모든 page에 대해 존재해야 하므로, page table의각 항목별로 저장    Valid - Invalid bit\n  기본 bit 값: invalid bit\n  특정 페이지가 참조되어 메모리에 적재 → Valid bit → 적재된 page가 swap area로 쫓겨남 → Invalid bit\n  Invalid bit 는 언제일 때를 말하는가?\n 해당 페이지가 물리적 메모리에 없는 경우 페이지가 속한 주소 영역을 프로세스가 사용하지 않은 경우 물리적 메모리에 A,C,G가 올라가 있기 때문에, 이에 해당하는 page table의 0, 2, 6이 valid라는 걸 확인할 수 있다.       Page fault  CPU가 한 페이지를 참조하려는데, 요청한 페이지가 메모리에 없어서 invalid bit인 경우를 말한다.    1.1 요구 페이징의 페이지 부재 처리   CPU가 무효 페이지에 접근 → 주소 변환 담당 MMU가 페이지 부재 트랩(page fault trap) 발생 → kernel mode로 전환 → OS의 페이지 부재 처리루틴(page fault handler)이 호출\n  OS의 처리 과정\n  OS는 프로세스의 해당 페이지에 대한 접근이 적법한지 먼저 체크 (reference)\n 사용되지 않는 주소 영역에 속한 페이지에 접근하려거나, 해당 페이지에 대한 접근 권한 위반(protection violation)을 했을 경우, 해당 프로세스를 종료 protection violtaion: read-only file에 write 시도를 한 경우    → 적법 판정 → 물리적 메모리의 빈 frame을 할당받아 이 공간에 해당 페이지를 적재.\n 빈 frame이 없다면, 물리적 메모리에 적재된 페이지 중 하나를 swap out    → 요청한 페이지를 디스크로부터 물리적 메모리에 적재하기(disk I/O 작업을 의미)까지 오랜 시간이 걸리므로, CPU를 빼앗기고 봉쇄 상태(block state)가 됨\n 현재까지 수행되던 프로세스는 CPU register state 및 PC value를 PCB에 저장하여, 나중에 이 프로세스를 재할당 시, 정확히 같은 상태에서 다음 instruction을 수행.    → I/O 작업이 완료되어 interrupt가 발생하면 page table에서 해당 page의 valid-invalid bit를 valid bit로 설정 (reset page table)\n  → 봉쇄된 process를 ready queue로 이동\n  → 다시 CPU를 잡고 running 하며 아까 중단되었던 instruction을 재개한다.\n    1.2요구 페이징의 성능  페이지 부재의 발생 빈도  페이지 부재로 인해 페이지 교체가 이뤄지는 과정에서 요청된 페이지를 디스크에서 메모리로 읽어오는 disk input/output 과 각종 overhead가 포함되어 시간이 오래 걸린다. 그래서 유효 접근 시간 이 짧을 수록 성능 향상     2. 페이지 교체   페이지 교체(page replacement)란?\n 페이지 부재가 발생 시, 요청 페이지를 디스크에서 메모리로 불러오기 위에 메모리에 적재된 여러 페이지 중 하나를 swap out하여 요청된 페이지를 메모리에 적재하는 것    교체 알고리즘(replacement algoritum)\n 페이지 교체 시, 어떤 프레임에 있는 페이지를 쫓아 낼지 결정하는 알고리즘 페이지 부재 발생비율(page-fault rate)을 최소화하는 것이 목표 평가 기준: 주어진 페이지 참조열에 대해 페이지 부재를 얼마나 내는지 조사  가까운 미래에 참조될 가능성이 적은 페이지를 내쫓는 것이 성능 향상 방안      페이지 참조열(page reference string)\n 참조되는 페이지들의 번호를 시간 순서에 따라 나열한 것  예) 1,2,3,4,1,2,5,1,2,3,4,5      2.1 최적 페이지(Optimal Algorithum) 교체   Belady’s optimal algorithum (빌레디의 최적 알고리즘) = MIN, OPT\n 페이지 부재율을 최소화하기 위해, 메모리에 존재하는 페이지 중 가까운 미래에 참조될 페이지를 쫓아내는 것    다른 알고리즘의 Upper bound\n 어떠한 알고리즘보다도 가장 적은 페이지 부재율을 보장 하므로 다른 알고리즘 성능에 대한 상한선(Upper bound) 를 제공한다. 그래서 어떤 교체 알고리즘이 이 알고리즘과 유사하다면 더 이상의 알고리즘 연구가 필요하지 않음을 시사한다.      예시\n 4 frames example 처음 페이지 참조 시에는 4회까지 페이지 부재가 불가피하다. 5, 6회는 이미 페이지가 존재하기 때문에 발생하지 않는다. 7회에서 페이지 5를 참조 시, 페이지 부재가 발생하여 디스크에서 메모리로 가져오는 작업이 필요하다. 이 때 페이지 교체를 해야 하는데, 가장 먼 미래에 참조될 페이지인 4번 페이지와 교체된다. 그래서 총 6번의 페이지 부재가 발생한다.    Offline algorithum\n 미래에 어떤 페이지가 참조될지 미리 알고 있다는 전제 이므로, 온라인에서 사용할 수 없어서 offline algorithum 이라 한다.    이 이후에 알고리즘은 미래를 모르는 알고리즘들이다.\n  2.2 선입선출(FIFO:First In First Out) 알고리즘  물리적 메모리에 먼저 올라온 페이지를 우선적으로 내쫓는 알고리즘  향후 참조 가능성 고려 X 물리적 메모리에 들어온 순서대로 대상 선정      페이지 프레임을 늘린다고, page fault가 줄어드는 게 아니다.\n  페이지 프레임 3개\n 9번의 페이지 부재    페이지 프레임 4개\n 10번의 페이지 부재      2.3 LRU(Least Recently Used) 알고리즘  교체 알고리즘으로 가장 많이 사용된다. 시간지역성(Temporal locality)이 낮은 페이지를 쫓아내는 알고리즘  시간 지역성: 최근에 참조된 페이지가 가까운 미래에 다시 참조될 가능성이 높은 성질 가장 오래 전에 참조된 것을 지워서, 참조 횟수는 고려하지 않는다.    2.4 LFU(Least Frequently used) 알고리즘   물리적 메모리 내에 존재하는 페이지 중 과거에 참조 횟수(reference count)가 가장 적은 페이지로 교체 페이지를 결정하는 알고리즘\n 최저 참조 횟수를 가진 페이지가 여러 개일 경우, 상대적으로 더 오래전에 참조된 페이지를 쫓아낸다.    참조 횟수를 계산하는 방식에 따라 Incache-LFU 와 Perfect-LFU 로 나눠진다.\n  Incache-LFU\n page가 물리적 메모리에 올라온 후부터의 참조 횟수를 카운트하는 방식 그래서 메모리에서 내려갔다가 다시 적재되면 참조 횟수는 초기화된다.    Perfect-LFU\n 메모리에 적재여부와 상관없이 그 페이지의 과거 총 참조 횟수를 카운트하는 방식 장점: 페이지의 참조 횟수를 정확히 반영 단점: 메모리에서 쫓겨난 페이지의 참조 기록까지 모두 보관하고 있어야 하므로, 오버헤드가 상대적으로 더 크다.    장단점\n 장점: LFU 알고리즘은 LRU알고리즘보다 오랜 시간 참조 기록을 보기 때문에, 더 정확히 반영 가능 단점: 참조 시점의 최근성을 반영 X, LRU보다 구현 복잡    2.5 클럭(Clock) 알고리즘  하드웨어적 지원을 통해 알고리즘의 운영 오버헤드를 줄인 방식\n  그래서 LRU 비해 페이지의 관리가 훨씬 빠르고 효율적으로 이뤄지기 때문에, 일반적으로 페이지 교체 알고리즘으로 클럭 알고리즘을 선택한다. LRU의 근사 알고리즘으로서, 다음과 같이 불린다.  Second chance algorithum NUR(Not Used Recently) NRU(Not Recently Used)   LRU는 가장 오래 전에 참조된 페이지를 교체하는 것에 비해 클럭 알고리즘은 오랫동안 참조되지 않은 페이지 중 하나를 교체하기 때문에, 가장 오래되었다는 건 보장하지 못한다.    그림 설명\n 직사각형= 물리적 메모리 안에 있는 페이지(= 페이지 프레임)를 의미    교체할 페이지 선정을 위해 HW가 세팅한 페이지 프레임들의 참조 비트(reference bit) 를 순차적으로 OS가 조사한다.\n pointer 이동 중에 reference bit 1은 모두 0으로 바꾼다. reference bit가 0인 것을 찾으면 그 페이지를 교체한다. 한 바퀴 되돌아와서도 (=second chance) 0 이면 그 때 교체된다. 자주 사용되는 페이지라면 second chance가 올 때 1    Clock algorithum의 개선\n HW가 bit를 setting reference bit = 0: 한 바퀴 도는 동안 이 페이지에 대한 참조가 없었다는 의미 reference bit = 1: 한 바퀴 도는 동안 적어도 한 번 참조된 페이지 modified bit = 1: 최근에 변경된 페이지(I/O를 동반하는 페이지)     3. 페이지 프레임의 할당(allocation) 프로세스 여러 개가 동시에 수행되는 상황에서 각 프로세스에 얼마만큼의 메모리 공간을 할당할 것인지 결정해야 한다. 이를 위한 알고리즘을 3가지로 나눌 수 있다.\n  첫 번째, 균등할당(equal algorithum)\n 모든 프로세스에게 페이지 프레임을 균일하게 할당하는 방식    두 번째, 비례할당(proportional allocation)\n 프로세스의 크기에 비례해서 페이지 프레임을 할당하는 방식    세 번째, 우선순위 할당(priority allocation)\n 프로세스의 우선순위에 따라 페이지 프레임을 다르게 할당하는 방식 당장 CPU에서 실행될 프로세스와 아닌 프로세스를 구분하여 전자 쪽에 더 많은 페이지 프레임을 할당하는 방식    할당 알고리즘만으로는 process의 페이지 아래의 참조 특성을 제대로 반영하지 못한다.\n 첫 번째, 명령어 수행을 위해 최소한 할당되어야 하는 frame의 수가 존재 두 번째, Loop(반복문)를 구성하는 page들은 한꺼번에 할당되는게 유리하다.  최소한의 allocation이 없으면 매 loop마다 page fault 발생   세 번째, 프로세스에게 최소한으로 필요한 메모리의 양은 시간에 따라 다르다.  그래서, 종합적인 상황을 고려해서 각 프로세스에 할당되는 페이지 프레임의 수를 결정해야 한다.\n경우에 따라서는, 최소한의 메모리 요구량을 충족시키기 위해 일부 프로세스에게 메모리를 할당하지 않아야 한다.\n 4. 전역교체와 지역교체 (Global vs. Local replacement) 교체할 페이지를 선정할 때, 교체 대상이 될 프레임의 범위에 따라 다음 2가지로 구분된다.\n  전역 교체(global replacement)\n  프로세스마다 미리 메모리를 할당하는 게 아닌, 전체 메모리를 공유해서 사용하고 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법\n 그래서 replace 시, 다른 process에게 할당된 frame도 빼앗아 올 수 있다. (경쟁)\n= 모든 페이지 프레임이 교체 대상 = Process 별 프레임 할당량을 조절하는 또 다른 방법    FIFO, LRU, LFU 등의 알고리즘을 사용하다보면 전체 시스템 차원에서 특정 페이지가 알아서 메모리에 올라가기 때문에 frame 할당량이 알아서 조절된다.\n  다음 절의 working set, PFF 알고리즘의 경우, 프로그램이 최소한 필요로 하는 할당 효과가 있는 알고리즘이기 때문에, 전역교체 방법으로 사용될 수 있다.\n    지역 교체(local replacement)\n 프로세스마다 페이지 프레임을 미리 할당하는 것 현재 수행 중인 프로세스에게 할당된 frame 내에서만 빼앗아올 수 있는 방법  frame 할당 알고리즘은 균등할당, 비례할당, 우선순위 할당으로 프로세스에게 미리 할당한다.   프로세스가 FIFO, LRU, LFU 등의 알고리즘을 독자적으로 운영할 때, 사용되는 방법     5. 스레싱(thrashing)  프로세스가 원활히 수행되기 위한 일정 수준 이상의 페이지 프레임을 할당받지 못하여 page fault가 지나치게 발생하는 상황\n Thrashinig의 자세한 발생 과정 프로세스에게 일정 수준 이상의 페이지 프레임 할당 X → 페이지 부재율이 크게 상승 → CPU 이용률이 급격히 하락\n→ 낮은 CPU 이용률 -\u0026gt; OS가 메모리에 올라가는 프로세스의 수 증가 = 다중 프로그래밍의 정도(Multi-Programming Degree: MPD) 증가 →\n MPD를 OS가 높이는 이유는 OS에게 CPU 이용률이 낮다는 건, 프로세스의 수가 너무 적고, 프로세스가 모두 I/O 작업을 하여 ready queue가 비는 경우를 의미한다.\n → 과도한 MPD 상승 -\u0026gt; 프로세스 당 할당되는 메모리 양이 지나치게 감소 -\u0026gt; 빈번한 페이지 부재 발생 → 페이지 교체하며 swap in \u0026amp; swap out이 지속적으로 발생 -\u0026gt; CPU 이용률 다시 감소 → 2번 과정 다시 수행\n  swap in \u0026amp; swap out 작업 과정\n I/O 작업을 수반 → 문맥교환을 통해 다른 프로세스에게 CPU 이양 → 다른 프로세스에게도 할당받은 메모리 양이 적으면 페이지 부재 발생 그래서 ready queue에 있는 모든 프로세스에게 CPU가 한 차례씩 할당되었는데도 모든 프로세스가 다 페이지 부재가 발생.    결국 낮은 처리량(low throughput)을 가진다.\n  이렇게 1번에서 5번 과정이 계속 반복되는 것을 스레싱이라 한다.\n  Thrashing graph  위 과정을 그래프로 나타낸 것이 다음과 같다.    프로그램이 1개일 때는 메모리를 쓰다가 I/O 하는 동안 CPU가 쉰다.\n  그래서 프로그램이 I/O 작업 시, 다른 프로세스에게 CPU 이양하여 CPU 이용률을 높인다.\n  하지만, 프로세스의 수를 증가시키면 오히려 CPU 이용률이 뚝 떨어진다.\n  왜냐하면 thrashing이 발생했기 때문이다.\n  그래서 CPU 이용률을 최대한 높이면서 MPD를 조절하는 게 중요하다.\n  이를 조절하는 알고리즘이 워킹셋(working-set algorithum) 과 페이지 부재 빈도 알고리즘(page-fault frequency scheme) 이 있다.\n  5.1 워킹셋(working-set) 알고리즘  지역성 집합이 메모리에 동시 올라갈 수 있도록 보장하는 메모리 관리 알고리즘\n   Locality of reference\n 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조하는 현상    Locality set(지역성 집합)\n 집중적으로 참조되는 해당 page들의 집합    Working-set 이란?\n 프로세스가 일정 시간 동안 원활히 수행되기 위해, 한꺼번에 메모리에 올라와 있어야 하는 페이지들의 집합 working-set에서의 locality set    MPD 조절 방법\n 프로세스의 워킹셋을 구성하는 페이지들이 한꺼번에 메모리에 올라갈 수 있는 경우에만, 그 프로세스에게 메모리를 할당 그렇지 않으면 프로세스에게 할당된 페이지 프레임들을 모두 반납한 후, 프로세스의 주소 공간 전체를 disk로 swap out한다.    5.1.1 Working-set algorithum 구현   Working Set(WS) 결정하기\n working-set window를 사용한다. window의 크기: Δ time interval 사이에 참조된 서로 다른 페이지들의 집합 WS 크기는 변한다.    working set 크기와 frame 수에 따른 MPD 제어\n 워킹셋 크기 합 \u0026gt; frame 수 → 일부 프로세스를 스왑 아웃 → 남은 프로세스의 워킹셋이 메모리에 모두 올라가는 것을 보장 ⇒ MPD 감소 효과 워킹셋 크기 합 \u0026lt; frame 수 → swap out한 프로세스를 다시 메모리에 적재 → working set을 할당 → MPD를 증가 위 두 가지 방식으로 thrasing을 방지 window의 크기가 너무 작으면, 지역성 집합을 모두 수용 X window의 크기가 너무 크면, 여러 규모의 지역성 집합 수용 가능하지만, MPD가 감소 → CPU 이용률 감소    5.2 페이지 부재 빈도(page fault frequency: PFF) 알고리즘  프로세스의 페이지 부재율을 주기적으로 조사하고, 이 값에 근거해서 각 프로세스에 할당할 메모리 양을 조절하여 MPD를 조절하면서 CPU 이용률을 높이는 알고리즘\n   page-fault rate의 상한값과 하한값을 둔다\n Page fault rate이 상한값을 넘으면 frame을 더 할당한다. Page fault rate이 하한값 이하이면 할당 frame 수를 줄인다.    빈 frame이 없으면 일부 프로세스를 swap out한다.\n  모든 프로세스에게 프레임을 다 할당한 후에도 프레임이 남는 경우, 위의 swap out된 process에게 frame을 할당하여 MPD를 높인다.\n   Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 - 운영체제와 정보기술의 원리 - 반효경 지음 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_10_%EA%B0%80%EC%83%81%EB%A9%94%EB%AA%A8%EB%A6%AC/","summary":"가상 메모리를 관리하기 위한 방법으로 demanding paging에 대해 알아본다. 그리고, 페이지 교체는 어떠한 순서로 이뤄지는지, 프로세스에 프레임은 어떤 알고리즘을 통해서 할당되는지, 전역 교체와 지역교체는 무엇인지 마지막으로 thrashing 상황과 MPD 개념에 대해 알아본다.","title":"[TIL] OS Chapter 10: 가상 메모리"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않고, kocw 이화여자대학교 운영체제 -반효경 교수- 강의만 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. The Deadlock Problem  deadlock이 현실 사례 비유  누군가가 희생하지 않으면 교착 상태는 발생하지 않는다. 즉, 각자 일부 자원을 가지고 있으면서, 상대방이 가지고 있는 걸 요구하는 상황    1.1 Deadlock이란??  일련의 프로세스들이 서로가 가진 자원을 기다리며 block된 상태\n 1.2 Resource (자원)이란??   하드웨어, 소프트웨어 등을 포함하는 개념 (예) I/O device, CPU cycle, memory space, semaphore 등     프로세스가 자원을 사용하는 절차\n Request(요청) → Allocate(할당) → Use(사용) → Release(반납)    Deadlock Example 1\n 시스템에 2개의 tape drive가 있다. 프로세스 P1과 P2 각각이 하나의 tape drive를 보유한 채 다른 하나를 기다리고 있다.    Deadlock Example 2\n Binary semaphore A and B Po: P(A) → P(B) P1: P(B) → P(A)  Po는 A를 획득한 후, B를 얻고 싶어한다. P1은 반대다. 서로 반대 것을 가지고 있기 때문에, Deadlock 상황이다.       2. Deadlock 발생의 4가지 조건  아래 4가지 조건을 다 만족해야 deadlock이 발생한다.\n   첫 번째: Mutal exclusion (상호 배제)\n 매 순간 하나의 프로세스만이 자원을 사용할 수 있다. (독점적 사용)    두 번째: No preemption (비선점)\n 프로세스는 자원을 스스로 내어놓을 뿐 강제로 빼앗기지 않는다.    세 번째: Hold and wait\n 자원을 가진 프로세스가 다른 자원을 기다릴 때, 보유 자원을 놓지 않고 계속 가지고 있는다.    네 번째: Circular wait\n 자원을 기다리는 프로세스 간에 사이클이 형성되어야 한다. 프로세스 Po, P1, \u0026hellip;. ,Pn이 있을 때  Po는 P1이 가진 자원을 기다린다. P1은 P2가 가진 자원을 기다린다. Pn-1은 Pn이 가진 자원을 기다린다. Pn은 Po이 가진 자원을 기다린다.       3. Resource - Allocation Graph  Deadlock 발생하는지 확인하기 위해, resource - allocation graph (자원 할당 그래프)를 그려본다.\n 3.1 Graph 설명   Vertex (= 꼭지점, 정점)\n Process P = {P1. P2, \u0026hellip;., Pn} Resource R = {R1, R2,\u0026hellip;,Rm}    Edge (= 화살표 )\n Pi → Rj: request edge = Pi가 Rj 자원을 요청한다. Rj → Pi: assignment edge = Rj 자원을 Pi 자원이 가지고 있다.    자원의 점은 instance를 의미한다\n  3.2 deadlock 확인하기 그래프에 deadlock이 있는지 어떻게 알 수 있을까?\n graph에 cycle 유무에 따라 deadlock을 판단할 수 있다.\n   1번, Cycle 無 in graph -\u0026gt; deadlock X\n  2번 Cycle 有 in graph -\u0026gt;\n 2-1번 one instance per resource -\u0026gt; deadlock O 2-2번 multiple intsnace per resource -\u0026gt; deadlock X \u0026amp; 가능성 O      오른쪽 graph: 2-2번 case\n P4가 resource를 다 사용 후, 반납하면 P3는 이용가능해진다. P2 또한 resource를 다 사용하고 반납하면 P1이 사용가능하다. 한 resource에 여러 개의 instance가 존재하기 때문에 deadlock이 아니다.    왼쪽 graph: 2-1번 case\n R2 자원을 P1과 P2가 가지고 있으면서, P3가 이 자원을 요청하는 상황이기 때문에, deadlock 이다.     4. Deadlock 처리 방법 위로 올라갈수록 강한 방법이다. 하지만, 맨 마지막 방법을 대부분의 OS가 채택하는 이유는 deadlock을 탐색하는 것과 deadlock에 대처하는 것 모든 것이 overhead이기 때문이다.\n  첫 번째, Deadlock Prevention\n 자원 할당 시, deadlock의 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것    두 번째, Deadlock Avoidance\n 자원 요청에 대한 부가적인 정보를 이용해서 deadlock의 가능성이 없는 경우에만 자원을 할당 시스템 state가 원래 state로 돌아올 수 있는 경우에만 자원 할당    세 번째, Deadlock Detection and recovery\n Deadlock 발생은 허용하되, 그에 대한 detection routine을 두어 deadlock 발견시 recover    네 번째, Deadlock Ignorance\n Deadlock을 시스템이 책임지지 않는다. Unix를 포함한 대부분의 OS가 채택  Deadlock은 빈번히 발생하는 문제가 아니기 때문에, 이를 방지하기 위해 오히려 많은 overhead가 발생하기 때문에, 이 방식을 택한다.      4.1 Deadlock 처리 방법 첫 번째: deadlock prevention  Process가 resource를 요구하는 방식에 제한을 두는 방식으로, deadlock이 발생하는 4가지 필요 조건 중 어느 하나가 만족되지 않도록 하는 것\n   Mutual Exclusion\n 공유해서는 안되는 자원의 경우, 반드시 성립해야 한다. 따라서, 이 조건의 발생을 막아 deadlock을 해결하는 건 불가능하다.    Hold and wait 조건에 대한 방법\n  프로세스가 자원을 요청할 때, 다른 어떤 자원도 가지고 있지 않기\n  방법 1: 프로세스 시작 시, 모든 필요한 자원을 할당받는 방법\n 다 사용하고 나서 자원을 반납한다.    방법 2: 자원이 필요할 경우, 보유 자원을 모두 놓고 다시 요청\n hold한 자원을 다 뱉는다.    하지만, 한 번에 한 프로세스만 자원을 소유할 수 있어서 효율적이지 않다.\n  starvation이 발생할 수 있고, throughput이 낮다.\n    No Preemption 조건에 대한 방법\n Preemption을 허락하기 Process가 어떤 자원을 기다려야 하는 경우, 이미 보유한 자원이 선점된다. 모든 필요한 자원을 얻을 수 있을 때, 그 프로세스는 다시 시작된다.  이 때, starvation이 발생할 수 있다.   state를 쉽게 save하고, restore할 수 있는 자원에서 주로 사용(CPU, memory)    Circular wait 막기\n 모든 자원 유형에 할당 순서를 정하여 정해진 순서대로만 자원을 할당하기 예를 들어 순서가 3인 자원 Ri를 보유 중인 프로세스가 순서가 1인 자원 Rj를 할당받기 위해서는 우선 Rj를 release해야 한다.    하지만, 생기지도 않을 수 있는 이런 제약들로 인해서 다음과 같은 문제점을 낳기 때문에, 이 방법은 잘 사용하지 않는다.\n⇒ Utilization 저하, throughout 감소, starvation 문제\n 4.2 Deadlock 처리 방법 두 번째: deadlock avoidance  자원에 대한 사전 정보를 이용해서 deadlock의 발생 가능성을 계속 검사하여, resource-allocation state가 safe state인 경우에만 자원을 할당하는 방식\n   자원에 대한 사전 정보\n 가장 단순하고 일반적인 예: 프로세스들이 필요로 하는 각 자원별 최대 사용량을 미리 선언    safe state란??\n 시스템 내의 프로세스들에 대한 safe sequence 가 존재하는 상태 순서가 어떻든 safe sequence가 존재하면 safe state다. 시스템이  safe state이면 no deadlock unsafe state이면 possibility of deadlock 존재      safe sequence란??\n n개의 프로세스 중 하나인 Pi(1≤ i ≤ n)의 자원요청이 가용 자원 + 모든 P_j(j \u0026lt; i)의 보유자원 에 의해 충족되는 순서 safe sequence가 존재하면 cycle을 형성하지 않는다. 조건을 만족하면 다음 방법으로 모든 프로세스의 수행을 보장한다.  Pi의 자원 요청이 즉시 충족될 수 없으면 모든 Pj(j \u0026lt;p i) 가 종료될 때까지 기다린다. P(i-1)이 종료되면 Pi의 자원 요청을 만족시켜 수행한다.      Deadlock Avoidance\n 시스템이 unsafe state에 들어가지 않는 것을 보장한다. 2가지 경우의 avoidance algorithum  single instance per resource types  Resource Allocation Graph algorithum 사용   Multiple instances per resource types  Banker’s Algorithum (은행원 알고리즘) 사용        4.2.1 Resource Allocation Graph algorithum: single instance per resource types  위의 resource allocation graph algorithum에 claim edge 를 추가한다. Claim edge (점선): Pi → Rj  프로세스 Pi가 자원 Rj를 미래에 요청할 수 있음을 뜻한다. 프로세스가 해당 자원 요청 시 request edge로 바뀐다. (실선: 소유하고 있다) Rj가 release되면 assignment edge는 다시 claim edge로 바뀐다.   request edge의 assignment edge 변경 시(점선을 포함하여), cycle이 생기지 않는 경우에만 요청 자원을 할당. Cycle 생성 여부 조사 시, 프로세스의 수가 n일 때 O(n^2)의 Time Complexity 를 가진다.  4.2.2 Banker’s Algorithum: multiple instances per resource types   위의 single instance일 때를 넘어서 일반화하는 algorithum 이용 가능한 자원으로 요청 양을 만족할 수 있는지 판단한다. 충족할 수 있으면 이 프로세스의 요청은 다 받아들이고, 충족되지 않으면 다 받아들여지지 않는다.     가정\n 모든 프로세스는 자원의 최대 사용량을 미리 명시  avoidance 설명대로 각 자원 별 최대 사용량을 미리 선언한 것   프로세스가 요청 자원을 모두 할당받은 경우, 유한 시간 안에 이들 자원을 다시 반납 이 알고리즘은 최악의 상황을 가정한다.    방법\n 기본 개념: 자원 요청 시, safe 상태를 유지할 경우에만 할당한다.  충분히 할당할 수 있는 자원의 수가 있어도, safe 상태를 유지하지 못하면 할당하지 않는다는 의미   총 요청 자원의 수가 가용 자원의 수보다 적은 프로세스를 선택  그런 프로세스가 없으면 unsafe 상태   그런 프로세스가 있으면 그 프로세스에게 자원을 할당 할당(allocation)받은 프로세스가 종료되면 모든 자원을 반납 (available이 된다.) 모든 프로세스가 종료될 때까지 이러한 과정 반복    사전 정보\n Allocation: 각 프로세스에 할당된 각 자원의 양 Max: 각 프로세스의 자원별로 최대 요구하는 자원의 양 Available: 각 자원 별로 현재 남아있는 자원의 양 Need: 각 프로세스의 추가로 요청 가능한 자원의 양      Resource\n 총 자원: A 10개,B 5개, C 7개 A = 2 + 3 + 2 = 7 이고, 가용자원으로 A가 3개임을 확인할 수 있다. P0의 할당된 자원 B를 반납하면 이용가능한 B 자원의 수는 늘어난다.    safe sequence\n  P0: P0에 추가로 할당할 수 있는 자원이 존재하지만, Need한 만큼 요청하면 가용자원만으로는 불가능하기 때문에, 요청을 받아들이지 않고, 기다린다.\n  P1: 최대 필요 요청은 가용 자원으로 충분히 가능하기 때문에, P0와 달리 받아들인다.\n  P1이 가용자원을 가져가서 다 사용 후, 자원을 반납하면 available resource에 추가되고 P3가 그걸로 가능하다.\n 이런 순서가 나타나는게 P1,P3,P4,P2,P0다. 이런 순서가 존재하면 절대 dead lock이 발생하지 않는 safe state다.      뱅커스 알고리즘 이렇게 최대요청을 해도 deadlock이 발생하지 않는 상황에서만 요청을 받아들여 deadlock을 피해간다.\n 하지만, 이는 혹시 모를 상황을 대비하기 때문에 비효율적이다.     4.3 Deadlock Detection and Recovery  알고리즘을 통해 현재 시스템에 deadlock이 있는지 찾고, 알고리즘을 통해 deadlock을 복구하는 것\n 4.3.1 Single instance per resource type  wait-for graph algorithum을 사용하며, deadlock detection을 하기 위해서는 wait-for graph에서 cycle이 있는지를 판단한다.\n   wait-for graph\n  cycle이 곧 deadlock을 의미한다.\n  자원 할당 그래프의 변형\n  프로세스만으로 node 구성\n  Edge 의미\n Pk → Pj: Pj가 가지고 있는 자원을 Pk가 기다리는 경우 R(resource) → P: 이 자원을 P가 소유하고 있다. P -\u0026gt; R(resource): P가 이 자원을 요청한다. 자원의 최대 사용량을 미리 알릴 필요가 없기 때문에, 그래프에 점선이 없다.      algorithum\n wait-for grpah에 cycle이 존재하는지를 주기적으로 조사 O(n^(2))    Resource-allocation graph에서 자원을 빼면 coreesponding wait-for graph가 된다.\n  4.3.1 Multiple instance per resource type  deadlock 찾는 방법은 banker’s algorithum과 유사한 방법 활용\n   Deadlock 존재 유무를 판단하기 위해서는 deadlock avoidance와 반대로 매우 보수적인 판단이 아닌, 긍정적인 판단을 해야 한다.\n 긍정적으로 바라보기 때문에, 각 프로세스는 가지고 있는 자원을 반납할 것이라 본다.    Deadlock 확인하기\n 가용자원(Avaoilable)이 몇 개 있는지 확인한다. 요청하지 않은 프로세스의 자원도 가용자원으로 합친다. 합친 가용자원으로 처리 가능한지 확인한다. 처리 후 처리된 프로세스의 자원도 합쳐서, 모든 프로세스가 끝낼 수 있는지 확인한다.    Deadlock detection과 recovery도 overhead가 크다.\n  4.3.2 Recovery   Process termination\n abort all deadlocked processes abort one process at a time until the deadlock cycle is eliminated    Resource Preemption\n 비용을 최소화할 victim으로 선정 safe state로 rollback하여 process를 restart starvation 문제  동일한 프로세스가 계속해서 victim으로 선정되는 경우 cost factor에 rollback 횟수도 같이 고려       4.4 Deadlock Ignorance  Deadlock이 일어나지 않는다고 생각하고, 아무런 조치도 취하지 않는 방식\n  Deadlock이 매우 드물게 발생하므로, deadlock에 대한 조치 자체가 더 큰 overhead일 수 있다. 만약 시스템에 deadlock이 발생한 경우, 직접 process를 죽이는 등의 방법으로 대처한다.  만약 한 번에 deadlock의 원인이 되는 process를 죽이면 효율적이지만, 원인이 되는 process가 죽을 수도 있다.   UNIX, Windows 등 대부분의 범용 OS가 채택하는 방식이다.    Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_09_%EA%B5%90%EC%B0%A9%EC%83%81%ED%83%9C/","summary":"교착 상태(deadlock)이란 무엇이고, deadlock 발생 조건 4가지는 무엇이며, 이에 따라 deadlock 처리 방법에 대해 알아본다.","title":"[TIL] OS Chapter 09: 교착 상태"},{"content":"0. Introduction  해당 내용은 kocw 이화여자대학교 운영체제 - 반효경 교수 - 강의만 보고 정리한 내용이다. 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않은 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   6. 프로세스 동기화의 첫 번째 문제  **Bounded-buffer problem (producer-consumber problem)**으로서, 생산자와 소비자가 공유 buffer에 도착했을 경우, 동기화되지 않는 문제\n   buffer: 임시로 데이터를 저장하는 공간\n  두 종류의 process\n Producer: 생산자 process로서, 공유 buffer에다가 데이터를 만들어서 집어넣는 역할 Consumer: 소비자 process로서, 공유 buffer에서 데이터를 꺼내는 역할    Bounded-buffer로 인한 문제점\n To producer  buffer가 가득 차고, 소비자가 안오는 상황이라면 data를 더 이상 생산할 수 없다는 문제가 발생된다.   To consumer  소비자 process는 소비할 수 있는 buffer가 없으면 문제가 발생된다. 생산자 process가 내용을 넣어줄 때까지 계속 기다린다.      Synchronization variable\n mutual exclusion: 공유 데이터의 상호 배제를 위해서 binary semaphore를 사용 resource count: 가용 buffer 수를 표시하기 위해서 counting semaphore를 사용    6.1 Semaphore로 문제 해결하기  Synchronization variable (= semaphore variable)  semaphore full = 0, empty = n, mutex = 1      Producer\n P(empty): 빈 buffer를 확인하고, 있으면 획득한다.  빈 buffer가 없으면 이 단계에서 대기한다. 소비자가 소비한 buffer는 producer에게는 자원이다.   P(mutex): buffer에 data를 넣기 위해 lock을 건다. V(mutex): buffer에 건 lock을 푼다. V(full): 내용이 들어가 있는 buffer의 갯수를 1 증가시키는 연산  내용이 들어가 있는 buffer는 소비자에게는 자원이다. 그리고, 소비자가 내용 있는 buffer가 없어서 대기하고 있으면 소비자를 wake up 해주는 연산      Consumer\n P(full): 내용이 있는 buffer 획득 P(mutex): 획득한 buffer에 lock을 건다. V(mutex): lock을 푼다. V(empty): 비어있는 buffer의 수를 1 증가시킨다. 그리고, 비어진 buffer는 생산자에게 자원이 된다.     7. 프로세스 동기화의 두 번째 문제  Readers and writers problem\n   Solution\n Writer가 DB에 접근 허가를 아직 얻지 못한 상태에서는 모든 대기 중인 Reader들을 다 DB에 접근하게 한다. Writer는 대기 중인 Reader가 하나도 없을 때, DB 접근이 허용된다. 일단 Writer가 DB에 접근 중이면 Reader들은 접근이 금지된다. Writer가 DB에 빠져나가야만 Reader의 접근이 허용된다. read는 동시에 여러 개가 접근해도 된다.    shared data\n DB 자체 readcount: 현대 DB에 접근 중인 reader의 수    Synchronization variables\n mutex: 공유 변수 readcount를 접근하는 코드(critical section)의 mutual exclusion 보장을 위해 사용 DB: reader와 writer가 공유 DB 자체를 올바르게 접근하는 역할      Writer\n P(db)가 DB에 lock을 걸고 쓰는 작업을 수행 이 작업이 끝나면 V(db)를 통해서 lock을 푼다. starvation 문제 발생  write가 reader들이 다 작업을 완료할 때까지 기다리는 중에, 또 다른 reader들이 들어오면 더 오래 기다려야 한다. 위 코드에서는 starvation에 대한 대책 코드는 나와있지 않는다.      Reader\n readcount는 공유 변수이기 때문에, race condition을 방지하기 위해서 mutex 변수를 사용한다. 그래서 P(mutex)에서 readcount 변수에 lock을 건다. readcount == 1: 자신이 최초의 reader라는 의미이고, DB에 lock을 건다. if readcount \u0026gt; 1: 이미 최초의 reader가 DB에 lock을 걸었기 때문에, 추가로 DB에 lock을 걸지 않고 읽기만 한다. readcount - -: process가 다 읽고 빠져나가기 때문에, 1 감소된다. if readcount == 0: writer가 작성할 수 있다.     8. 프로세스 동기화의 세 번째 문제  Dinning-philosophers problem (식사하는 철학자 문제)\n   Deadlock 발생지점\n 모든 철학자가 동시에 배가 고파서 왼쪽 젓가락을 집어버린 경우    Solution\n 4명의 철학자만이 테이블에 동시에 앉을 수 있도록 한다. 젓가락을 두 개 모두 집을 수 있을 때에만 젓가락을 집을 수 있게 한다. 비대칭  짝수(홀수) 철학자는 왼쪽(오른쪽) 젓가락부터 집도록한다. Semaphore code        Synchronization variables\n  enum {thinking, hungry, eating} state [5]\n  semaphore self[5] = 0 or 1\n i 번째 철학자가 젓가락을 소유할 수 있는 권한 유무 0 -\u0026gt; 권한 X 1 -\u0026gt; 권한 O    semaphore mutex = 1\n 본인의 상태를 본인 뿐만 아니라, 다른 철학자가 바꿀 수 있음을 나타내는 것      Philosopher i: 5명의 철학자가 하는 일을 의미\n putdown: 젓가락 내려놓기 pickup: 젓가락 집기 test    밑 단원 monitor 개념을 이용한 식사하는 철학자 문제\n  - semaphore code와 비교하기   9. Monitor 9.1 Semaphore의 문제점  코딩하기 어렵다. 정확성 입증이 어렵다. 자발적 협력이 필요하다. 한 번의 실수가 모든 시스템에 치명적인 영향을 준다.  # Deadlock 발생 경우 P(mutex) Critical section P(mutex)  # Deadlock 발생하지 않는 경우 V(mutex) Critical section P(mutex) 9.2 Monitor  동시 수행 중인 프로세스 사이에서 abstract data type의 안전한 공유를 보장하기 위한 고수준의 동기화 구조체\n   Semaphore와의 차이점\n lock을 걸 필요가 없다. Monitor: 동시 접근 막는 것을 지원 semaphore: 자원을 얻기 위해서 프로그래머가 작성    monitor는 공유 데이터에 접근하기 위해서 monitor 라고 정의된 내부 procedure를 통해서만 접근이 가능하다.\n   이 monitor를 어떻게 지원할지는 프로그래밍 언어마다 다르다.  9.2.1 Monitor 내부 구조  shared data + shared data에 접근하는 operations + initialization code\n   Process\n shared data에 접근하고 싶으면 밑에 operations (process) 들을 통해서만 가능하다. process들은 동시에 실행되지 않고, 한 번에 한 process만 실행되도록 설정하므로, lock이 불필요하다. 그래서 개발자가 별도로 lock을 구현할 필요가 없다. (semaphore와의 차이점 이유) monitor 안에 하나의 process만 활성화되기 때문에, 나머지 process는 이에 entry queue에 줄서서 기다린다. monitor 안에 공유자원의 갯수가 없어서 기다려야 하면,  내용 있는 process를 기다리는 queue는 x이고, 내용 없는 process를 기다리는 queue는 y다.      semaphore에서는 resource의 갯수를 세는 개 필요하듯이 monitor도 그러하다.\n 자원이 있으면 접근 허용, 자원이 없으면 대기한다.    Condition variable\n monitor 안에서 process가 기다릴 수 있도록 하기 위해 condition variable을 사용한다.  semaphore 변수와 동일한 역할을 한다.   condition variable은 wait과 signal 연산에 의해서만 접근 가능하다.  x.wait(): x.wait()을 invoke한 process는 다른 프로세스가 x.signal을 invoke하기 전까지는 suspend 된다. x.signal(): x.signal을 정확하게 하나의 suspend된 프로세스를 resume 한다. suspend된 프로세스가 없으면 아무 일도 일어나지 않는다.      monitor가 lock이 필요없는 이유\n  \u0026gt; monitor bounded_buffer \u0026gt; { int buffer[n]; \u0026gt; condition full, empty;  \u0026gt; void produce(int x) \u0026gt; { if there is no empty buffer \u0026gt; empty.wait(); \u0026gt; add x to an empty buffer \u0026gt; full.signal (); \u0026gt; }  \u0026gt; void consume(int *x) \u0026gt; { if there is no full buffer \u0026gt; full.wait(); \u0026gt; remove an item from buffer and store it to *x \u0026gt; empty.signal(); \u0026gt; } \u0026gt; }  full, empty 같은 condition var.을 가지지 않고, 자신의 queue에 process를 매달아서, sleep시키거나, queue에서 process를 깨우는 역할만 한다.  full: 내용이 들어 있는 buffer를 기다리면서 잠들게 하는 역할 empty: 내용이 없는 buffer를 기다리면서 잠들게 하는 역할   작업을 하기 위해서는 모니터 내부 코드를 실행해야 한다. 생산자 소비자 모두 하나의 프로세스 안에서 활성화되기 때문에, 락을 걸지 않아도 race condition 문제를 고려하지 않아도 된다. empty.wait()  생산자 입장에서는 빈 buffer가 필요한데, 그런 경우 empty wait을 통해서 빈 buffer에 줄 서서 기다린다.   full.signal()  내용이 들어 있는 buffer가 있으면 생산자를 깨운다.     Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_08_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EB%8F%99%EA%B8%B0%ED%99%94_2/","summary":"프로세스 동기화의 전통적인 문제 3가지와 semaphore를 개선한 방법인 monitor에 대해 알아본다.","title":"[TIL] OS Chapter 08: 프로세스 동기화 2"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 책에는 있지 않고, kocw 이화여자대학교 운영체제 - 반효경 교수 - 강의만 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 데이터 저장과 연산 순서  storage로부터 data를 가져와 연산한 후, 다시 storage에 저장한다.   각 box 예시    E-box S-box     CPU Memory   컴퓨터 내부 디uy7스크   프로세스 그 프로세스의 주소 공간       2. Race condition 2.1 Race condition이란??  여러 프로세스/스레드가 동시에 shared data를 조작할 때, 한 연산자가 stroage에서 가져와 작업 중인데, 작업 중인 data를 다른 연산자가 가져가서 작업하여 동기화되지 않는 현상\n 2.2 Race condition 발생 배경과 원인   공유 데이터(shared data)의 동시 접근(concurrent access) -\u0026gt; 데이터의 불일치(inconsistency) 발생\n  그래서 concurrent process는 동기화가 필요하다.\n 일관성(consistency) 유지를 위해 협력 프로세스(cooperating process) 간의 실행 순서(oderly execution)을 정해주는 메커니즘이 필요하다.    데이터 불일치가 발생하는 상황들\n Multiprocessor system (Memory ~ CPU) shared memory를 사용하는 process들 (address space ~ process) kernel 내부 data를 접근하는 routine들 간 발생     3. OS에서의 race condition 3가지  원인: kernel address space를 공유할 때, race condition이 발생한다.\n 3.1 Interrupt handler vs kernel   연산 과정\n 첫 번째: load  메모리에 있는 값을 CPU 내의 register로 불러들인다.   두 번째: Increase  불러들인 값을 증가시킨다.   세 번째: Store  memory에 저장시킨다.      Race condition 발생\n Load 후, interrupt가 들어왔을 경우 -\u0026gt; Count++ 작업을 중단한 후, interrupt service routine으로 넘어간다. -\u0026gt; interrupt handler 이기 때문에, kernel address space를 공유한다. -\u0026gt; 이 상황에서 Count --를 실행하여, 완료하면 interrupt 당한 작업으로 돌아온다. -\u0026gt; 돌아와서 interrupt handler 작업을 완료한 context 부터 작업을 실행해야 하지만, interrupt 당하기 전 load 한 context부터 실행된다. 즉, count--는 실행이 안된 것과 동일하다.    Solution: 먼저 하던 작업을 끝낸 후, 넘긴다.\n 중요한 변수값을 건드리는 동안에는 인터럽트가 들어와도 인터럽트 처리 루틴으로 바로 넘어가지 않는다. 인터럽트를 disable 시켰다가, 작업이 다 끝난 다음에 interrupt service routine으로 넘긴다.    3.2 Preempt a process running in kernel  한 프로세스의 system call을 통한 mode 전환 이미지   kernel mode로 실행 중 system call로 인한 CPU 선점  두 프로세스의 address space 간에는 data sharing이 없다.  그러나 \u0026lsquo;Pa의 CPU 할당시간 만료\u0026rsquo;로, Pa는 kernel mode로 실행 중 Pb에게 \u0026lsquo;CPU를 선점\u0026rsquo;당한다.   system call을 하는 동안, kernel address space의 data에 접근한다. 이로 인해 race condition이 발생한다.     Solution  첫 번째: kernel mode에서 수행 중일 때는 CPU를 빼앗지 않는다. 두 번째: kernel mode에서 user mode로 돌아갈 때 CPU를 빼앗는다.    3.3 Multi-processor   Problem\n multi-processor인 경우, interrupt enable 과 disable로 해결되지 않는다. CPU 한 쪽의 interrupt를 막았어도, 다른 CPU가 남아있기 때문이다.    Solution\n 해결책 1: 한 번에 하나의 CPU만이 kernel에 들어갈 수 있도록 하는 방법 해결책 2: shared data in kernel에 접근할 때마다 이 데이터에 대해 lock 과 unlcok을 하는 방법  kernel 전체를 하나의 lock으로 막고, kernel에서 나올 때는 unlock 한다.       4. Critical section problem 4.1 Critical section(임계구역)이란??  각 process가 shared data에 접근하기 위해 가지고 있는 code\n 4.2 Critical section problem이란 무엇인가??  Problem  2개 이상의 process가 shard data를 동시에 사용하기를 원하는 경우, 각 프로세스의 critical section을 통해서 접근해야 한다. A process가 critical section에 있을 때 = 공유 데이터에 접근하는 코드를 실행하고 있을 때, A process의 CPU 할당 시간이 끝나서 다른 process에게 CPU를 넘겼다. 하지만, A process가 critical section에 있기 때문에, 다른 process가 CPU를 받아도 critical section에 들어갈 수 없고, 대기해야 한다. 이를 Critical section problem 이라 한다.    4.3 SW 해결법의 충족 조건 3가지(requirements)   가정(Assumption)\n 모든 process의 수행 속도는 0보다 크다. process들 간의 상대적인 수행 속도는 가정하지 않는다.    첫 번째 requirement: Mutual Exclusion\n process P_i가 critical section 부분을 수행 중이면 다른 모든 process들은 그들의 critical section에 들어가면 안된다.    두 번째 requirement: Progress\n 아무도 critical section에 있지 않은 상태에서 critical section에 들어가고자 하는 process가 있으면 critical section에 들어가도록 해야한다.  첫 번째 requirement의 부작용으로 critical section에 어떤 process도 들어가지 않은 상황이 발생한다.      세 번째 requirement: Bounded waiting\n Process가 critical section에 들어가려고 요청한 순간부터 그 요청이 허용될 때까지 다른 process들이 critical section에 들어가는 횟수에 한계가 있어야 한다.  횟수 한계가 없으면 starvation 문제가 발생한다.      4.4 위 조건을 해결하기 위한 SW solution: Peterson\u0026rsquo;s Algorithum  SW 방법으로 해결하기 위한 code의 일반적인 구조  do {  entry section # 다른 process는 못 들어오게 shared data를 lock 하는 code  critical section # shared data에 접근하려는 코드  exit section # 다 처리 후, 다른 process가 들어오도록 unlock하는 코드  remainder section # 못 들어온 process를 의미하는 코드 } while(1)   process들은 수행의 동기화(synchronization)을 위해 몇 몇 변수를 공유할 수 있다.\n synchronization varible    Algorithum이 필요한 이유\n 고급 언어는 단일 instruction이 아니기 때문에, instruction 수행 중 CPU를 빼앗길 수 있기 때문이다. 그래서 이를 방지하고자 알고리즘으로 구현한다.    Synchronization variables(동기화 변수)\n  boolean flag [2] # process 0과 1의 flag initially flag [모두] = false; # no one is in Critical Section  Process Pi가 CPU를 잡고 있는 상황  do {  flag [i] = true; # critical section에 들어가겠다는 의미  turn = j; # turn을 상대방 turn을 바꾼다.   # 상대방이 깃발을 들고 있고, 이번이 상대방 차례인 조건을 만족하면 기다린다.  while (flag [j] \u0026amp;\u0026amp; turn == j)   critical section  flag [i] = false; # 깃발을 내린다.  remainder section } while (1)  모든 요구 조건들을 만족하지만, 그래도 문제점이 존재한다.  busy waiting (= spin lock): 계속 CPU와 memory의 할당 시간을 쓰면서 기다리는 현상  while 문을 돌면서( spin ) 계속 lock 을 걸어서 상대방이 못 들어온다. A process가 critical section에 들어가 있는 상태에서 B process가 CPU를 받아서 작동할 때, B process의 CPU 할당 시간 동안 while문이 만족되는지 체크한다. 하지만, A process가 CPU를 잡아서 조건을 바꿔줘야 B process가 들어올 수 있다. 그래서 이를 busy waiting이라 한다.      4.5 위 조건을 해결하기 위한 HW solution   Synchronization HW\n  HW 적으로 Test \u0026amp; modify 를 atomic 하게 수행할 수 있도록 지원하는 경우, 앞의 문제는 간단히 해결된다.\n HW 적으로 lock을 읽고 setting하는 작업을 말한다.        atomic instruction이란??\n 실행 중간에 간섭받거나 중단되지 않는다. 같은 메모리 영역에 대해 동시에 실행되지 않는다.    Test_and_set (a)\n a라는 데이터를 읽은 후, 1로 쓰는 Instruction 읽는 작업과 쓰는 작업을 동시에 지원하는 HW가 있다면 쉽게 해결할 수 있다.    Mutual exclusion with Test \u0026amp; Set\n  Synchronization variable:  boolean lock = false; # 다른 process가 lock이 걸려 있는지 확인  Process Pi  do {  while(Test_and_Set(lock));  critical section  lock = false; # lock에 0 할당  remainder section  }  lock = false : critical section에 아무도 안들어간 상태  들어가고 나서, Test_and_Set에 의해 lock = True로 바뀌면서 lock 이 걸린다.   lock = true: critical section에 프로세스가 들어간 상태  들어가지 못 하고, 계속 while문을 돈다. critical section에서 나오면서 lock = false로 재설정하여 while문에서 돌고 있는 process가 들어오게 한다.     5. Semaphores 5.1 Semaphores 란??  공유자원을 얻고 반납하는 작업을 위해서 lock \u0026amp; unlock 작업을 도와주는 추상 자료형\n   추상화\n 세부 구현으로부터 분리하여 개념을 일반화시키는 것 what은 정의하지만, 언어를 사용하여 어떻게 구현할지 How는 정의하지 않는다.    추상 자료형\n 추상화를 통해 얻어낸 자료형 구성: object + operation  operation의 구현은 system 마다 다르다.      atomic instruction이란??\n 실행 중간에 간섭받거나 중단되지 않는다. 같은 메모리 영역에 대해 동시에 실행되지 않는다.    Semaphores S\n  위 SW와 HW 알고리즘들 방식을 추상화시켜, 보다 효율적으로 관리한다.\n  integer variable (=Semaphore variable)\n semaphore variable = 자원의 갯수  ex) semaphore variable = 5: 자원의 갯수가 5개라는 의미   자원을 획득하는 연산을 사용하면 자원의 갯수는 감소 자원을 반납하는 연산을 사용하면 자원의 갯수는 증가    정의된 2가지 atomic operation: P, V\n  Semaphore variable을 가지고 수행하는 연산\n  P(S) operation: 공유 데이터 자원을 획득하고 lock을 거는 연산\n// S가 음수라는 건 자원이 없다는 걸 의미한다. // 자원이 없기 때문에, while문에서 계속 반복하며 기다린다. while(S \u0026lt;= 0) do no-op;  // 자원을 획득하여 P 연산을 시작하므로, S 값을 1 감소시킨다. S--;   V(S) operation: 공유 데이터 자원을 다 사용하고 나서 반납하고, unlock하는 연산\n// operation 사용이 끝나면 V 연산을 하여 S 값을 1 증가시킨다.  S++       Semaphore의 문제점\n while문에서 계속 기다리기 때문에 busy \u0026amp; wait 문제가 존재한다.    5.2 Criticall section of n process  critical section에 semaphore 사용하기\n  mutex = mutual exclusion  Synchronization variable semaphore mutex: # initally 1  Process Pi: do {   # 진입할 때 사용하는 연산. 이 조건에 만족하면 critical section에 진입하고 semaphore 감소, 그렇지 않으면 대기.  P(mutex):   critical section   V(mutex): # 빠져나올 때 사용하는 연산으로, semaphore 증가   remainder section  } while(1)  busy-wait(spin lock) 방식은 CPU를 할당받았지만, while문에서 대기하는 걸로 할당시간을 낭비하기 때문에 효율적이지 못하다. 그래서 block \u0026amp; wake up (=sleep lock) 방식으로 구현한다.  shared data를 쓰고 있는 process가 criticial section 실행을 완료할 때까지, 대기 중인 process는 block 상태에 있어서 CPU를 얻지 못하고, 사용 중이던 process가 데이터를 내놓으면 block 상태에 있는 process는 wake up 하여 ready queue에 들어와서 대기하는 방식    5.3 Block \u0026amp; Wakeup implementation  Semaphore 정의  typeef struct { int value; # semaphore를 의미  struct process *L; # queue for process wait } semaphore;   Block \u0026amp; Wakeup\n Block  kernel은 block을 호출한 process를 suspend 시킨다. 이 process의 PCB를 semaphore에 대한 wait queue에 넣는다.   Wake up  block state인 process P를 wake up 이 process의 PCB를 ready queue로 옮긴다.      정의된 Semaphore 연산\n  S: semaphore variable\n  P(S): resource 획득 연산\n  S.value --; # 자원을 획득하기 때문에 감소 if (S.value \u0026lt; 0 ) # 음수이면 들어가지 못 한다. {  # 음수면 이 프로세스를 queue에서 대기하도록 추가한다. 그 후, block로 둔다.  add this process to S.L;  block }  V(S): resource 반납 연산과 이 자원을 기다리면 잠든 프로세스를 깨우는 연산  S.value ++;  # 자원을 내놓았는데도 0이거나 음수라는 건, 어떤 프로세스가 P 연산에 의해 block 상태임을 의미 if (S.value \u0026lt;= 0 ) { # queue에서 제거한다.  remove this process to S.L;  wake(P); }   5.4 Busy-wait VS Block \u0026amp; wake-up  critical section의 길이에 따라 달라진다.\n   critical section의 길이가 긴 경우\n block / wakeup이 필수  오랫 동안 풀지 않은 lock을 풀기 위해 CPU를 얻어도 계속 while문에서 대기하는 게 길기 때문이다.      critical section의 길이가 짧은 경우\n block/wakeup overhead가 busy-wait overhead보다 더 커질 수 있다. 일반적으로는 block/wakeup 방식이 더 좋다.    5.5 Two types of semaphores  Counting semaphores and Binary semaphores (=mutext)\n    Attribute Counting semaphore Binary semaphore     resource resource \u0026gt;= 0 resource = 1   purpose resource counting mutext(lock / unlock)    5.5 Semaphore 주의사항: Deadlock and Starvation 5.5.1 Deadlock  둘 이상의 process가 서로 상대방에 의해 충족될 수 있는 event를 무한히 기다리는 현상\n  어떤 일을 하기 위해서, S와 Q를 모두 획득해야지만 일할 수 있고, S, Q를 모두 반환한다. S와 Q: 서로 배타적으로 사용할 수 있는, 1로 초기화된 semaphore  - Process 모두 하나씩 차지한 상황 - P0가 S를 먼저 작업하다가 CPU를 빼앗겨 P1이 CPU와 Q semaphore 를 얻어 작업한다. - 그런데, 상대방의 것을 서로 요구한다. - 하지만, 서로 가지고 있기 때문에, 영원히 기다려야 한다. - 왜냐하면 다 사용하고 나서 반환하기 때문이다. - 이 문제를 `Deadlock` 이라 한다.   Solution  - 서로 다른 프로세스여도 같은 순서로 정한다. - Q를 획득하려면 S를 먼저 획득하라는 의미  5.5.2 Starvation  infinite blocking이라 하며, process가 suspend된 이유에 해당하는 semaphore queue에서 빠져나갈 수 없는 현상\n  특정 process 자원을 독점하여 나머지 프로세스가 자원을 얻지 못하고 무한히 기다리는 현상으로 Deadlock과 유사하지만, 다르다.   Reference  kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_08_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EB%8F%99%EA%B8%B0%ED%99%94_1/","summary":"Race condition이란 무엇이고, 이 race condition은 OS에서 언제 발생되며, 이를 해결하기 위한 방법으로 SW 방법과 SW 방법에는 무엇이 있는지를 배운다. 또한, Semaphore가 무엇인지 알아본다.","title":"[TIL] OS Chapter 08: 프로세스 동기화 1"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   이번 chapter 내용인 메모리 관리는 물리적인 메모리 관리로, 주요 내용은 address binding이다. address binding에서의 OS의 역할은 없고, 다 HW가 해야한다. address binding을 할 때마다 OS에게 CPU 제어권을 양도해도, 결국 물리적 메모리에 instruction을 실행하는 건 CPU다. 그래서 HW가 해야한다.   4. 페이징 기법  프로세스의 주소 공간을 동일한 크기의 페이지 단위로 나누어, 물리적 메모리의 서로 다른 위치에 불연속적으로 페이지들을 저장하는 방식\n   각 프로세스의 주소 공간 전체를 물리적 메모리에 한꺼번에 올릴 필요 없이, 스와핑을 사용하여 일부만 메모리에 올릴 수 있다.\n  또한, 이 메모리는 페이지와 동일한 크기의 프레임(frame) 으로 미리 나누어둔다.\n 그래서 빈 프레임이 있으면 메모리의 어떤 위치이든 사용될 수 있다. 이 특징으로 연속할당에서의 동적 메모리 할당 문제와 외부조각 문제가 발생하지 않는다. 그러나, 프로그램의 크기가 항상 페이지 크기의 배수라는 보장이 없기 때문에 내부조각이 발생할 가능성은 있다.    Problem\n 물리적 메모리의 불연속적인 위치에 각 페이지를 올리기 때문에, 논리적 주소에서 물리적 주소로 변환하는 작업이 복잡하다.    Solution\n 위 문제에 대한 해결책으로 페이지 테이블(page table) 을 가진다. page table이 사용하는 주소 변환기법에 대해 알아보자.    4.1 주소 변환(address translation) 기법   page table에는 각 page마다 frame 주소가 mapping되어 있다.\n  logical address에서 physical address로 변환하는 구체적인 과정은 다음과 같다.\n   p = 페이지 번호: page table 접근 시 인덱스(index)로 사용 d = 페이지 offset\n-\u0026gt; 각 index의 항목(entry)에는 그 페이지의 물리적 메모리상의 기준 주소(base address)인 시작위치가 저장되어 있다.\n-\u0026gt; page table에서 위에서 p 번째를 찾으면 frame 번호(f)가 나온다.\n-\u0026gt; 이렇게 해서 logical address에서 physical address로 바뀐다.  4.2 페이지 테이블의 구현   page table이란? paging 기법에서 주소 변환을 하기 위한 자료 구조로, 물리적 메모리에 위치한다. page table에 접근하기 위해 2개의 레지스터를 사용한다.     page table에 접근하기 위한 2개의 레지스터는 다음과 같다.\n 페이지 테이블 기준 레지스터(page-table base register, PTBR): 물리적 메모리 내에서의 페이지 테이블의 시작 위치 페이지 테이블 길이 레지스터(page-table length register, PTLR): 페이지 테이블의 크기를 보관    Problem\n 페이징 기법에서 메모리 접근 연산은 총 두 번 이뤄진다.  첫 번째: 주소 변환을 위해 메모리에 있는 페이지 테이블에 접근하기 두 번째: 변환된 주소로 실제 데이터에 접근하기   즉, 두 번 접근해야 하는 오버헤드가 뒤따른다.      Solution: TLB\n TLB란?  Translation Look-aside Buffer 의 약어로, 테이블 접근 오버헤드를 줄이고, 메모리 접근 속도를 높이기 위한, 고속 주소 변환용 하드웨어 캐시 page table에서 빈번히 찾는 일부 entry를 저장하고 있다.   TLB mechanism  CPU가 논리적인 주소를 주면 page table보다 먼저 TLB를 검색한다. TLB 저장된 정보를 통해서 주소 변환이 가능한지 확인한다.  TLB에 저장되어 있다면 TLB를 통해서 바로 주소 변환을 한다. 이 경우, 메모리에 한 번만 접근한다. 저장되어 있지 않다면 page table을 통해서 일반적인 주소 변환을 실행한다.        TLB의 문제점\n page table의 경우  page 번호만큼 떨어진 항목에 곧바로 접근해 대응되는 프레임 번호를 얻는다.   하지만, TLB의 경우  모든 페이지에 대한 주소 변환 정보 X -\u0026gt; 페이지 번호와 이에 대응하는 프레임 번호가 쌍으로 저장되야 한다. 해당 페이지에 대한 주소 변환 정보가 TLB에 있는지 확인하기 위해 TLB의 모든 항목을 다 찾아봐야 하는 오버헤드가 발생한다.      Associative register\n 위의 언급한 오버헤드를 줄이기 위해 병렬 탐색(parallel search)이 가능한 연관 레지스터(associative register)를 사용한다.  Parallel search: TLB 내의 모든 항목을 동시에 탐색할 수 있는 기능      page table은 각 process마다 논리적인 주소 체계가 달라서, 각 프로세스마다 존재한다.\n 그래서, TLB도 각 process마다 다르게 존재한다.    4.3 계층적 페이징  2개 이상의 page table을 통해서 물리적 메모리에 접근하는 기법으로, 각 페이지를 다시 페이지화시키는 기법\n 4.3.1 Twp-level page table이란???  2단계 페이징 기법(Two-level page table)은 outer-page table과 inner-page table을 통해서 Physical memory에 접근한다.  4.3.2 Two-level page table을 사용하는 이유   현대의 컴퓨터는 address space가 매우 큰 프로그램을 지원한다.\n  컴퓨터 시스템에서의 K, M, G\n K = 2^(10) = Kilo M = 2^(20) = Mega G = 2^(30) = Giga    32 bit address 사용 시: 2^(32) byte (= 4G byte)의 주소 공간\n  페이지의 크기가 4KB일 때, 4GB / 4KB = 1M 개의 page table entry(항목)이 필요\n  페이지의 항목이 4 byte 라면 한 프로세스 당 페이지 테이블을 위해 1M x 4byte = 4MB 크기의 메모리 공간이 필요하다.\n    이런 상황에서 왜 2단계 페이징 기법을 사용하는가??\n page table이 2개라서 공간 낭비일 것 같지만, 다음과 같은 이유로 효과가 더 크기 때문에 사용한다. 프로그램의 대부분은 방어용 코드로 주로 사용하는 페이지 수는 적다. 그래서, 사용되지 않는 주소 공간에 대해서는 outer page table의 항목을 NULL로 설정하며, 여기에 대응하는 inner page table을 생성하지 않는다. 그 결과, page table의 공간을 줄일 수 있기 때문에, 속도가 느려도 사용한다. 사용하지 않는 주소 공간에 대해서 outer page table에 생성하는 이유는 page table의 자료구조 특성상 index로 작용하기 때문이다.    4.3.3 Two-level page table의 구성과 갯수, 크기 계산   logical address의 구성\n two level 이므로, 두 종류의 페이지 번호(P1,P2) 페이지 오프셋(d) P1: outer page table의 index P2: inner page table의 index    outer page table의 entry 하나 당 inner page table이 하나 만들어진다.\n  inner page table 하나의 크기가 page 크기와 동일하다.\n  page table entry 하나의 크기가 4 byte 라고 했는데, 그러면 entry 갯수는 1K 개다.\n  page 크기가 4KB 이고, 32bit 주소체계라고할 때, page number와 page offset의 크기는 다음과 같다.\n page 크기가 4K = 2^(12) 이므로, 한 페이지를 구분하기 위해서는 page offset은 12bit 가 필요하다. page table entry가 4byte이므로, 내부 페이지 테이블은 1KB = 2^(10) 개의 항목을 가진다. 2^(10)개를 구분하기 위해서는 P2는 10bit 가 필요하다. 그러면 총 32bit 주소체계에서 22bit를 사용했으므로, P1에는 10bit 가 할당된다.    P1 P2 Page offset     10bit 10bit 12bit        다음과 같은 순서로 찾는다.\n 첫 번째  outer page table로부터 P1만큼 떨어진 위치에서 inner page table의 주소 를 얻는다. inner page table은 여러개가 있다. outer page table의 한 entry당 하나의 inner page table이 만들어진다.   두 번째  innter page table로부터 P2만큼 떨어진 위치에서 요청된 페이지가 존재하는 프레임의 위치 를 얻는다.   세 번째  해당 프레임으로부터 d 만큼 떨어진 곳에서 원하는 정보에 접근한다.      4.3.4 multi-level page의 문제점과 해결책   Problem\n  process의 address space가 커질수록 page table의 크기도 커지므로, 주소 변환을 위한 메모리 공간 낭비 점점 심각해지기 때문에, 다단계 페이지 테이블이 필요.\n  이에 따라 공간은 절약할 수 있지만 메모리 접근시간이 크게 늘어나는 문제가 발생.\n    Solution: TLB\n TLB 와 함께 사용하여 메모리 접근 시간을 줄일 수 있고, 다단계 page table을 사용하여 메모리 공간의 효율적 사용 효과는 매우 크다.    4.4 메모리 보호(Memory Protection)  메모리 보호를 위해 page table의 각 entry마다 보호 비트(protection bit)와 유효-무효 비트(valid-invalid bit)를 둔다.\n   보호 비트(Protection bit): 각 page에 대한 연산 접근 권한을 설정하는데 사용\n read / write / read-only    유효-무효 비트(Valid-Invalid bit): 해당 페이지의 내용에 접근을 허용하는지 결정\n valid 로 세팅: 해당 메모리 프레임에 그 페이지가 존재 -\u0026gt; 접근 허용 invalid 로 세팅 -\u0026gt; 유효한 접근 권한 X  첫 번재 경우, 프로세스가 그 주소 부분을 사용 X 두 번째 경우, 해당 페이지가 물리적 메모리에 올라있지 않고, 백킹스토어에 존재      4.5 역페이지 테이블(Inverted page table)   page table이 매우 큰 이유\n 모든 process 별로 그 logical address에 대응하는 모든 page에 대해 page table entry를 다 구성해야 하기 때문이다. 대응하는 page가 메모리에 존재하든 안하든 page table에는 entry로 존재    Inverted page table\n   logical address에 대해 page table을 만드는 것이 아닌, physical address에 대해 page table을 만드는 것\n   시스템 전체에(system-wide) page table을 하나만 두는 방법\n physical address는 1개이기 때문에, physical address에 대해 page table을 만든다는 건 하나만 만드는 걸 의미한다. 각 프로세스마다 page table을 두는 게 아니다.    page table entry 수 = Physical memory의 page frame 수\n Physical memory의 page frame 하나당 page table에 하나의 entry를 둔 것 page table entry 수 =! process의 page 갯수    각 page table entry는 각각의 물리적 메모리의 page frame이 담고 있는 내용 표시\n process의 id(pid), logical address(p) 어떤 process의 p번째 페이지인지를 확인하기 위해 pid를 저장해야 한다.    단점: 테이블 전체를 탐색해야 한다.\n 역페이지 테이블에 주소 변환 요청이 들어오면, 그 주소를 담은 페이지가 물리적 메모리에 존재하는지 여부를 판단하기 위해, 페이지 테이블 전체를 다 탐색해야한다.      physical address를 보고 logical address로 바꾸는 것이기 때문에, 목적에 맞지 않다.\n  그러면 이 table을 통해서 어떻게 전환할 것인가??\n 논리주소에 해당되는 P가 물리적 메모리 어디에 올라가는지를 찾을라면 이 entry를 다 찾아서 해당되는 P가 F 번째에 나오면, f번째에 있는 물리적 프레임에 있다는 걸로 파악한다. table의 장점인 index를 통해서 찾을 수 있는 장점이 없다.    그래서 시간이 아닌 단지 공간을 줄이기 위해서 사용되는 것이다.\n  해결책: associative register 사용한다.\n 연관 레지스터를 사용하여 병렬탐색을 하여 시간적 효율성을 높인다. 단, 비용이 비싸다.    4.6 공유 페이지(Shared page)  shared code(공유 코드)를 담고 있는 페이지\n   shared code란??\n 메모리 공간의 효율적인 사용을 위해, 여러 프로세스에서 공통으로 사용되도록 작성된 코드 재진입 가능코드 (re-entrant code) 또는 순수 코드(pure code)라 한다. read-only 특성을 가진다. -shared memory 기법에서는 read - write다.    프로세스 간 공유 페이지이므로 물리적 메모리에 하나만 적재하여 효율적으로 사용한다.\n  하지만, 이 특성으로 모든 프로세스의 logical address space 의 동일한 위치에 존재해야하는 제약점이 있다.\n 왜냐하면 logical address에서 실행 시작하여 physical address에 올라갈 때, logical address에 연결되기 때문이다. Address binding 내용에서 이미지를 참고하자.    private page(사유 페이지)\n 공유 페이지와 대비되는 개념으로, 프로세스끼리 공유하지 않고 독자적으로 사용하는 페이지 사유 페이지는 해당 프로세스의 논리적 주소 공간 중 어더한 위치에 있어도 무방하다.     5. 세그먼테이션  프로세스 가상 메모리를 의미 단위인 segment로 나눠서 물리적 메모리에 올리는 기법\n   프로세스의 주소 공간을 크기 단위가 아닌 의미 단위(logical unit)로 나눈 것이기 때문에, 크기가 균일하지 않다.\n main (), function, global variables, stack\u0026hellip;    그래서 부가적인 관리 오버헤드가 뒤따른다.\n  segment 크기 기준\n 프로그램은 의미 단위인 여러 개의 segment로 구성한다. 작게는 프로그램을 구성하는 함수 하나 하나를 segment로 정의한다. 크게는 프로그램 전체를 하나의 세그먼트로 정의한다. 일반적으로는 code, data, stack 부분이 하나씩의 segment로 정의된다.    5.1 Segmentation Architecture 5.1.1 Logical address  두 가지 [s: segment-number, d: offset]로 구성\n 5.1.2 Segment table  Segmentation에서 주소 변환을 위해 사용하는 table\n   이 table은 기준점(base) 와 한계점(limit) 을 가진다.\n 기준점:  물리적 메모리에서 각 세그먼트의 시작위치를 의미.   한계점:  각 세그먼트의 길이를 의미. 페이징 기법과는 달리 각 segment의 길이가 균일하지 않기 때문이다.      segment의 갯수에 따라 table entry 수가 결정된다.\n    CPU 안에 주소 변환을 위한 2개의 레지스터\n  Segment Table Base Register(STBR) : 물리적 메모리에서의 segment table의 시작위치\n  Segment Table Length Register(STLR) : 프로세스의 segment의 길이와 갯수\n    Logical address를 physical address로 변환하기 위한 두 가지 사항\n 첫 번째: segment number(s)가 STLR에 저장된 값보다 작은 값인지 확인  아니라면 trap 발생시키기   두 번째: 논리적 주소의 오프셋 값(d)이 세그먼트의 길이보다 작은 값인지 확인  세그먼트 테이블의 한계점과 요청된 논리적 주소의 오프셋값을 비교해 확인한다. d가 더 크다면 trap 발생시키기      균일하지 않은 segment로 인한 paging과의 차이점들\n 첫 번째 차이  paging 기법에서는 크기가 균일하기 때문에, offset의 크기가 page 크기에 의해서 결정된다. segment 기법에서는 offset 크기가 segment 크기를 제한하는 요소다.   두 번째 차이  paging 기법에서는 크기가 균일하기 때문에, 시작 주소가 frame 번호다. segment 기법에서는 크기가 다르기 때문에, 이 segment가 어디서 시작되는지 정확한 byte 단위 주소로 알려줘야 한다.      장점: paging과 달리 의미 단위라서 segment의 갯수가 상대적으로 많이 적다.\n 그래서 table로 인한 메모리 낭비를 비교하자면 일반적인 시스템에서는 적다.    5.2 세그먼테이션에서의 보호비트와 유효비트  보호 비트(protection bit): 각 세그먼트 별로 가지고 있어서 각각에 대해 읽기/쓰기/실행 등의 권한이 있는지 나타낸다. 유효 비트(valid bit): 각 세그먼트의 주소 변환 정보가 유효한지, 즉 해당 세그먼트가 현재 물리적 메모리에 적재되어 있는지 나타낸다.  valid bit = 0 : illegal segment    5.3 공유 세그먼트(shared segment)   공유 세그먼트(shared segment)\n 여러 프로세스가 특정 세그먼트를 공유해 사용한다. 이 세그먼트를 공유하는 모든 프로세스의 주소 공간에서 동일한 논리적 주소에 위치 해야 한다.    장점: 공유(sharing)와 보안(protection) 측면에서 세그먼테이션\n 의미 단위로 나눠져 있어서 페이징 기법보다 훨씬 효과적이다. -\u0026gt; 5.2 와 연결하기 왜냐하면 크기 단위로 나누다 보면 공유 코드와 사유 데이터 영역이 동일 페이지에 공존하는 경우가 발생할 수 있기 때문이다. 그래서 어떤 권한을 줘야할지 결정하기가 어렵다.    5.4 세그먼트 할당 방식  세그먼트를 가용 공간에 할당하는 방식  세그먼트 크기가 균일하지 않기 때문에, 외부 조각 같은 문제점이 발생한다.  내부 조각은 없다는 장점 paging은 fragmentation이 발생하지 않는다.   그래서 동적 메모리 할당 문제가 존재한다. 이 문제에 대해서는 first-fit 방식과 best-fit 방식을 사용한다.     6. 페이지드 세그먼테이션  segmentation을 기반으로, 각 segmentation을 크기가 동일한 page로 구성\n 6.1 pure segmentaton과의 차이점  segment-table entry 가 segment의 base address 를 가지고 있는 것이 아닌, segment를 구성하는 page table 의 base address 를 가지고 있다.  6.2 Paged segmentation의 logical address  두 가지 [s: segment-number, d: offset]로 구성  6.3 Paged segmentation의 특징과 장점   물리적 메모리에 적재하는 단위: page\n  address binding을 위해 외부의 segment table과 내부의 page table을 이용한다.\n  장점: segmentation에서의 외부조각 문제와 paging 기법의 접근 권한 보호 문제를 해결\n  6.4 address binding 과정 설명   첫 번째\n 논리적 주소의 상위 비트인 segment number(s)로 segment table의 해당 항목에 접근    두 번째\n 이 segment table entry = segment 길이 + segment의 page table 시작 주소    세 번째\n  세그먼트 길이를 넘어서는 메모리 접근 시도인지 여부를 체크하기 위해, segment length와 logical address의 하위 비트 offset(d) 값과 비교.\n  If segment lenth \u0026lt; offset: 유효 X -\u0026gt; trap 발생.\n  If segment lenth \u0026gt; offset: offset 값을 다시 상위 하위 비트로 나눔.\n 나눠진 상위비트(p): 그 segment 내에서 page number를 의미. 나눠진 하위비트(d\u0026rsquo;): page 내에서의 변위를 의미.        네 번째\n segment table entry에 있는 segment의 page-table base를 기준으로, p만큼 떨어진 page table entry로부터 물리적 메모리의 page frame 위치(f)를 얻음.    다섯 번째\n 이 얻어진 위치에서 d\u0026rsquo;만큼 떨어진 곳 = 물리적 메모리 주소.    page table for segment s 의 entry 갯수는 segment table의 segment 길이를 보면 알 수 있다.\n   Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_07_%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B4%80%EB%A6%AC_2/","summary":"불연속 할당 방법인 pagin 기법, segmentation 기법, paged segmentation 기법에 대해 알아본다.","title":"[TIL] OS Chapter 07: 메모리 관리 2"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용이다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   이번 chapter 내용인 메모리 관리는 물리적인 메모리 관리로, 주요 내용은 address binding이다. address binding에서의 OS의 역할은 없고, 다 HW가 해야한다. address binding을 할 때마다 OS에게 CPU 제어권을 양도해도, 결국 물리적 메모리에 instruction을 실행하는 건 CPU다. 그래서 HW가 해야한다.   1. 주소(address) 바인딩 1.1 주소란??   서로 다른 위치를 구분하기 위해 사용하는 일련의 숫자 크게 논리적 주소와 물리적 주소로 나뉠 수 있다.    Memory는 주소를 통해 접근하는 저장장치다. 컴퓨터 시스템은 32bit 혹은 64bit의 주소체계를 사용하는데,  32bit는 2^(32) 가지, 64bit는 2^(64) 가지의 서로 다른 메모리 위치를 구분할 수 있다.   byte 단위로 메모리 주소를 부여한다.  1.2 논리적 주소, 물리적 주소   논리적 주소(logical address, virtual address)란?\n 프로세스마다 독립적으로 가지는 주소 공간 각 프로세스마다 0번지부터 시작 CPU가 보는 주소는 logical address  Why? 물리적 메모리에 올라오는 위치는 달라도 코드 상의 내용은 compile 시 내용.      물리적 주소(physical address)란?\n 메모리에 실제로 올라가는 위치 물리적 주소의 낮은 주소 영역에는 kernel이 올라간다. 물리적 주소의 높은 주소 영역에는 user process들이 올라간다.    프로세스가 실행되기 위해서\n 해당 프로그램이 물리적 메모리에 올라가 있어야 한다. 해당 논리적 주소가 물리적 메모리의 어느 위치에 매핑되는지 확인해야 한다.    1.3 주소 바인딩(address binding)  logical address를 physical address로 연결시켜서, physical address를 결정하는 작업\n  Symbolic address \u0026ndash;(compile)\u0026ndash;\u0026gt; Logical address \u0026ndash;(address binding)\u0026ndash;\u0026gt; Physical address    주소 바인딩 방식 3가지: 물리적 메모리 주소가 결정되는 시기에 따라 분류된다.\n 컴파일 타임 바인딩(compile time binding) 로드 타임 바인딩(load time binding) 실행시간 바인딩(execution time binding or run time binding)    방식 이름 compile time binding load time binding run time binding     시기 컴파일 시 프로그램 실행이 시작 시 (변경 가능 X) 프로그램 실행이 시작 시, (변경 가능 O)   swapping 효과 좋지 않음 좋지 않음 좋음        Compile time binding\n 컴파일 시, 논리적인 주소와 물리적인 주소 다 생성된다. compiler는 절대 코드 를 생성한다.  그래서 program이 올라가 있는 물리적 메모리의 시작위치를 변경할려면 컴파일을 다시 해야 한다.   물리적 주소의 0번지부터 시작한다. 현대의 시분할 컴퓨터 환경에서는 잘 사용하지 않는 기법    Load time binding\n 컴파일 시에는 논리적인 주소만 결정된다. 이를 실행하고 나서, 메모리가 비어있는 곳부터 올린다. 로더(loader)의 책임 하에 물리적 메모리 주소 부여  Loader: user program을 memory에 적재시키는 프로그램   compiler가 재배치 가능 코드 를 생성한 경우 가능    Run time binding\n Load time binding 처럼 실행 시, physical address가 생성된다. 실행을 시작한 후에도 물리적 메모리상의 위치(물리적 주소)를 옮길 수 있는 방식 CPU가 주소 참조 시, address mapping table을 이용해 원하는 데이터가 물리적 메모리의 어느 위치에 존재하는지 확인한다. MMU(Memory Management Unit) 라는 하드웨어적 지원이 필요    1.4 MMU 기법(MMU scheme)  기준 레지스터를 사용하여 logical에서 physical address로 mapping해주는 HW device\n   가정\n 프로그램의 주소 공간이 메모리의 한 장소에 연속적으로 적재되는 걸 가정한다.    MMU scheme\n 사용자 프로세스가 CPU에서 수행되여 생성해내는 모든 논리적 주소값에 대해 base register(= relocation register) 의 값을 더하여 물리적 주소값을 얻어낸다. base register = CPU가 사용하려는 프로세스의 물리적 메모리 시작 주소      user program\n logical address 만을 다룬다. 실제 physical address 를 볼 수 없으며, 알 필요가 없다.    예시\n CPU가 논리적 주소: 123번지 정보를 요청 기준 레지스터(=재배치 레지스터): 23000 물리적 주소 = 123 + 23000 = 23123 물리적 주소 23123번지에서 CPU가 요청한 정보를 찾는다. 논리적 주소란 기준 레지스터로부터 얼마나 떨어져 있는지를 나타내는 것    동일한 논리적 주소\n 프로세스는 각 자신만의 고유한 주소 공간을 가진다. 그래서 동일한 논리적 주소라고 할 지라도, 서로 다른 내용을 담는다. MMU 기법에서 프로세스가 바뀔 때마다 기준 레지스터의 값을 바뀌는 프로세스에 해당되는 값으로 재설정한다.    메모리 보안\n Problem  가상 메모리에 기준 레지스터를 더했을 때, 해당 프로세스의 주소 공간을 벗어나는 경우, 다른 프로세스 영역에 침범하거나, kernel 영역을 변경해 치명적인 결과를 초래할 수 있다.   Solution  한계 레지스터(limit register) 를 사용하여, 프로세스 자신의 주소 공간을 넘어서는 메모리 참조를 하는지 확인한다.  한계 레지스터(limit register): 논리적 주소의 범위   벗어날 경우, trap을 발생시켜 해당 프로세스를 강제종료시킨다.       2. 메모리 관리와 관련된 용어 2.1 동적 로딩(Dynamic loading)   다중 프로그래밍 환경에서 메모리를 효율적으로 사용하기 위한 기법 프로세스의 주소 공간 전체를 메모리에 다 올려놓는 게 아닌, 해당 부분이 불릴 때에마다 메모리에 적재하는 방식    loading: 물리적 메모리로 올리는 것 부분적으로만 올리는 이유  실제 프로그램의 코드 중 상당 부분 = 가끔씩 사용하는 방어용 코드 -\u0026gt; 주소 공간 전체 loading -\u0026gt; 메모리 낭비 초래   동적 로딩 -\u0026gt; 더 많은 프로그램 로딩 가능 -\u0026gt; 메모리 이용 효율성 향상 운영체제 지원 없이 개발자가 코드로 구현 가능하고, OS는 라이브러리를 통해 지원 가능  2.2 중첩(overlays)  메모리보다 큰 프로세스를 실행하기 위해서, 프로세스의 주소 공간을 분할해 실제 필요한 부분만을 메모리에 적재하는 기법\n  중첩과 동적 로딩의 차이점: 목적  동적 로딩의 목적: 메모리에 multi-process를 실행하기 위한 용도 중첩의 목적: single-process를 실행하기 위한 환경에서 메모리 용량보다 큰 프로세스를 실행하기 위한 용도 운영체제의 지원 없이 프로그래머가 직접 구현해야 한다.    2.3 스와핑(Swapping)  프로세스의 주소 공간 전체를 메모리에서 backing store로 쫓아내는 것\n   스왑 영역(Swap area)란??\n 다른 말로 백킹 스토어(backing store) 라고 한다. 디스크 내의 파일 시스템과는 별도로 존재하는 일정 영역으로,  파일 시스템 은 전원이 나가도 유지되어야 하는 비휘발성 저장공간이지만, 스왑 영역 은 프로세스가 수행 중인 동안에만 디스크에 일시적으로 저장하는 휘발성 영역이다. 프로세스 실행이 종료되면 메모리에서 디스크로 내려놓는다. (swap out)   그리고, 다음과 같은 특징을 가져야 한다.  다수의 사용자 프로세스를 담을 수 있을 만큼 충분히 큰 저장 공간이다. 어느 정도의 접근 속도가 보장되야 한다.      Swap in \u0026amp; out\n Swap in: disk -\u0026gt; memory 올리는 작업 Swap out: memory -\u0026gt; disk 내리는 작업    스와핑이 일어나는 과정\n  첫 번째: Swapper라 불리는 중기 스케쥴러 에 의해 swap out할 process를 선정.\n 선정 기준: priority  priority가 낮은 프로세스를 swap out priority가 높은 프로세스를 swap in      두 번째: 선정된 process를 메모리에 올라간 주소 공간 전체 내용을 disk swap area로 아웃시켜서 메모리의 프로세스 수를 조절한다.\n  즉, Swapper로 멀티 프로그래밍 정도(degree of multi-programming)를 조절한다.\n  메모리에 많은 프로그램이 올라오면 할당되는 메모리 양이 지나치게 적어져, 시스템 전체 성능이 감소되기 때문이다.\n    Swap time\n Swap time: swapping에 소요되는 시간 Transfer time: 데이터를 읽고 쓰는 전송 시간 Swap time은 디스크를 탐색하는 것보다 disk sector에서 transfer time이 대부분을 차지한다. 즉, transfer time 은 swap 되는 양에 비례      address binding에 따른 swapping\n compile time binding \u0026amp; load time binding: 다시 swap in 시, 원래 존재하던 메모리 위치로 다시 올라가야 해서 swapping의 효과가 좋지 않다. runtime binding은 추후 빈 메모리 영역 아무 곳에나 프로세스를 올리기 때문에, swapping으로 인한 효과가 좋다.    2.4 동적 연결(Dynamic linking))   연결(linking)이란??\n 목적 파일(object file)과 이미 컴파일된 라이브러리 파일을 묶어서 하나의 실행파일을 생성하는 과정  Object file: 프로그래머가 작성한 source code를 컴파일하여 생성된 파일      정적 연결(static linking)과 동적 연결(dynamic linking)의 차이: 첫 번째\n  정적 연결: 프로그래머가 작성한 코드와 라이브러리가 모두 합쳐진 상태에서 실행파일이 생성되는 방식으로, 연결된 상태에서 실행파일을 생성하는 방식\n 라이브러리가 프로그램의 실행 파일 코드에 포함되어, 실행파일의 크기가 상대적으로 크다.    동적 연결 : 라이브러리를 포함하지 않는 생성된 실행 파일이 라이브버리 호출 시 , 연결이 이뤄지는 방식\n 그래서 라이브러리의 위치를 찾기 위해 라이브러리 호출 부분에 stub 이라는 작은 코드를 둔다. 이 stub을 통해 해당 라이브러리 루틴이 메모리에 이미 존재하는지 먼저 살펴본다.  메모리에 이미 존재 -\u0026gt; 그 메모리 위치에서 직접 참조 메모리에 없음 -\u0026gt; 디스크에서 읽어옴        정적 연결(static linking)과 동적 연결(dynamic linking)의 차이: 두 번째\n  정적 연결: 첫 번째 차이점으로 인해 동일한 라이브러리를 각 프로세스가 개별적으로 메모리에 적재해야 하므로, 물리적 메모리가 낭비된다.\n 동일한 라이브러리 코드여도 각 프로세스의 주소 공간에 독자적으로 존재하는 코드이므로 별도의 적재가 필요하다. 그 결과, 메모리 낭비가 심하다.    동적 연결: 라이브러리를 호출하면 되므로 메모리에 한 번만 적재하여 낭비 X\n 공용으로 쓰는 라이브러리를 shared library 라 한다.      Summary\n   특징 정적 연결 동적 연결     연결 시기 실행 파일 생성 전 실행 파일 생성 후, 호출   적재 횟수 각 프로세스 개별적으로 메모리에 한 번만   실행 파일에 라이브러리 포함 유무 O X   메모리 낭비 발생 O X       3. 물리적 메모리의 할당 방식  물리적 메모리 할당 방식과 사용자 영역 관리 방식은 다음과 같다.  3.1 연속할당(Contiguous allocation) 방식  프로세스를 메모리에 올릴 때, 주소 공간을 여러 개로 분할하지 않고, 메모리의 한 곳에 연속적으로 적재하는 방식\n  고정분할 방식 과 가변분할 방식 으로 나눠진다. 연속적으로 할당하기 때문에 물리적 메모리 주소로 mapping 하는 게 쉽다. 연속 할당 기법에서는 프로세스의 주소 공간 전체를 담을 수 있는 가용공간을 찾아야 한다.  가용 공간(hole) : 사용되지 않은 메모리 공간으로, 메모리 내의 여러 곳에서 산발적으로 존재할 수 있다.   이 가용공간(hole)은 물리적 메모리 내부에 산발적으로 존재하기 때문에, 효율적으로 관리하기 위해서 운영체제는 사용 중인 공간과 가용 공간에 대한 정보를 각각 유지한다.  3.1.1 고정분할(Fixed partition) 방식  물리적 메모리를 영구적인 분할(partition)로 미리 나누어두고, 각 분할에 오직 하나의 프로세스만을 적재해 실행하는 방식\n   이에 따라 다음과 같은 특징을 가진다.\n 미리 나누는 분할의 크기는 다 동일할 수도 있고, 다르게 할 수도 있다. 동시에 메모리에 올릴 수 있는 프로그램의 수가 고정되었다. 수행 가능한 프로그램의 최대 크기 또한 제한된다. 외부 조각(external fragmentation)과 내부 조각(internal fragmentation)이 발생한다.    외부 조각과 내부 조각에 대해 알아보자.\n   조각 종류 외부 조각 내부 조각     When 프로그램 크기 \u0026gt; 분할 크기 프로그램 크기 \u0026lt; 분할 크기   할당 유무 할당하지 않은 조각 할당된 조각     외부 조각:  프로그램의 크기가 분할 크기보다 커서 프로그램을 적재하지 못하여 발생하는 메모리 공간 하지만, 분할 크기보다 작은 프로그램이 도착하면 이 외부조각에 적재할 수 있다.   내부 조각:  하나의 분할에 프로그램을 적재한 후, 남아서 사용되지 않는 메모리 공간 남은 공간에 충분히 적재할 수 있는 프로그램이 있을지라도, 이미 할당된 조각이므로 다른 프로그램에 할당할 수 없다.      3.1.2 가변분할(Variable partition) 방식   미리 분할시키는 것이 아닌 프로그램이 실행될 때마다 메모리에 순서대로 차곡차곡 쌓는 방식 그래서, 분할의 크기, 개수가 동적으로 변한다. 현대의 컴퓨터가 사용하는 방식     분할의 크기를 프로그램 크기보다 일부러 크게 할당하지 않기 때문에, 내부조각이 발생하지 않는다.\n  Problem 1:외부조각\n 메모리에 존재하는 프로그램이 종료될 경우, 중간에 빈 공간이 발생하는데, 이 공간이 새로 시작하는 프로그램보다 작을 경우 외부조각이 발생할 가능성이 있다.    Solution 1: Compaction\n 외부조각 같은 hole을 해결하는 방법으로 **컴팩션(compaction)**을 사용한다.  Compaction이란???  물리적 메모리 중에서 프로세스에 의해 사용 중인 메모리 영역을 한 쪽으로 몰고, 가용 공간들을 다른 한쪽으로 모아서 하나의 큰 가용공간을 만드는 방법     메모리 위치를 상당 부분 이동해야 해서 비용이 매우 많이 들기 때문에, 최소한의 메모리 이동으로 얻을려고 한다. 또한, 수행 중인 프로세스의 물리적 메모리 위치를 옮겨야 하므로, 실행 도중 프로세스 주소를 동적으로 바꿀 수 있는 run time binding 방식을 지원하는 환경에서만 수행할 수 있다.    Problem 2: 동적 메모리 할당 문제(Dynamic storage-allocation problem)\n size가 n인 프로세스를 메모리 내 가용 공간 중 어떤 위치에 올릴 지 결정하는 문제    Solution 2: 3가지\n 아래 3가지 방법들 중 첫 번째와 두 번째가 속도와 공간 이용률 측면에서 효과적이다. 최초적합(first-fit) 방법  size가 n 이상인 것 중 가장 먼저 찾아지는 hole에 프로세스를 할당하는 방법으로, 시간적인 측면에서 효율적이다.   최적적합(best-fit) 방법  size가 n 이상인 가장 작은 hole을 찾아 새로운 프로그램을 할당하는 방법으로, 모든 hole의 리스트를 탐색하므로 시간적 오버헤드가 발생하지만, 공간적인 측면에서는 효율적이다.   최악적합(Worst-fit) 방법  가장 크기가 큰 hole을 찾아 새로운 프로그램을 할당하는 방법으로, 시간적 오버헤드가 발생하고, 가용 공간을 빨리 소진한다.      3.2 불연속할당(Noncontiguous allocation) 기법  물리적 메모리의 여러 위치에 분산되어 올라가는 메모리 할당 기법\n   프로그램을 분할하는 기준에 따라 여러 방법으로 나눠진다.\n 페이징(paging) 기법: 동일한 크기로 나누어 메모리에 올리는 기법 세그먼테이션(segmentation) 기법: 크기는 일정하지 않지만, 의미 단위로 나누어 메모리에 올리는 기법 페이지드 세그먼테이션(paged segmentation) 기법: segmentation을 기본으로 한 후, paging 기법으로 나누어 메모리에 올리는 기법    그러면 다음 챕터에서 위 3가지 기법들에 대해 알아보자.\n   Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_07_%EB%A9%94%EB%AA%A8%EB%A6%AC%EA%B4%80%EB%A6%AC_1/","summary":"logical address와 physical address를 어떻게 mapping하는지, 메모리 관리와 관련된 용어 4가지에 대해 알아보고, 물리적 메모리의 할당 방식 연속할당과 불연속할당 방식 중 연속할당에 대해 알아본다.","title":"[TIL] OS Chapter 07: 메모리 관리 1"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. Bound process 1.1 CPU란??  CPU(Central Processing Unit): PC(Program Counter)가 가리키는 주소의 기계어 명령을 실제로 수행하는 컴퓨터 내의 중앙처리장치  PC: Program Counter로, 레지스터의 한 종류로서 현재 CPU에서 수행할 프로세스의 코드의 메모리 주소값을 가지고 있다.    1.2 기계어 명령의 종류   CPU에서 수행하는 기계어 명령어의 종류를 알아보자.\n  1. CPU 내에서 수행되는 명령어\n Add 명령어: CPU 내의 레지스터에 있는 두 값을 더해 레지스터에 저장하는 명령어 CPU 내에서만 수행되므로 명령의 수행 속도가 매우 빠르다.    2. 메모리 접근을 필요로 하는 명령어\n Load 명령어: 메모리에 있는 데이터를 CPU로 읽어들이는 명령어 Store 명령어: CPU에서 계산된 결과값을 메모리에 저장하는 명령어 1번보다 느리지만, 비교적 짧은 시간에 수행 가능하다.    3. 입출력 동반 명령어\n 입출력 작업(I/O 작업)이 필요한 경우, 사용하는 명령어  ex) 키보드로부터 입력을 받기, 화면에 출력하기   입출력 수반 명령은 1번과 2번에 비해 대단히 오랜 시간이 걸린다. 입출력 작업은 특권 명령으로 규정해서 user program이 직접 수행할 수 없고, OS를 통해서 서비스를 대행하도록 한다.    각 명령어 수행 속도 비교: 3번 \u0026gt; 2번 \u0026gt; 1번\n  특권 명령과 일반 명령으로 분류\n 특권 명령: 3번 일반 명령: 1번과 2번    1.3 CPU burst와 I/O burst   user program이 실행되는 과정은 CPU 작업 과 I/O 작업의 반복이다.\n  즉, CPU burst 와 I/O burst가 번갈아 실행된다.\n CPU burst(버스트): user program이 CPU만 연속적으로 사용하여 instruction만 실행하는 일련의 단계 -\u0026gt; user mode I/O burst(버스트): I/O 요청이 발생해 kernel에 의해 입출력 작업을 진행하는 비교적 느린 단계 -\u0026gt; kernel mode    위 2가지를 I/O 작업을 기준으로 분류해보자.\n  CPU burst: program이 I/O를 한 번 완료한 후, 다음 번 I/O를 수행하기까지 직접 CPU를 가지고 명령을 수행하는 일련의 작업\n  I/O burst: I/O 작업이 요청된 후, 다시 CPU burst로 돌아가기까지 일어나는 일련의 작업\n    1.4 Bound process: CPU \u0026amp; I/O   각 program마다 CPU burst와 I/O burst의 비율이 균일하지 않다.\n  그래서 CPU bound process와 I/O bound process로 나눠볼 수 있다.\n  CPU bound process: 계산 위주의 jb\n few very long CPU bursts 입출력 작업 없이 CPU 작업에 소모하는 계산 위주의 프로그램이 해당된다.    I/O bound process: CPU를 잡고 계산하는 시간보다 I/O에 많은 시간이 필요한 job\n Many short CPU bursts 대화형 프로그램(interactive prgram)에 해당 즉, 사용자에게 입력을 받아 CPU 연산을 수행하여 그 결과를 다시 출력하는 작업에 해당      1.5 CPU sheduling이 필요한 이유   여러 종류의 process(=job)이 동일한 시스템 내부에서 섞여 있기 때문에, CPU scheduling이 필요하다.\n  I/O는 interactive job으로서 적절한 response 필요하다.\n  CPU와 I/O 장치 등 시스템 자원을 골고루 효율적으로 사용\n    특히, 이 CPU는 한 시스템 내에 하나 밖에 없으므로, 시분할 시스템에서 매우 효율적으로 관리해야 한다.\n  대부분의 짧은 CPU burst + 극히 일부분의 긴 CPU burst\n= 대부분 CPU를 오래 사용하기보다는 잠깐 사용하고, I/O 작업을 수행하는 process들이 많다.\n= CPU busrt가 짧은 process는 대부분 대화형 작업이다. = CPU 스케쥴링을 할 때, CPU burst가 짧은 process에게 우선적으로 CPU를 사용할 수 있도록 하는 스케쥴링이 필요\n  그래서, I/O bound process의 우선순위를 높이는 것이 바람직한다.\n I/O bound process에게 늦게 주면 사용자는 답답함을 느낀다.     2. CPU 스케쥴러   CPU 스케쥴러란?? ready state에 있는 procese 중에서 이번에 CPU를 줄 프로세스를 결정하는 OS의 code\n HW가 아닌, os의 code 중 이 기능을 하는 부분을 CPU 스케쥴러라 부르는 것이다.    CPU 스케쥴링이 필요한 경우\n I/O 요청 system call에 의해 running에서 blocked로 바뀐 경우 Timer interrupt에 의해 running에서 ready로 바뀐 경우 I/O 작업 요청으로 blocked 상태였던 process가 I/O 작업 완료에 의해 devce controller가 interrupt 발생하여 ready 상태로 바뀐 경우 running 상태에 있는 프로세스가 종료(terminate)되는 경우    CPU 스케쥴링 방식 2가지: 비선점형(non-preemptive) 과 선점형(preemptive)\n 비선점형(preemptive): process가 작업완료 후, 자발적으로 CPU를 반납하는 방식 -\u0026gt; 1번과 4번 선점형(preemptive): CPU를 계속 사용하기 원해도, 강제로 빼앗는 방법 -\u0026gt; 2번과 3번  ex) timer interrupt       3. Dispatcher   Dispatcher란?? CPU scheduler에 의해 새롭게 선택된 프로세스가 CPU를 할당받아 작업을 수행하도록 환경설정을 하는 OS의 code\n HW가 아닌, os의 code 중 이 기능을 하는 부분을 CPU 스케쥴러라 부르는 것이다.    Dispatcher 과정\n 현재 수행 중이던 process context를 이 process의 PCB에 저장한다.\n-\u0026gt; 새로운 process의 PCB를 복원\n-\u0026gt; user mode로 전환하여 CPU를 넘긴다.\n-\u0026gt; 복원된 context의 program counter로 현재 수행할 주소를 찾는다.    Dispatch latency (디스패치 지연시간): 디스패치가 하나의 프로세스를 정지시키고 다른 프로세스에게 CPU를 전달하기까지 걸리는 시간\n Dispatcher 과정에서 1번부터 3번까지 걸린 시간 context switching의 overhead에 해당     4. 스케쥴링의 성능 척도   스케쥴링의 성능을 평가하기 위해 여러 지표들이 사용된다.\n 시스템 관점의 지표: CPU 이용률, 처리량(throughput) 사용자 관점의 지표: 소요시간, 대기시간, 응답시간    시스템 관점의 지표\n  CPU 이용률(CPU utilization): 전체 시간 중 CPU가 일을 한 시간\n 휴면 상태(idle)에 머무르는 시간을 최대한 줄이는 것이 CPU 스케쥴링의 중요한 목표    처리량(throughput): 주어진 시간 동안 ready queue에서 CPU burst를 완료한 프로세스의 개수\n CPU burst가 짧은 process에게 할당할수록 증가한다.      사용자 관점의 지표\n  소요시간(turnaround time): process가 CPU를 요청한 시점부터 자신이 원하는 만큼 CPU를 다 쓰고, CPU burst가 끝날 때까지 걸린 시간\n 대기시간(waiting time) + 실제로 CPU를 이용한 시간의 합    대기시간(waiting time): CPU burst 기간 중 process가 ready queue에서 CPU를 얻기 위해 기다린 시간의 합\n CPU burst 동안, CPU를 얻기 잃는 걸 반복한다.    응답시간(response time): process가 ready queue에 들어온 후, 첫 번째 CPU를 획득하기까지 기다린 시간\n 사용자 응답하는 대화형 시스템에서 적합한 성능 척도 사용자 관점 지표에서 가장 중요 timer interrupt가 빈번할수록 응답시간 감소      생활 속의 비유: 중국집\n 이용률과 처리량 -\u0026gt; 중국집 입장에서의 척도  이용률: 전체 시간 중 주방장이 일한 시간의 비율 처리량: 주방장이 주어진 시간 동안 몇 명의 손님에게 요리를 만들어주었는지 중국집 입장에서는 주방장을 고용해서 가능한 많은 일을 시키는 것이 좋으므로, 이용률이 높은 것을 선호한다.   소요시간, 대기시간, 응답시간 -\u0026gt; 손님 입장에서의 척도  소요시간: 손님이 중국집에 들어와서 주문한 음식을 다 먹고 나가기까지 소요된 총 시간 대기시간: 각각의 음식이 나오기까지 기다린 시간을 합한 것 응답시간: 최초의 음식이 나오기까지 기다린 시간       5. 스케쥴링 알고리즘 5.1 선입선출 스케쥴링(FCFS: First-Come First-Served)   process가 ready queue에 도착한 순서대로 CPU를 할당하는 방식. 비선점형이다.     FCFS 스케쥴링은 먼저 도착한 프로세스의 성격에 따라 평균 대기시간이 크게 달라진다.\n CPU burst가 긴 프로세스가 먼저 도착할 경우: 평균 대기시간이 길어진다. (Conboy effect) CPU burst가 짧은 프로세스가 먼저 도착할 경우: 평균 대기시간이 짧아진다.    단점\n 콘보이 현상(Convoy effect): CPU burst가 긴 process가 짧은 process보다 먼저 도착하여 오랜 시간을 기다려야하는 현상으로, 평균 대기시간이 길어진다.  FCFS의 대표적인 단점      예시\n   프로세스 CPU burst 시간     P1 24   P2 3   P3 3      들어온 순서가 P1,P2,P3 일 때\n 대기시간: P1 = 0, P2 = 24, P3 = 27 평균 대기시간: (0 + 24 + 27 ) / 3 = 17    들어온 순서가 P2, P3, P1 일 때\n 대기시간: P1 = 6, P2 = 0, P3 = 3 평균 대기시간: (6+0+3)/3 = 3      5.2 최단작업 우선 스케쥴링(Shortest-Job First: SJF)   CPU burst가 가장 짧은 process에게 제일 먼저 CPU를 할당하는 방식 평균 대기시간을 가장 짧게 하는 최적 알고리즘(optimal algorithum)이지만 최고의 알고리즘은 아니다.     SJF algorithum의 방식: 비선점형(non-preemptive) 과 선점형(preemptive)\n  효율적이지만, 형평성을 간과한 스케쥴링\n 비선점형(preemptive): 프로세스가 CPU를 자진 반납하기 전까지는 CPU를 빼앗지 않는 방식 선점형(preemptive): ready queue에서 CPU burst가 가장 짧은 process에게 CPU를 할당했어도, 더 짧은 process가 도착할 경우, CPU를 빼앗아 더 짧은 process에게 부여하는 방식  SRTF(Shortest Remaining Time First)라고도 한다. process들이 ready queue에 도착시간이 불규칙한 환경에서는 선점형이 평균 대기시간을 최소화하는 최적의 알고리즘이 된다.      SJF의 선점형 첫 번째 문제점: 기아 현상(starvation)\n 기아 현상(starvation): CPU burst가 짧은 process가 계속 도착할 경우, 한 process는 영원히 CPU를 할당받지 못하는 현상    SJF의 두 번째 문제점: 현실적으로 미리 알 수 없는 CPU burst 시간\n 하지만 과거의 data를 통해서 예측할 수 있다.    예시\n  비선점형\n  선점형\n    5.3 우선순위 스케쥴링(Priority scheduling)   ready queue에서 기다리는 process 중 우선선위가 가장 높은 process에게 제일 먼저 CPU를 할당하는 방식 우선순위는 우선순위값(priority number)을 통해 표시하며, 작을수록 높은 우선순위를 가지는 것으로 가정한다.     우선순위 스케쥴링도 비선점형 방식과 선점형 방식으로 각각 구현할 수 있다.\n  SJF도 우선순위 스케쥴링의 한 종류다.\n 왜냐하면, CPU burst 시간을 우선순위값으로 정의하며 우선순위 스케쥴링은 SJF 알고리즘과 동일하다.    Problem: 우선순위 스케쥴링도 기아 현상(starvation) 문제점이 있다.\n  Solution: 노화 기법(aging) 을 사용한다.\n 기다리는 시간이 비례하여 우선순위를 높이는 것을 말한다.\nex) 버스나 지하철에서 나이 드신 분께 자리를 양보하는 것과 동일.    5.4 라운드 로빈 스케쥴링(Round Robin Scheduling)   시분할 시스템의 성질을 가장 잘 활용한 스케쥴링 방식 각 프로세스가 연속적으로 CPU를 사용할 수 있는 시간이 제한되며, 이 시간이 경과하면 CPU를 회수해 ready queue에 줄 슨다.     현대 CPU 스케쥴링의 기반 + CPU 설명의 기반 스케쥴링: 라운드 로빈 스케쥴링\n  각 프로세스가 연속적으로 CPU를 사용할 수 있는 시간: 할당 시간(time quantum)\n 규모: 수십 밀리초 정도의 규모 할당시간이 지나면 timer interrupt가 발생 CPU 사용 시간이 할당 시간보다 짧으면 스스로 반납한다. 할당 시간이 너무 짧으면 문맥교환의 오버헤드가 증가하여, 전체 시스템 성능이 저하된다.    대화형 프로세스의 빠른 응답 시간(response time)을 보장할 수 있다.\n  라운드 로빈 스케쥴링의 기본적인 목적: 공정성\n CPU burst 시간이 짧은 프로세스가 빨리 CPU를 얻고, 동시에 CPU burst 시간이 긴 프로세스가 불이익 X CPU를 사용하고자 하는 양에 비례하여 소요시간이 증가하므로 공정하다.    Round robine과 다른 scheduling 비교\n  SJF와의 비교: SJF보다 평균 turnaround time이 길지만, response time은 더 짧다는 것이 중요한 장점이다.\n  FCFS와의 비교: 할당시간을 크게 하면 FCFS와 동일\n  CPU 버스트 시간이 동일한 프로세스들일 경우,\n FCFS: CPU를 먼저 쓰고 나가는 프로세스의 소요시간 및 대기시간이 짧아진다. Round robine: CPU를 조금씩 같이 쓰고, 거의 동시에 끝나게 되어 소요시간 및 대기시간이 가장 오래 기다린 프로세스에 맞춰진다. 따라서 Round robine 스케쥴링은 FCFS의 평균 대기시간 및 평균 소요시간이 FCFS보다 거의 두 배로 더 길어진다.    하지만, CPU burst 시간이 균일하지 않은 경우가 대부분이기 때문에, Round robine은 FCFS보다 합리적\n      5.5 멀티레벨 큐(Multi-level queue)   ready queue를 여러 개로 분할해 관리하는 스케쥴링 기법 공정하지 않은 알고리즘이지만, 우선순위가 높은 프로세스가 더 빨리 CPU를 얻어야 하기 때문이다.     이 기법의 경우, 다음과 같은 문제점이 발생한다.\n 이 기법의 경우, 어떤 줄에 서 있는 프로세스를 우선적으로 스케쥴링할 것인가?? 프로세스가 도착했을 때, 어느 줄에 세워야할지 결정하는 메커니즘 필요    첫 번째 문제에 대한 해결책: 프로세스의 성격에 맞는 스케쥴링을 사용한다.\n 전위 큐(foreground queue): 대화형 작업(interactive job)을 담기 위한 전위 -\u0026gt; 응답시간을 짧게 하기 위해 Round robin scheduling 사용 후위 큐(background queue): 계산 위주의 작업을 담기 위한 후위 -\u0026gt; 응답 시간이 큰 의미를 가지지 않기 때문에, 그리고 context switching overhead를 줄이기 위해 FCFS 사용    두 번째 문제에 대한 해결책: 고정 우선순위 방식(fixed priority scheduling)\n Fixed priority scheduling(고정 우선순위 방식)  Queue에 고정적인 우선순위를 부여하는 방식  우선순위가 높은 큐를 먼저 서비스 -\u0026gt; 낮은 큐는 우선순위가 높은 큐가 비어있을 때만 서비스 실행.   즉, 전위 큐에 있는 프로세스에게 우선적으로 CPU를 부여하고, 전위 큐가 비어 있는 경우에만 후위 큐에 있는 프로세스에게 CPU를 할당한다. 하지만, starvation 이 발생할 수 있다.      두 번재 문제에 대한 또 다른 해결책: time slice\n 각 queue에 CPU 시간을 적절한 비율로 할당  ex) RR인 전위 큐: 80% , FCFS인 후위 큐: 20%      5.6 멀티레벨 피드백 큐(Multi-level Feedback Queue)  멀티레벨 큐와 거의 다 동일하나, 차이점은 process가 하나의 queue에서 다른 큐로 이동이 가능하다.\n즉, 프로세스의 우선순위가 바뀔 수 있다.\n   우선순위 스케쥴링의 aging 기법을 멀티레벨 피드백 큐 방식으로 구현하면,\n 기다렸으면 우선순위가 낮은 큐에서 높은 큐로 승격시키는 방식이다. 차근 차근 시간을 늘려 때문에, CPU 사용 시간을 예측할 필요가 없다.    멀티레벨 피드백 큐를 정의하는 요소들\n 큐의 수 각 큐의 스케쥴링 알고리즘  프로세스를 상위 큐로 승격시키는 기준 프로세스를 하위 큐로 강등시키는 기준 프로세스가 도착했을 때, 들어갈 큐를 결정하는 기준 등등      멀티레벨 피드백 큐의 동작 예\n 프로세스가 준비 큐에 도착하면 우선순위가 가장 높은 큐(Round robine, 할당시간 8)에 줄을 선다.\n-\u0026gt; CPU 사용시간이 짧은 대화형 프로세스라면 빨리 서비스 박고 작업완료할 수 있다.\n-\u0026gt; CPU burst가 긴 process라면 하위 큐(Round robine, 할당시간 16)로 강등시킨다. -\u0026gt; 그럼에도 완료하지 못하면 계산위주의 프로세스로 간주하여 최하위 큐인 FCFS scheduling을 적용    5.7 다중처리기 스케쥴링(Multi-processor system)  multi-processor 상황에서의 scheduling 기법\n   은행창구에서 번호표를 뽑아 기다리는 것처럼 CPU가 알아서 다음 프로세스를 꺼내가도록 할 수 있다.\n  하지만, 반드시 특정 CPU가 실행해야 한다든가 ex) 미용실에서 특정 미용사로 예약한 경우\n  Load sharing\n 각 CPU 별 부하가 적절히 분산되도록 하는 매커니즘이 필요하다.    다중처리기 스케쥴링의 방식\n 대칭형 다중처리(SMP, Symetric Multi-Processing): 모든 CPU가 대등해서 각자 알아서 스케줄링을 결정하는 방식 비대칭형 다중처리(asymmetric multiprogramming): 하나의 CPU가 다른 모든 CPU의 스케줄링 및 데이터 접근을 책임지고, CPU는 거기에 따라 움직이는 방식    5.8 실시간 스케쥴링(real-time system)  정해진 시간(dead line) 이내에 처리해야만 하는 스케줄링\n  경성 실시간 시스템(Hard real-time system)과 연성 실시간 시스템(soft real-time system)으로 나눠진다.  전자는 원자로 제어, 미사일 발사 등 시간을 정확히 지켜야하는 시스템 후자는 데드라인이 존재하지만, 지키지 못했다고 하여 위험한 상황이 발생하지 않는다.    5.9 Thread scheduling  Thread를 구현하는 방식 2가지  Local Scheduling (by user process)  User level thread의 경우, process가 thread를 직접 관리하고 OS는 thread의 존재를 모른다. 그래서 OS는 이 thread에게 CPU를 줄지 결정한다. 그리고, process 내부에서 어떤 thread에게 줄지를 결정한다.   Global Scheduling (by OS)  Kernel level thread의 경우, 일반 프로세스와 마찬가지로 커널의 단기 스케쥴러가 어떤 thread를 스케줄할지 결정 즉, OS가 thread의 존재를 인지한다.       6. 스케쥴링 알고리즘의 평가  스케쥴링 알고리즘의 성능을 평가하는 방법에는 큐잉모델(Queuing model), 구현 및 실측(Implementation \u0026amp; measrrement), 시뮬레이션(Simulation)가 있다.  Queueing model: 이론가들이 수행하는 방식  수학적 계산을 통해 performance index(CPU 처리량, Process 평균 대기시간 등)를 구한다. 밑에 방식이 훨씬 많이 사용된다.   Implementation \u0026amp; measurement: 이론가가 아닌 구현가들이 수행하는 방식  동일한 program을 원래 kernel과 CPU scheduler code를 수정한 kernel에서 수행한 후, 실행시간을 측정하여 알고리즘을 평가한다. 이 방법이 어려우면 밑에 방법을 사용한다.   Simulation: 가상으로 CPU scheduling program을 작성하는 방식  가상으로 CPU scheduling program을 작성한 후, 프로그램의 CPU 요청을 입력값으로 넣어 어떠한 결과가 나오는지 확인하는 방법 그래서 가상으로 생성된 값과 실제 system에서 추출한 입력값(이를 trace라 한다.)을 비교한다.       Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_06_cpu_scheduling/","summary":"Bound process를 중심으로 CPU 스케쥴러가 왜 필요한지, 스케쥴링의 성능 척도는 무엇인지, CPU sheduling 알고리즘의 종류에는 무엇이 있고, 이 알고리즘 평가는 어떻게 이뤄지는지 알아보자.","title":"[TIL] OS Chapter 06: CPU scheduling"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 프로세스의 개념 1.1 Process (프로세스)  is a prgram in execution  프로세스 = 실행 중인 프로그램 디스크에 실행파일 형태로 존재하는 상태(프로그램) → 메모리에 올라감 → 실행 이 실행 중일 때를 process라 한다.    1.2 Process context (프로세스 문맥 )   process의 수행 상태를 정확히 아는데 필요한 모든 요소\n  process conetxt를 알아야 하는 이유???\n CPU는 시분할 시스템으로, timer interrupt에 의해서 여러 process가 돌아가면서 CPU를 사용한다. 이런 상황에서, 한 process가 CPU를 다른 process에게 이양했다가 다시 획득했을 때, 직전 수행 시점의 정확한 상태 를 재현하기 위해서 필요하다.    Process context의 분류\n  Hardware context\n Program counter 각종 register  이 register에 저장된 값들      Process의 address space\n code, data, stack  process만의 독자적인 주소 공간      process 관련 kernel 상의 문맥\n PCB (Process Control Block) Kernel stack  OS가 process를 관리하기 위해 유지하는 자료구조들: PCB, kernel stack       2. 프로세스의 상태 2.1 Process의 상태도   Process는 다음 상태 중 어느 한 상태에 머무르며, 시간의 흐름에 따라 변한다.\n  Process의 상태를 나누는 이유는 컴퓨터의 자원을 효율적으로 관리하기 위함\n  Process의 상태도\n Running:  CPU를 잡고 instruction을 수행 중인 상태   Ready:  다른 조건은 다 만족하고, 메모리에는 올라와 CPU만 기다리는 상태   Blocked( wait, sleep ):  CPU를 할당받아도 당장 instruction을 수행할 수 없는 상태 process 자신이 요청한 even가 즉시 만족되지 않아 이를 기다리는 상태  ex) disk에서 file을 읽어와야 하는 경우 (I/O 작업)     New:  process가 시작되어 자료구조는 생성되었지만, 메모리 획득을 승인받지 못한 상태   Terminated:  execution(실행)이 끝났지만, 자료 구조 정리는 완료하지 못한 상태      Dispatch:\n CPU를 할당받을 process를 선택한 후, 실제로 CPU의 제어권을 넘겨받는 과정    2.2 Process 상태 변화 예시  입출력을 요청한 프로세스의 상태 변화 Running state  A process가 CPU를 할당 받아 기계어 명령을 하나씩 수행\n→ I/O 요청 파일의 내용을 disk에서 읽어와야 명령이 진행될 수 있으므로, 입출력 요청을 한다.\n→ Blocked state 입출력 요청이 완료될 때까지 CPU를 반환한 다음, disk 입출력 서비스를 기다리며 봉쇄 상태로 바뀐다. 그리고, 해당 process는 device I/O queue 뒤에 줄슨다.\n→ Ready state의 process 중 선정 CPU를 할당받을 process를 선택하기 위해, ready 상태의 process 들 중에서 CPU scheduler가 적절한 process를 하나 선정하여 CPU를 할당한다.\n→ Running state B process가 CPU를 받아 자신의 code를 실행한다.\n→ device controller 가 interrupt 발생 I/O 작업을 하던 controller가 interrupt를 발생하여 CPU에게 I/O 작업 완료를 알림\n→ B process를 user mode에서 kernel mode 진입 interrupt의 발생 원인이 B process와 상관없어도, CPU가 현재 사용하고 있던 process가 kernel mode로 진입했다고 판단.\n→ Ready state HW interrupt에 의해서 A process를 blocked state에서 ready state로 바꾼 후, CPU의 ready queue에 줄을 세운다. 그리고, device의 local buffer에 있는 내용을 memory로 이동한다.     3. 프로세스 제어블록 3.1 PCB란 ??  운영체제가 각 process를 관리하기 위해, process 마다 유지하는 정보들을 담는, 커널 내의 자료구조  3.2 PCB의 구성 요소  1) OS가 관리를 위해 사용하는 정보  Process state, process ID  process state: CPU를 할당해도 되는지 여부를 결정하기 위해 process ID: 효율적인 관리를 위해 process 마다 매긴 고유 번호   scheduling information, priority   2) CPU 수행 관련 HW 값  program counter: 다음에 수행할 명령의 위치를 가리킨다. registers   3) 메모리 관련  code, data, stack   4) 파일 관련  open file descriptors: 입출력 관련 상태 정보     4. 문맥교환 (Context switch) Context switch란??   CPU를 한 프로세스에서 다른 프로세스로 넘겨주는 과정\n  문맥 교환 중, OS가 실행하는 것들\n  CPU를 내어주는 process의 state를 이 process의 PCB에 저장\n  CPU를 새롭에 얻는 process의 state를 PCB에서 읽어온다.\n    context switch가 일어나는 경우와 그렇지 않은 경우\n  System call이나 interrupt 발생 시, 반드시 문맥교환이 일어나는 게 아니다.\n 첫 번째 경우, 단지 같은 process의 mode가 바뀌는 경우 두 번째 경우가 context switch다. 첫 번째 경우도 CPU 수행 정보 등 context의 일부를 PCB에 저장해야 하지만, context switch를 하는 경우, 오버헤드가 훨씬 크다. (eg. cache memory flush)  A process의 address space의 code를 실행하다가, kernel address space의 code를 실행하는 것이기 때문에, PCB에 저장해야 한다.        문맥교환에 소요되는 시간은 일종의 오버헤드다.\n 그래서, timer로 CPU 할당시간을 아주 작게 세팅하면 문맥교환이 빈번히 발생하기 때문에, 오버헤드가 상당히 커진다. 하지만, CPU 할당 시간을 너무 크게 설정하면 시분할 시스템의 의미가 퇴색된다. 그러므로, 적절한 CPU 할당시간을 정해야 한다.     5. 프로세스를 스케쥴링 하기 위한 큐 5.1 kernel의 process 상태 관리  process 상태 관리는 kernel의 주소 공간의 data 영역 에 다양한 queue를 두어 수행한다. process들은 각 queue들을 오가며 수행한다.  5.2 다양한 queue 종류  Job queue  현재 시스템 내에 있는 모든 프로세스를 관리하기 위한 큐 모든 process가 속한다. ready queue와 device queue가 다 포함된다. ready 큐에 포함하면 device 큐에는 포함되지 않는다.   Ready queue  현재 메모리 내에 있으면서 CPU를 잡아서 실행되기를 기다리는 프로세스의 집합   Device queues (장치 큐) = HW queue  각 I/O device의 service를 기다리는 process의 집합 각 deivce마다 있기 때문에, 다양하다. 예)  device controller가 줄 서 있는 순서대로 I/O 작업 수행 → 작업 완료하면 controller가 interrupt 발생 → interrupt service routine에 의해서 입출력 작업이 완료된 process는 I/O queue에서 나와 CPU대기 queue 슨다.     resource queue = SW resource  SW queue가 필요한 이유??  SW resource인 공유 데이터에 여러 process가 접근할 경우, 데이터의 일관성 훼손 이 발생할 수 있다. 그래서, 공유 데이터에는 매 시점 하나의 프로세스만이 접근하도록 한다.  SW resource에 접근 중인 process가 다 사용하고 반납할 때까지, 다른 process가 CPU를 할당받았어도 접근하지 말고 공유 데이터 queue에서 기다려야 한다.        5.3 Process scheduling queue의 모습  위 image는 OS가 queue를 어떻게 자료구조로 구현하는지 보여준다. queue는 각 process의 PCB를 연결 list 형태로 관리하여 순서를 정한다. Queue header  큐의 가장 앞부분 PCB의 pointer 부분이 이어진다.   queue 흐름 설명  process가 CPU 할당받고 수행 중 I/O 요청이 발생하면 해당 device queue에 줄을 슨다. device queue에 속한 process는 blocked state였다가, 해당 장치의 서비스를 받으면, device controller가 인터럽트를 발생시켜 준비 상태로 바껴 ready queue로 이동한다. ready queue에는 PCB 7 다음에, PCV 2가 대기하고 있다. magnetic tape에는 아무것도 대기하지 않는다. disk queue에는 PCB 3 ← PCB 14 ← PCB 6 순서로 대기하고 있다. terminal queue에는 PCB 5 만 대기하고 있다.     6. 스케쥴러 (Scheduler) 6.1 Long-term scheduler (장기 스케쥴러 or job scheduler)  시작 프로세스 중 어떤 것들을 ready queue 로 보낼지 결정 process에 memory (및 각종 자원) 을 주는 문제  메모리를 어느 것에 줄지를 결정 현대의 컴퓨터는 메모리를 기본적으로 바로 준다.   degree of Multiprogramming 제어  multi-programming: 메모리에 여러 프로그램이 동시에 올라가는 것을 의미 이 메모리에 올라가는 수를 제어하는 것 → 컴퓨터 성능에 영향을 줌 현 컴퓨터에는 장기 스케쥴러는 없고, 프로그램이 시작하면 다 ready 상태로 들어간다.   time sharing system에는 보통 장기 scheduler가 없다. (무조건 ready)  6.2 Short-term schduler (단기 scheduler or CPU scheduler)  어떤 프로세스를 다음 번에 running 시킬지 결정 프로세스에 CPU 를주는문제 충분히 빨라야 함 (milli-second 단위)  6.3 Medium-Term Scheduler (중기 스케쥴러 or Swapper)  여유 공간 마련을 위해 프로세스를 통째로 메모리에서 디스크로 쫓아낸다. 프로세스에게서 memory 를 뺏는 문제  메모리에 프로그램이 너무 많이 올라가면, 쫓아내어 전체적인 컴퓨터 성능을 개선. 시스템 입장에서는 장기 스케쥴러보다 중기 스케쥴러를 주는 게 더 이득   degree of multiprogramming 을 제어  현재 multi-programming을 제어하는 scheduler 이 중기 스케쥴러가 들어가 있기 때문에, 프로세스의 상태 3가지에 추가된 게 suspended다.    6.4 추가된 프로세스 상태도  중기 스케쥴러에 의해 suspended state가 추가되었다. Running  CPU를 잡고 instruction을 수행 중인 상태   Ready  CPU를 기다리는 상태( 메모리 등 다른 조건을 모두 만족하고)   Blocked (wait, sleep)  I/O 등의 event를 스스로 기다리는 상태 예) 디스크에서 file을 읽어와야 하는 경우   Suspended (stopped)  외부적인 이유로 강제로 프로세스의 수행이 정지된 상태  중기 스케쥴러에 의해 강제로 뺏긴 상태   이 상태의 프로세스는 통째로 디스크에 swap out 된다. 예) 사용자가 프로그램을 일시 정지시킨 경우 (break key). 이 경우에는 사람이 재개시켜야 위의 상태가 된다.  시스템이 여러 이유로 프로세스를 잠시 중단시킴 → 중기 스케쥴러 (메모리에 너무 많은 프로세스가 올라와 있을 때)     blocked와 suspended 구분하기  Blocekd: 자신이 요청한 event가 만족되면(자신이 요청한 작업이 완료되면) Ready Suspended: 외부에서 정지된 상태이기 대문에, 외부에서 resume 해 주어야 Active     7. 프로세스의 생성 7.1 Process creation (프로세스 생성) : COW(Copy-On-Write)  OS가 process를 전부 생성하는 게 아닌, 부팅 후 최초의 process는 운영체제가 직접 생성한다. 그 다음부터는 이미 존재하는 process가 다른 process를 복제 생성한다. process를 생성하는 process를 부모 프로세스라 하고, 생성된 process를 자식 프로세스라 한다.  부모 프로세스 1개가 자식 프로세스 최소 1개를 복제 생성 한다. 또한, 자식 프로세스가 또 process를 생성할 수 있다. 프로세스의 트리(계층 구조) 형성   작업 수행을 위한 자원  부모 프로세스는 OS로부터 받는다. 자식 프로세스는 부모 프로세스와 공유 한다.  부모와 자식 프로세스가 서로 모든 자원을 공유 하는 모델 일부를 공유 하는 모델 전혀 공유하지 않는 모델     주소 공간 (Address space)  process 생성의 첫 번째: 부모 공간을 복사 → 두 번째: 복사한 공간에 새로운 프로그램의 주소 공간을 덮어씌운다.   Process 와 관련한 system call (특권 명령 )  fork() : create a child (copy) exec() : overlay new image = 새로운 프로그램으로서 덮어씌운다. wait() : sleep until child is done exit() : frees all the resources, notify parent   UNIX의 예  os에게 fork() system call 요청하여, 새로운 process를 생성  부모를 그대로 복사하고, 주고 공간을 할당 복사할 때, 부모 프로세스의 process ID는 제외한다.   fork () 다음에 이어지는 exec () system cal을 통해 새로운 프로그램을 메모리에 올린다. fork () 와 exec () 둘 다 system call을 통해서 실행되므로, 운영체제가 생성한다.    7.2 Process Termination (프로세스 종료)  프로세스가 마지막 명령을 수행한 후, 운영체제에게 이를 알려준다. (’exit’ system call)  자식이 부모에게 output data를 보낸다. (via ‘wait’ system call) 프로세스의 각종 자원들이 운영체제에게 반납된다. 자식 프로세스가 먼저 종료 후 부모 프로세스가 종료되야 한다.   부모 프로세스에게 자식의 수행을 종료시킨다. (abort)  자식이 할당 자원의 한계치를 넘어설 때 자식에게 할당된 task가 더 이상 필요하지 않을 때 (자식 프로세스를 만든 이유가 일을 시키기 위함이기 때문) 부모가 종료(exit)할 때  운영체제는 부모프로세스가 종료하는 경우, 자식이 더 수행되도록 두지 않는다. 단계적인 종료( 손자 → 자식 → 부모 )가 지켜져야 한다.      7.3 fork () system call  creats a new address space that is a duplicate of the caller 자식 process를 만들 때, 부모 process의 program counter까지 복사된다.  부모 process와 자식 process의 차이는 식별자 다.   그래서, program counter는 fork () 실행 후, 다음 코드를 가리키기 때문에, 자식 process는 fork ()한 이후부터 코드를 실행한다.  자식 process라 부르지만, 복제인간이라 생각하는 게 정확한다. 또한, 복제된 process는 자신을 원본이라 생각한다.   복제된 process인지 아닌지 구분하는 방법  fork 함수의 결과값으로 자식 process 는 0을, 부모 process에게는 양수를 준다.    7.4 exec () system call  fork () 한 후, exec () system call을 통해서 자식 프로세스를 새로운 program으로 대체한다. (overwrite) 한 번 만들어지면 다시 되돌아갈 수 없다.  7.5 wait () system call  wait () system call은 자식 process가 종료될 때까지 process A를 blocked state로 만든다. 자식 프로세스가 종료되면 kernel은 프로세스 A를 준비 상태로 변경하여 준비 큐에 진입.  7.6 exit() system call  process의 종료  자발적 종료  마지막 statement 수행 후, OS에게 exit () system call로 자신이 종료됨을 알린다. 명시적으로 exit ()을 호출하지 않아도, main () 함수가 반환되는 위치에 compiler가 자동으로 삽입해 프로세스 종료 직전에 항상 호출한다.   비자발적 종료 (자식 프로세스 밖에서 종료시키는 경우)  부모 프로세스가 자식 프로세스를 강제 종료시킨다. When??  자식 프로세스가 한계치를 넘어서는 할당 자원 요청을 할 때 자식에게 할당된 task가 더 이상 필요하지 않을 때   프로그램 종료 버튼을 누르는 경우나, 키보드로 kill, break 등을 친 경우 부모가 종료하는 경우  부모 프로세스가 종료하기 전에 자식들이 먼저 종료된다.       프로그램을 강제 종료시킨 후, 계속 수행시켜야하는 경우에는 종료되지 않는 다른 자식 프로세스로 이양시켜서, 기존 부모 프로세스가 종료된 후에도 다른 프로세스 아래에서 계속 수행한다.  부모가 죽기 전에 자식이 먼저 죽는다는 원칙은 여전히 지켜진다.     8. 프로세스 간의 협력 8.1 Process 간 협력하는 이유  독립적 프로세스 (Independent process)  프로세스는 각자의 주소 공간을 가지고 수행되므로, 원칙적으로 하나의 프로세스는 다른 프로세스의 수행에 영향을 미치지 못한다.   하지만, process 간 협력한다면 왜 하고 어떻게 하는 것일까?? 협력 프로세스( Cooperating process)  Why?  업무의 효율성 증대: 부분적인 처리 결과, 정보를 공유할 수 있고, 처리 속도가 향상.   How? - IPC(Inter-Process Communication): process 간 통신과 동기화를 이루기 위한 mechanism     8.2 IPC의 대표적인 방법: 2가지   Message passing: 메시지 전달 방식\n  Message passing의 특징\n 프로세스 사이에 공유 변수(shared variable)을 일체 사용하지 않고 통신하는 시스템. 중간에 kernel을 통해서 하는데, 명시적으로 process의 이름을 표시하냐 안하냐의 차이. kernel에 의해 send(message)와 receive(message)라는 두 가지 연산을 제공받는다.  즉, 이 두 가지 연산은 특권명령이다.      Message passing 방식 2가지\n 직접 통신 (direct communication) 간접 통신 (Indirect communication)      Shared memory: 공유 메모리 방식\n  8.3 Message passing 방식: 2가지  Message passing 방식에는 직접통신(direct communication)과 간접통신(indirect communication) 으로 나뉜다. Direct communication  - 통신하려는 프로세스의 이름을 명시적으로 표시한다. - Send (Q, message): process Q에게 메시지를 전송하는 것을 의미 - Receive (P, message): process P로부터 메시지를 전달받는 것을 의미 - link는 자동적으로 생성되며, 하나의 link는 정확히 한 쌍의 process에게 할당된다. - 각 쌍의 process에게는 오직 하나의 link만이 존재한다.   Indirect communication  - 통신하려는 프로세스의 이름을 명시적으로 표시하지 않는다. - mailbox ( or port)를 통해 메시지를 간접 전달한다. - mailbox에는 고유의 ID가 있다. - 이 mailbox를 공유하는 process 들끼리만 서로 통신할 수 있다. - Send(M, message): M이라는 mailbox에 message를 전달하는 것 - Receive(M, message): M이라는 mailbox로부터 메시지를 전달받는 것 - mailbox를 3개 이상의 process가 공유할 경우, 각각의 프로세스에게 링크를 따로 생성가능.  8.4 Shared memory  서로 다른 process 간에도 일부 주소 공간을 공유하게 하는 mechanism 두 process가 서로 신뢰할 수 있는 process여야 한다. kernel에게 system call 후, memory가 공유된다. 물리적인 공간에 mapping 할 때, 공유된 상태로 진행한다. 이 방법에서 동기화 문제는 kernel 책임지지 않고, 공유되는 process 들이 책임져야 한다.   9. Thread 9.1 Thread란??   A Thread (or lightweight process) is a basic unit of CPU utilization\n CPU의 기본 실행 단위를 Thread 라 한다.    Thread의 구성\n Program counter register set stack space  stack space에서 여러 thread로 나눠진다.      process 내부에서 thread가 동료 thread와 공유하는 부분 = task\n code section data section OS resources    heavyweight process 는 하나의 thread를 가지고 있는 task 다.\n CPU가 명령을 수행하기 위해서는 코드의 실행될 부분을 가리키는 program counter가 있어야 한다. 또한, memory에 register 값 을 세팅해야 한다. 그리고, OS는 process를 관리하기 위해 process마다 1개의 PCB를 둔다. 이 PCB를 보면 여러 thread로 구성된 걸 확인할 수 있다.    9.2 Thread의 장점  Responsiveness: 응답성  eg) multi-thread: 하나의 서버 thread가 blocked state 인 동안에도, 동일한 task 내의 다른 thread가 계속 실행되어 빠른 처리를 할 수 있다.   Resource sharing: 자원의 효율적인 관리  여러 thread가 process의 code, data, resource를 공유하기 때문에, 자원 관리가 효율적.   Economy: 경제성  process를 새로 생성하는 것보다 thread를 새로 생성하는 게 오버헤드가 훨씬 적다. process 간의 switching보다, thread 간의 switching이 오버헤드가 훨씬 적다.   Utilization of MP Architectures  병렬로 thread가 실행될 수 있다. 다중 thread가 협력하여 높은 처리율과 성능 향상을 얻는다.    9.3 Implementation of threads  Some are supported by kernel ⇒ Kernel threads  thread가 여러 개인 것을 운영체제가 알고 있음 예)  Windows 95, 98 / NT Solaris Digital UNIX, Mach     Others are supported by library ⇒ User Threads  운영체제가 프로세스 안에 thread가 여러개인 걸 모른다. 즉, User program이 thread를 관리한다. 예)  POSIX Pthreads MAch C-threads Solaris threads     Some are real time threads  real time을 지원하는 thread     Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_05_%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EA%B4%80%EB%A6%AC/","summary":"프로세스란 무엇인지, 프로세스의 상태는 어떻게 흘러가는지, 문맥 교환이란 무엇인지, 프로세스가 어떻게 생성되고 종료되는지, 프로세스끼리 협력은 어떻게 하는지, thread는 무엇인지 알아보겠다.","title":"[TIL] OS Chapter 05: 프로세스 관리"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 프로그램의 구조와 인터럽트  프로그램이 CPU에서 명령을 수행하기 위해서는 명령을 담은 프로그램의 주소 영역이 메모리에 올라가 있어야 한다. 왜냐하면 CPU는 메모리에 있는 instruction만을 보고 실행하기 때문이다.  1.1 프로그램의 주소 영역  프로그램의 주소영역 = Code + Data + Stack 영역 Code 영역  작성한 함수의 코드가 CPU에서 수행하는 기계어 형태로 변환되어 저장 되는 공간   Data 영역  전역 변수(global variable) 등 프로그램이 사용하는 데이터를 저장 하는 공간   Stack 영역  프로그램 내의 함수 호출 시의 복귀 주소 및 데이터를 저장 하는 공간 예)  프로그램 내의 X 함수 수행 → 프로그램 내의 Y 함수 호출 → 이 때 X 함수에서 Y 함수를 호출하는 지점을 stack 영역에 저장 → Y 함수가 호출되어 실행할 명령의 메모리 위치가 바뀜 → Y 함수 수행 완료 → stack에 저장된 X 함수의 주소 위치로 돌아와 코드를 계속 수행      1.2 PCB: 프로그램 수행의 복귀 위치  인터럽트가 발생할 경우 복귀 위치: PCB(Process Control block)에 저장한다. interrupt가 발생한 시점에서 프로그램의 어느 부분까지 수행했는지를 PCB에 저장 과정  A 프로그램이 CPU를 할당받아 명령을 수행 → interrupt 발생 → 현재 수행 중인 명령 위치를 PCB에 저장 → CPU 제어권을 OS에게 양도 → 인터럽트 처리 완료 후, PCB에 저장된 작업 지점으로 돌아와 계속 수행     2. 컴퓨터 시스템의 작동 개요  컴퓨터 시스템의 작동  CPU에서 명령을 수행하는 부분 + 컴퓨터 외부장치와 입출력이 이루어지는 부분    2.1 프로그램 카운터(Program Counter(PC))  PC = Program Counter = CPU가 수행해야할 메모리 주소를 담고 있는 레지스터  CPU는  빠른 속도의 연산 능력은 가지고 있지만, 결정 능력을 가지고 있지 않다. 단지 매번 프로그램 카운터가 가리키는 메모리 위치의 명령을 처리한다.   통상 프로그램 카운터가 다음 명령어를 가리키어 CPU 명령은 순차적으로 수행된다.  반복문이나 함수 호출 등으로 바로 다음 주소가 아닌 명령을 수행할 수도 있다.     Program Counter 가  OS가 존재하는 메모리 위치 를 가리키면 CPU가 \u0026lsquo;kernel mode\u0026rsquo; 에서 수행 중 사용자 프로그램의 메모리 위치 를 가리키면 CPU가 \u0026lsquo;user mode\u0026rsquo; 에서 수행 중    2.2 일반 명령과 특권 명령  일반 명령  메모리에서 자료를 읽어와 CPU에서 연산을 하고, 그 결과를 메모리에 쓰는 명령 모든 프로그램이 수행 가능 mode bit가 1일 때   특권 명령  보안이 필요한 명령 각종 장치에 접근하는 명령 운영체제만이 수행 mode bite가 0일 때   운영체제를 향한 사용자 프로그램의 대행 요청: system call  사용자 프로그램이 특권 명령을 사용하고자 할 때, 사용자 프로그램이 특권 명령을 수행할 수 없으므로 운영체제에게 대행 요청 system call 을 한다. 그러면 CPU의 제어권이 운영체제에게 넘어가서 특권 명령을 수행한다.    2.3 인터럽트 라인을 세팅하는 이유  Problem  CPU는 프로그램 카운터가 가리키는 메모리 위치의 명령만 계속 수행하여, 주변장치의 상태를 지속적으로 파악할 수 없다.   Solution  주변 장치들이 CPU의 도움이 필요할 때 인터럽트 라인(interrupt line)을 세팅한다.  CPU는 매번 명령을 수행한 후, 인터럽트 라인을 체크하여 요청 유무를 확인한다. 또한, 인터럽트의 원인이 다양하기 때문에, 인터럽트 라인을 다르게 해서 구분한다.       3. 프로그램의 실행  “프로그램이 실행(program execution)되고 있다”  = disk에 존재하던 실행 파일이 메모리에 적재된다 = program이 CPU를 할당받고 instruction을 수행하고 있는 상태   “프로그램이 동시에 실행된다”  = 여러 프로그램이 짧은 시간 단위로 CPU를 나누어 사용한다. = 프로그램이 메모리에 동시에 적재되어 있을 수 있으므로    3.1 가상 메모리(Virtual Memory)   프로그램은 실행 파일 형태로 하드 디스크에 저장한다.\n 이 때는 프로그램은 주소 영역을 가지고 있다고 한다. 하지만, 실행되는 순간 프로세스가 되며 프로그램의 주소 영역은 프로세스의 주소 공간이 되는 것이다.    파일 실행 → 가상 메모리(Virtual Memory) 생성 → Address transition → 물리적 메모리(Physical Memory) 에 올라감\n 가상 메모리(address space, logical memory) : 프로세스마다 가지는 독자적인 주소 공간 물리적 메모리(Physical Memory) : 0번지부터 시작 Address transition : 가상 메모리 주소를 물리적 메모리 주소로 변환하는 것으로, 하드웨어 장치가 수행     Virtual memory = 주소 공간 = Address space = code + data + stack\n  OS의 주소 공간\n kernel의 code  자원 관리를 위한 부분 사용자에게 편리한 인터페이스를 제공하기 위한 부분 system call 및 interrup를 처리하기 위한 부분   kernel의 data  하드웨어와 소프트웨어(ex: 사용자 프로그램)를 포함하는 시스템 내의 모든 자원을 관리하기 위한 자료구조를 유지 ex) PCB   kernel의 stack  현재 수행 중인 프로세스마다 별도의 스택을 두어 관리.  Reason 1: system call로 특권 명령 대행을 요청한 후, 운영체제가 system call 내부의 다른 함수를 호출할 경우 복귀 주소는 커널 내의 주소가 되기 때문에 Reason 2: kernel은 일종의 공유 코드로서, 모든 프로세스가 system call을 통해 kernel 함수를 접근할 수 있으므로, 각 프로세스마다 커널 내에 별도의 스택을 둔다.        함수 호출 복귀 시 저장 장소\n '____' 코드 수행 중 이루어지는 함수 호출로 인한 복귀 주소 유지는 '____' 을 사용  process → 자신의 address space 내의 stack kernel → kernel stack   여기서 유의사항은 CPU 수행 주체가 OS로 바뀔 때 직전 수행 프로그램의 복귀 정보는 stack이 아닌 PCB에 저장한다는 사실이다.    3.2 Swap area  Problem  프로그램이 프로세스가 되었을 때 생성되는 address space를 물리적 메모리에 다 올리지 않는다. Why?? 다 올리면 메모리 낭비가 심하기 때문   Solution  바로 필요한 코드 부분만 memory에 올린다. 그 외 부분은 보조기억장치에 놔두는데, 이 영역을 swap area라 한다. swap area는 메모리 용량 한계로 메모리 연장 용도로 사용한다. 하지만, 프로그램이 파일 형태로 저장되는 보조기억장치의 disk 영역은 비휘발성 용도로 저장한다.     4. 사용자 프로그램이 사용하는 함수  프로그램이 사용하는 함수의 종류  사용자 정의 함수: 프로그래머 본인이 직접 작성한 함수 라이브러리 함수: 자신의 프로그램에서 정의하지 않고 가져다 쓴 함수로, 자신의 프로그램의 실행 파일에 포함되어 있다. 커널 함수: kernel의 코드에 정의된 함수 = system call 함수 + interrupt 처리 함수  system call 함수: 사용자 프로그램이 운영체제의 서비스를 요청하기 위해 호출함수 interrupt 처리 함수: 각종 HW 및 SW가 CPU의 서비스를 요청하기 위한 함수  kernel의 address space에 code가 정의되기 때문에, system call로 kernel mode로 바꿔야 실행 가능하다.       사용자 정의 함수와 라이브러리 함수 는  프로그램의 코드 영역에 기계어 명령 형태로 존재 → 프로그램 실행 시, 해당 프로세스의 address space에 포함 프로세스 내의 함수 호출 시에도, 프로세스의 address space에 있는 stack 영역을 사용 프로세스의 address space의 code 영역 안에서 메모리 상의 점프를 한다. user mode에서 실행된다.     5. 인터럽트 5.1 Interrupt 작동 순서 복습  CPU는 프로그램 카운터가 가리키는 명령만 쉬지 않고 수행하기 때문에, 다른 명령을 수행하기 위해서는 interrupt를 걸어야 한다. CPU는 program counter가 가리키는 명령을 하나씩 수행한 후, interrupt line이 세팅되었는지 확인한다. interrupt line setting을 통해 interrupt가 발생했으면 현재 수행하던 process를 멈추고, 운영체제의 인터럽트 처리 루틴으로 이동하여, 인터럽트 처리를 수행한다. 인터럽트 처리를 마치면 인터럽트 발생 직전의 프로세스에게 CPU 제어권이 넘어간다.  5.2 Interrupt의 서로 다른 중요도  인터럽트 처리 중, 또 다른 인터럽트가 발생한 경우에는 어떻게 처리되는가???  중요도를 비교한다. 현재 처리 중인 인터럽트의 중요도가 상대적으로 낮으면, 처리 중인 인터럽트 코드의 수행 지점을 저장한다. 그 다음, 중요도가 더 높은 인터럽트를 처리한다. 인터럽트 처리가 끝나면 저장 주소로 복귀해 이전에 수행하던 인터럽트 처리 코드를 마저 수행한다.     6. 시스템 콜   system call 사용의 예\n process가 CPU에서 명령을 수행하던 중 I/O 작업이 필요한 경우, sw interrupt인 system call을 통해 kernel 함수를 호출한다.\n→ kernel 함수는 사용자 프로그램이 수행할 수 없으므로, CPU 제어권을 OS에게 넘겨야 하는데,\n→ OS에게 넘기기 위해서 인터럽트 라인을 세팅하는 명령을 실행하여, CPU에게 interrupt가 발생했다는 걸 알린다.\n→ CPU는 program counter가 가리키는 명령을 하나씩 실행한 후, interrupt line을 체크하여 interrupt 발생을 확인한다.\n→ interrupt를 확인한 CPU는 현재 실행 중인 process를 멈춘 후, process의 실행 상태를 PCB에 저장한다.\n→ OS는 interrupt line을 통해서 어느 종류의 interrupt인지 확인한 후, interrupt vector가 가리키는 interrut service routine을 찾아 실행하여, 요청한 I/O에 해당하는 device controller에게 I/O 명령을 한다.\n→ I/O 요청이 수행되는 동안, 해당 process는 데이터가 없어서 다음 명령을 수행할 수 없으므로, CPU를 다른 process에게 이양한다.\n→ 다른 process의 작업을 CPU가 작업하는 도중에, I/O 작업이 완료되면 device controller가 CPU에게 interrupt를 발생시켜 I/O 작업 완료를 알린다. 이 때 발생한 interrupt는 HW interrupt다.\n→ interrupt 처리 내용으로 device controller가 device로부터 읽어와서 local buffer에 저장한 내용을 메모리로 복사해온다.\n→ 복사 후, I/O 작업을 요청했던 process에게 다시 CPU를 얻을 수 있는 권한을 준다.\n→ 그러면 I/O 작업을 이제 완료한 process는 CPU를 기다리는 큐에 삽입되고, CPU의 제어권은 interrupt를 당한 process에게 넘어가서 하던 작업을 계속 수행한다.    process가 CPU를 빼앗기는 경우: 2가지\n Timer의 CPU 할당 시간이 만료된 경우, interrupt가 발생  time sharing system의 필수적인 요소 한 process가 CPU를 독점하는 걸 방지   process가 I/O 작업 같은 kernel code 수행이 필요한 경우 sw interrupt인 system call 하는 경우  시간이 오래 걸리는 I/O 작업이 수행하는 동안, CPU를 다른 process에게 할당한다.  그 이유는???  입출력 작업을 요청한 process에게 CPU를 할당해도 파일 데이터가 있어야 당장 다음 명령을 수행할 수 있는데, I/O 연산 속도는 CPU 연산 속도보다 매우 느리기 때문에, 긴 기다리는 시간 동안 CPU가 일을 할 수 없어 비효율적이기 때문이다.           7. 프로세스의 두 가지 실행 상태  프로세스의 실행 상태 두 가지: user mode running(사용자 모드에서의 실행 상태) 와 kernel mode running(커널 모드에서의 실행 상태) 프로그램 자신의 주소 공간에서 정의된 코드를 실행 ↔ user mode running  ex) 사용자 정의 함수 와 라이브러리 함수를 호출   kernel의 system call 함수 (kernel 주소 공간에 정의된 함수) 를 실행 ↔ kernel mode running  system call 실행이 끝나면 다시 user mode로 복귀 또한, 프로그램 실행이 끝날 때에는 kernel mode로 진입해 프로그램을 종료한다.   process 가 kernel mode에서 실행 중이란 의미는???  process A가 system call 을 통해 OS에게 대행 요청을 하여 kernel code를 실행 중이다 = process A가 kernel mode에서 실행 중 os가 kernel code를 수행하고 있을 지라도, os는 process A를 대신하여 수행 중이기 때문에, process A가 실행 상태인 걸로 간주한다.     Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_04_%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%A8%EC%9D%98%EA%B5%AC%EC%A1%B0%EC%99%80%EC%8B%A4%ED%96%89/","summary":"프로그램의 구조와 실행에 대해 설명한다. 예를 들어 프로그램의 주소영역, PCB, Program counter, 일반 명령과 특권 명령, Virtual memory, kernel mode와 user mode 등등을 알아본다.","title":"[TIL] OS Chapter 04: 프로그램의 구조와 실행"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   5. 입출력 구조  CPU의 명령 수행 속도는 빠르지만, 입출력 연산은 매우 느리다. 이 입출력 방식에는 동기식 입출력 과 비동기식 입출력 이 있다.  5.1 동기식 입출력(Synchronous I/O)   일반적으로 사용하는 방식으로 어떤 프로그램이 입출력했을 때, 입출력 작업이 완료된 후에야 그 프로그램이 후속 작업을 수행할 수 있는 방식이다.\n 예) 프로그램이 CPU를 점유한 상태에서 디스크에 정보를 읽어오라는 요청을 했다. 디스크 입출력이 완료되기까지 어느 정도의 시간이 소요된다. 이 때 동기식은 입출력 작업이 완료될 때까지 다음 명령을 수행하지 않고 기다린다. 그러다가 입출력이 완료되면 인터럽트를 통해 이 사실을 대기하고 있던 CPU에게 전달하고, CPU의 제어권이 프로그램에게 넘어가서 다음 명령을 수행할 수 있다.    동기식 입출력 과정\nA process가 code 실행 중에 I/O 요청이 필요한 명령을 만나서 I/O 요청을 한다\n→ A는 CPU에게 system call이라는 SW interrupt를 발생\n→ CPU는 프로그램 A의 코드를 실행하던 일을 멈추고, 현재 상태를 프로그램의 PCB에 저장한다\n→ CPU의 제어권이 운영체제에게 넘어간다\n→ A가 입출력 연산을 요청했으므로, 운영체제가 프로세스 A를 봉쇄상태로 표시 그리고, 운영체제는 인터럽트 처리루틴 수행\n→ CPU는 컨트롤러에게 입출력 연산을 요청\n→ 컨트롤러는 A가 요청한 데이터를 디스크로부터 자신의 로컬 버퍼로 읽어온다.\n A가 직접 입출력 작업을 하는 건 아니지만, A의 요청에 의해서 하는 것이므로, 이 과정을 프로세스 A가 입출력 작업을 수행 중이라 언급한다.\n → 컨트롤러가 읽어오는 동안 CPU를 다른 프로그램 B에 할당해 계속 CPU가 일을 할 수 있도록 한다\n→ 원하는 정보가 로컬버퍼로 다 들어오면 컨트롤러는 CPU에게 입출력이 완료되었다는 사실을 인터럽트를 발생시켜 알린다. 이 때 발생시킨 인터럽트는 하드웨어 인터럽트다\n 프로세스 A가 입출력 작업을 완료했다고 언급한다.\n → 프로그램 B를 수행 중이던 CPU는 수행하던 지점 및 상태를 process B의 PCB에 저장하고, 인터럽트를 처리\n→ 인터럽트 처리 루틴은 로컬 버퍼에 있는 A가 요청한 데이터를 A의 메모리 영역으로 읽어오고 A의 봉쇄 상태를 해제시킨다.\n→ A는 CPU를 기다리는 줄에 다시 선다\n→ 다시 B로 돌아와 업무를 중단한 지점부터 계속 진행\n→ A는 CPU를 큐에서 기다리다가 자신의 차례가 되면 CPU를 할당받고 입출력 연산 이후의 작업을 수행\n  5.1.1 입출력 연산 동안 CPU를 다른 process에게 할당하는 이유   기본지식\n 입출력 연산 속도는 CPU 연산 속도보다 매우 느리다. 매 시점 시스템 내에서는 하나의 입출력만 수행할 수 있다. 하지만, 동기화는 자동적으로 이뤄진다.    이유: CPU 낭비 방지를 위해서\n 입출력 연산 속도는 매우 느려서 이를 수행하고 있는 프로그램이 CPU를 계속 점유하면, 프로그램의 입출력 연산이 끝날 때까지 CPU는 인터럽트를 기다리며 아무런 일을 하지 못한다. 그래서 일반적으로 프로그램이 입출력을 수행 중인 경우, CPU를 다른 프로그램에게 이양해 CPU가 쉬지 않고 일하도록 관리한다.    입출력 작업을 수행 중인 프로세스에게 CPU를 할당해도 명령을 수행하지 못하는 이유\n 입출력 중인 프로그램의 상태를 봉쇄 상태(Bblocked state) 로 전환하기 때문 봉쇄 상태의 프로그램에게는 CPU를 할당하지 않고, CPU 할당 시 곧바로 명령을 수행할 수 있는 프로그램에만 CPU를 할당한다. 인터럽트를 보내면 프로그램의 상태를 봉쇄 상태로부터 해제시킨다.    5.1.2 봉쇄 해제 후, ready 상태로 큐에서 기다리는 이유   이유: 동기성 보장 = 동기화를 위해서\n 입출력 수행 중일 때 다른 프로그램에게 CPU를 양도하면, 다수의 입출력 연산이 동시에 요청되거나 처리되어 동기화에 문제가 발생할 수 있다. 그래서 입출력 요청의 동기화를 위해 장치별로 큐(queue)를 두어 요청한 순서대로 처리할 수 있도록 한다.    예시\n 프로그램 A가 먼저 요청했으면 이를 먼저 큐에 넣고, 그 후에 발생한 B의 요청을 A 요청 뒤에 삽입한다. 디스크 차원에서는 큐에 있는 순서대로 처리하여 동기화 문제를 해결할 수 있다.    5.1.3 Summary  동기식 입출력을 요청한 프로그램은 입출력이 완료될 때까지 다음 명령을 수행할 수 없어 CPU가 낭비된다. 그러나, CPU의 효율적인 사용을 위해 입출력이 수행하는 동안 다른 프로그램에게 CPU를 양도하면 동시에 다수의 입출력 연산이 일어날 수 있다. 그래서 다수의 프로그램이 동시에 입출력 연산을 요청하는 경우 동기성(synchronization)을 보장하기 위해 장치마다 큐를 두어 요청된 순서대로 처리할 수 있도록 한다.  5.2 비동기식 입출력(Asynchronous I/O)  I/O가 시작된 후, 입출력 작업이 끝나기를 기다리지 않고 즉시 제어가 사용자 프로그램에 넘어간다. 그래서 입출력 연산과 무관한 처리 가능한 작업부터 처리한다.   6. DMA  Direct Memory Access의 약어로, CPU의 중재 없이 device controller가 device의 buffer stroage에 읽어오면 CPU를 대신하여 잃어온 내용을 메모리에 block 단위로 직접 복사한 후, CPU에게 interrupt를 발생시키는 장치\n  왜 DMA가 필요한가???  문제점: CPU가 interrupt로 많은 방해를 받아 효율이 많이 떨어진다.  Interrupt가 발생하면 CPU는 controller의 local buffer와 memory 사이에서 데이터를 옮기는 일을 수행하는데, 만약 사용자 프로그램이 CPU를 사용하는 중에 I/O 장치가 interrupt를 많이 걸면, CPU가 많은 방해를 받아 CPU 효율이 많이 떨어진다.   해결책: DMA가 CPU를 대신하여 local buffer에서 메모리로 읽어오는 작업을 수행한다.  CPU는 바이트(byte) 단위로 읽어오지만, DMA는 byte가 아닌 block이라는 큰 단위로 정보를 메모리로 읽어온 후에 CPU에게 인터럽트를 발생시켜 해당 작업의 완료를 알리기 때문에, 인터럽트의 빈도를 줄인다.   결과: DMA를 통해 CPU를 효율적으로 관리하고, 입출력 연산을 빠르게 수행 가능     메모리에는 CPU 뿐만 아니라 DMA도 접근할 수 있다는 걸 알 수 있다.\n  7. 저장장치의 구조  저장장치 = 주기억장치 + 보조기억장치 주기억장치 = 메모리 = RAM with 휘발성(volatile) 보조기억장치 = 마그네틱 디스크 with 비휘발성(non-volatile)  ex) 마그네틱 디스크(하드디스크), 플래시 메모리, CD, 마그네틱 테이프 보조기억장치의 용도 = file system용 + swap area용  file system용:  비휘발성 성질을 이용하여 전원이 나가도 유지해야할 정보를 파일형태로 저장하는 용도   swap area용:  메모리 한계로 메모리 연장 용도로 사용. 프로그램 수행에 필요한 부분만 메모리에 올려놓고(process), 그렇지 않은 부분은 swap area에 내려놓는다. swap area에 내려놓는 일을 swap out(스왑 아웃) 이라 한다. 비휘발성으로 사용되는 file system용과 구분       하드디스크의 물리적 구조  여러 개의 마그네틱 원판들이 회전축에 붙어있고, 원판의 표면은 track으로 나눠지고, 각 track은 sector로 나눠지며, 이 sector에 최소한의 단위 정보가 저장된다. Arm assembly에 연결된 arm이 움직이면서 head가 저장된 데이터를 읽고 쓴다.     8. 저장장치의 계층 구조  컴퓨터 시스템의 저장장치 계층 구조는 다음과 같다.  위로 올라갈수록 속도는 빨라지고, 가격은 비싸지고, 용량은 적어진다.     저장장치 = Primary(주기억장치) + Secondary(보조기억장치) Primary  적은 용량, 빠른 속도, 비싼 가격  CPU는 한 clock 당 한 instruction이 걸리지만, Main memory는 10 clock 당 한 instruction이 걸린다. 그래서 그 중간의 완충으로 cache memory를 둔다.   당장 필요한 정보를 저장 구성: 휘발성 저장장치로 구성되어, 전원이 나가면 그 내용이 사라진다.  최상위 CPU 내부에 존재하는 register부터 cache memory, main memory 등 regsiter: CPU 내부에 존재하는 작은 저장 장소 cache memory: CPU 내부에 있는 메모리로써, CPU와 main memory 간 속도 차이를 줄이기 위해 사용     Secondary  많은 용량, 느린 속도, 저렴한 가격 당장 필요하지 않은 정보 구성: 비휘발성 저장장치로 구성되어, 전원이 나가도 지워지지 않는다.   Caching: copying information into faster storage system  상대적으로 용량이 적은 빠른 저장장치를 이용해 느린 저장장치의 성능을 향상시키는 총체적인 기법 상대적으로 ‘느린 저장장치’ 에 있는 내용 중 당장 필요한 것만 ‘빠른 저장장치’ 에 선별적으로 복사 저장 하여 두 저장장치의 속도를 완충시킨다. 프로그램을 구성하는 모든 부분이 균일하게 사용되는 게 아니라, 일부분만 집중적으로 사용되기 때문에 적은 용량으로도 효과를 거둔다.    9. 하드웨어의 보안  하드웨어의 보안이 필요한 이유??  OS는 multi-programming 환경에서 동작하기 때문에, 프로그램 간에 충돌이나, 다른 프로그램의 실행을 방해할 수 있기 때문.   Solution: 보조 장치 Mode bit 사용  Mode bit 을 통해 하드웨어적으로 두 가지 모드의 operation 지원 Mode bit == 0: kernel mode  운영체제가 CPU를 수행하는 mode 모든 종류의 명령 실행 가능 보안을 해칠 수 있는 중요 명령어는 특권명령 으로 규정 모든 I/O 명령은 특권명령이므로, kernel mode에서 실행 interrupt가 들어오면 mode bit는 0으로 setting   Mode bit == 1: user mode  사용자 프로그램이 CPU를 수행하는 mode 자신의 메모리 영역 주소만 보고 수행하여, 모든 기계어 실행을 막는다. 사용자가 무한 루프로 CPU를 사용할 경우에도 timer가 있기 때문에 CPU 독점 사용 방지가능 운영체제가 CPU 제어권을 사용자 프로그램에게 넘길 때 mode bit를 1로 세팅하여 넘긴다.     전환 mechanism  CPU는 보안 관련 명령을 수행하기 전에는 항상 mode bit가 0인지 확인한다. 입출력 명령도 보안 관련 명령이므로, 사용자 프로그램이 입출력을 직접 할 수 없고, 운영체제가 한다. 그래서, 사용자 프로그램이 입출력을 하고 싶으면 sw interrupt인 system call을 CPU에 걸어서 운영체제가 CPU를 할당 받고, interrupt vector가 가리키는 위치를 통해 interrupt service routine으로 이동한다. sw interrupt를 거는 순간 mode bit 는 1에서 0으로 세팅되어 입출력 명령을 수행할 수 있다.     10. 메모리 보안  메모리 보안이 필요한 이유??  메모리에 여러 프로그램들이 동시에 올라와 실행되기 때문에, 한 사용자 프로그램이 다른 사용자 프로그램이나 운영체제가 위치한 메모리 영역을 침범할 수 있기 때문이다. 그래서 프로세스가 합법적인 메모리 범위에 있는지 체크하는 방법을 사용한다.   Solution: 기준 레지스터(base register) + 한계 레지스터(limit register)  기준 레지스터(base register)  어떤 프로그램이 수행하는 동안 그 프로그램이 합법적으로 접근할 수 있는 메모리 상의 가장 작은 주소를 보관한다.   한계 레지스터(limit register)  프로그램이 기준 레지스터값부터 접근할 수 있는 메모리의 범위를 보관     이 Solution을 어떻게 사용하는가???  사용자 프로그램이 base register + limit register 값을 벗어나는 주소에 접근하면 불법적인 메모리 접근이므로, SW interrupt인 exception을 발생시킨다. 그래서 CPU의 제어권을 해당 프로그램으로부터 운영체제로 이양시키고, 예외상황을 발생시킨 프로그램을 강제로 종료시킨다.   메모리 보안에서 특권명령  기준 레지스터와 한계 레지스터의 값을 세팅하는 연산은 특권명령으로 규정. 메모리 접근 연산은 사용자 프로그램이 CPU를 가지고 있는 동안 수행되므로 특권명령이 아니다.   kernel mode와 user mode의 메모리 접근 차이  kernel mode: 메모리에 무제한 접근 가능 user mode: base register와 limit register를 사용해서 메모리를 보호     11. CPU 보호  CPU의 독점 사용을 방지하기 위해 Timer(타이머) 라는 하드웨어를 사용한다.  사용자 프로그램이 CPU를 보유하고 있다가 정해진 시간이 흐른 뒤, 운영체제에게 제어권이 넘어가도록 interrupt를 발생시키는 하드웨어 매 clock tick 때마다 1씩 감소하다가, 0이 되면 interrupt가 발생한다.   timer의 값을 setting하는 명령을 load timer 라 하며, 특권 명령 이다. timer는 시분할 시스템을 구현하기 위해서도 사용된다.   12. 시스템 콜을 이용한 입출력 수행  모든 입출력(I/O) 명령은 특권 명령(kernel 영역)에 해당한다. 그러면 사용자 프로그램은 어떻게 I/O를 하는가??  system call이라는 SW interrupt를 통하여 운영체제에게 I/O 서비스 대행 요청을 한다. 그러면 제어권이 사용자 프로그램에서 운영체제로 넘어간다. 그리고, 운영체제는 인터럽트 처리 루틴을 실행한다. 입출력 완료 시, 제어권을 사용자 프로그램에게 넘긴다.     Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_03_%EC%BB%B4%ED%93%A8%ED%84%B0%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC_2/","summary":"입출력 구조, DMA, 저장장치의 구조 그리고 계층구조에 대해 알아본다. 또한, 하드웨어, 메모리, CPU의 각 보안 방법에 대해 알아본다.","title":"[TIL] OS Chapter 03: 컴퓨터 시스템의 동작원리 2"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리 -반효경 지음- 와 kocw 이화여자대학교 운영체제 - 반효경 교수 -를 보고 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 컴퓨터 시스템의 구조 1.1 컴퓨터의 구조: 내부장치와 외부장치  컴퓨터 시스템의 구조 = 컴퓨터 내부장치 + 컴퓨터 외부장치  컴퓨터 내부장치 : CPU, Memory 컴퓨터 외부장치 : Disk, keyboard, mouse, monitor, network device 등    1.2 컴퓨터의 업무 처리 방식  컴퓨터 외부장치에서 내부장치로 데이터를 읽어와 각종 연산을 수행한 후, 연산 결과를 외부장치로 다시 내보내는 방식으로 업무를 처리한다. 이때, 업무의 각 부분을 다음과 같이 정의한다.  입력(input): 컴퓨터 내부로 데이터가 들어오는 것 출력(output): 컴퓨터 외부장치로 데이터가 나가는 것  입출력(Input-output: I/O): 컴퓨터 시스템이 컴퓨터 외부 입출력 장치들과 데이터를 주고 받는 것   예시)  키보드로부터 입력을 받아 컴퓨터가 연산을 한 후, 그 결과를 모니터에 출력 컴퓨터 외부장치인 디스크에서 내용을 읽어 컴퓨터 내부에 연산을 한 후, 디스크에 데이터를 저장.      1.3 Controller: 각 하드웨어 장치의 작은 CPU  컴퓨터 전체에 CPU(Cetnral Processing Unit)라는 중앙처리장치가 있듯이, 컴퓨터의 각 하드웨어 장치에는 이들을 제어하는 일종의 작은 CPU인 컨트롤러 가 있다. 예)  메모리를 제어하는 컨트롤러는 메모리 컨트롤러 디스크를 제어하는 컨트롤러는 디스크 컨트롤러     2. CPU 연산과 I/O 연산 2.1 연산 = CPU가 무언가를 한다  컴퓨터에서 연산을 한다 = CPU가 무언가 일을 한다 컴퓨터의 구성장치 관점에서 연산을 나눠 보자면 다음과 같이 담당한다.  입출력 장치들의 I/O 연산 → 입출력 컨트롤러가 담당 컴퓨터 내에서 수행되는 연산 → main CPU 이 때 입출력 장치와 main CPU는 일이 다른 곳에서 발생하므로 동시 수행이 가능하다.    2.2 Local Buffer(로컬 버퍼)  각 장치 컨트롤러는 장치로부터 오고 나가는 데이터를 임시 저장 하기 위한 작은 메모리인 로컬 버퍼(local buffer) 가 존재한다. 입력 장치로부터 데이터를 읽어오는 경우, 각 입력장치의 컨트롤러가 장치에서 로컬버퍼로 데이터를 읽어와서 저장 후, 컴퓨터 내부의 메모리에 전달한다.  2.3 CPU와 I/O 장치의 연산과정  프로그램에서 데이터를 읽어오라는 명령을 내린다 → 각 장치의 컨트롤러가 장치로부터 내용을 읽어 로컬버퍼에 저장한다 → 데이터를 읽는 작업을 완료했기 때문에, 메인 CPU에서 I/O 작업을 요청한 프로그램의 다음 일을 수행할 수 있다. HW 또는 SW는 CPU 옆에 인터룹트 라인(interrup line) 을 세팅하는 명령을 실행하여, 컨트롤러가 인터룹트(interrupt) 를 발생시켜 메인 CPU에게 I/O작업이 완료됨을 알린다 →   인터럽트란 컨트롤러들이 CPU의 서비스가 필요할 때 이를 통보하는 방법  CPU는 명령 하나를 수행할 때마다 인터룹트가 발생했는지 확인하는데, 인터럽트가 발생하면 자신이 하던 일을 멈추고, 인터럽트 처리를 먼저 한 후 멈춘 명령을 다시 수행한다.   3. 인터럽트의 일반적 기능 3.1 Interrupt(인터럽트)란??   인터럽트(Interrupt)란 CPU의 제어권을 양도하라는 신호\n  사용자 프로그램에게 CPU 제어권이 있어서, CPU를 사용하고 있다가 interrupt를 발생시키면 kernel에게 CPU가 이양된다.\n  오늘날 운영체제가 CPU를 점유하는 건 인터럽트에 의하지 않고는 발생하지 않는다.\n 운영체제는 단지 인터럽트가 발생할 때에만 CPU의 제어권을 획득할 수 있는데, 인터럽트가 발생하지 않으면 사용자 프로그램이 계속 CPU를 점유한다.    3.2 인터럽트 처리루틴이란???  인터럽트를 당한 시점의 레지스터와 program counter를 저장한 후, CPU 제어를 인터럽트 처리 루틴에 넘긴다. 인터럽트 처리루틴(Interrupt Service Routine) 이란?  해당 인터럽트를 처리하는 커널 함수 인터럽트 핸들러(interrupt handler) 라고도 한다. 다양한 controller가 있는 만큼 interrupt의 종류도 다양하다. 그러므로 인터럽트 처리루틴의 종류도 다양하다.   인터럽트 벡터(interrupt vector)  해당 인터럽트의 처리 루틴 주소를 가리킨다.   인터럽트 처리루틴까지의 과정  컨트롤러가 인터럽트를 발생시키면 CPU는 인터럽트 라인을 통해 인터럽트 발생을 확인하고, 자신이 하던 일을 멈춘다.\n-\u0026gt; 프로그램의 실행 상태를 PCB에 저장한 후, CPU의 제어권은 프로세스에서 운영체제로 넘어간다.\n-\u0026gt; 그리고, 운영체제는 interrupt vector가 가리키는 곳으로 가서 인터럽트 처리루틴을 찾는다.\n-\u0026gt; 인터럽트 처리루틴을 통해 해당하는 인터럽트 처리를 완료하고 나면, CPU는 PCB로부터 CPU 상에 복원하여 인터럽트 당하기 직전의 위치부터 계속 수행.    3.3 Interrupt line  특정 프로그램이 CPU를 독점하는 걸 방지하기 위해서 timer 라는 HW를 사용하여, timer의 시간이 다 되면 interrupt line 을 통해 interrupt를 건다. 또한, controller가 I/O 작업을 완료하면 interrupt line을 통해 interrupt를 건다.  3.4 인터럽트의 종류: HW interrupt 와 SW interrupt  Interrupt = HW interrupt + SW interrupt HW interrupt  HW가 발생시킨 인터럽트 HW 일꾼들이 CPU와 정보 교신을 위해서 거는 것 하드웨어 장치가 CPU의 interrupt line을 세팅한다. 통상적으로 불리는 interrupt의 의미가 HW interrupt다.   SW interrupt (= 트랩(trap))  사용자 프로그램이 운영체제에게 대행해달라고 요청하는 것 소프트웨어가 CPU의 interrupt line을 세팅한다. Trap의 종류: 예외 상황(exception) 과 시스템 콜(system call)   HW interrupt와 SW interrupt의 공통점  CPU 옆 인터럽트 라인에 신호를 보내 인터럽트 발생유무를 알리는 방식은 동일하다.    3.5 Trap: exception 과 system call 3.5.1 예외 상황(exception)  비정상적인 작업 또는, 권한이 없는 작업을 시도할 때, 이에 대한 처리를 위해 발생시키는 인터럽트\n  비정상적인 작업의 예: 사용자 프로그램이 0으로 나누는 연산을 실행 권한이 없는 작업의 예: 사용자 프로그램이 자신의 메모리 영역 바깥에 접근하려는 시도  3.5.2 시스템 콜(system call)  사용자 프로그램이 운영체제 내부에 정의된 코드를 실행할 때, 운영체제에게 서비스를 요청하는 방법\n  사용자 프로그램의 코드는 사용자 프로그램이 CPU에 대한 제어권을 가지고 실행한다. 하지만, 커널 내부에 있는 코드를 사용자 프로그램이 실행하고자 할 때는 사용자 프로그램이 직접 접근할 수 있는 게 아니라, system call을 통해서 대행 요청 을 한다. system call 요청을 interrupt line 을 통해 CPU 제어권을 운영체제로 넘겨 커널 내부 코드를 실행한다.   4. 인터럽트 핸들링(Interrupt handling) 4.1 Interrupt handling 이란??  인터럽트가 발생한 경우에 처리해야할 일의 절차\n   프로그램 A가 실행되고 있을 때, 인터럽트가 발생하면 프로그램 A의 현재 상태를 먼저 저장 한다.\n 현재 상태란? 현재 CPU에서 실행 중인 명령의 메모리 주소를 포함해 몇 가지 부가적인 정보들을 의미한다.    현재 상태를 먼저 저장하는 이유는??\n CPU에서 명령이 실행될 때 CPU 내부에 있는 임시 기억장치인 레지스터(register)에 데이터를 읽거나 쓰면서 작업을 한다. 그런데, 인터럽트가 발생해 새로운 명령을 실행하면 기존의 레지스터 값들이 지워지므로 , CPU 내의 이러한 상태를 저장해둬야 한다.    4.2 PCB(Process Control Block)이란??  OS가 현재 시스템 내에서 실행되는 프로그램들을 관리하기 위해 둔 자료구조로 PCB(Process Control Block, 프로세스 제어 블록)라 한다.\n  PCB 는  각각의 프로그램마다 하나씩 존재 한다. 해당 프로그램의 어느 부분이 실행 중이었는지를 저장 한다.  ex) 코드의 메모리 주소, 레지스터값, 하드웨어 상태 등     PCB 사용절차  Interrupt 발생 → CPU의 제어권을 넘기기 전에 프로그램의 실행 상태를 PCB에 저장 → CPU의 제어권이 OS로 넘어간다 → 운영체제는 인터럽트 벡터가 가리키는 곳으로 가서 인터럽트 처리루틴에 따라 인터럽트 처리를 수행→ 인터럽트 처리 완료 → 저장된 상태를 PCB로부터 CPU 상에 복원 → 인터럽트 당하기 직전 위치부터 재실행     Reference  운영체제와 정보기술의 원리 kocw 이화여자대학교 운영체제 - 반효경 교수 -  ","permalink":"http://jeha00.github.io/post/os/os_chapter_03_%EC%BB%B4%ED%93%A8%ED%84%B0%EC%8B%9C%EC%8A%A4%ED%85%9C%EC%9D%98%EB%8F%99%EC%9E%91%EC%9B%90%EB%A6%AC_1/","summary":"I/O 연산이 무엇이고, controller와 local buffer가 무엇이고, 입출력 연산이 Interrupt를 중심으로 어떻게 진행되는지를 알아본다.","title":"[TIL] OS Chapter 03: 컴퓨터 시스템의 동작원리 1"},{"content":"0. Introduction  해당 내용은 운영체제와 정보기술의 원리을 보고 혼자 정리한 내용입니다. 정확하지 않은 내용이 있다면 말씀해주시면 감사하겠습니다.   1. 운영체제의 정의 운영체제란?   운영체제(operating system) 란??\n컴퓨터 하드웨어의 바로 윗단에 설치되는 소프트웨어로, 사용자 및 다른 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층이다.\n  왜 system이라 하는가??? system은 흔히들 하드웨어를 지칭할 때 주로 사용되는 단어인데, 이 system을 사용한 이유는 운영체제 없이 하드웨어만 있다면 컴퓨터 역할을 할 수 없고, OS와 하드웨어가 같이 있어야 진정한 컴퓨터이기 때문이다.\nkernel이란?? 소프트웨어가 실행되기 위해서는 메모리에 그 프로그램이 올라가야 한다. 운영체제도 하나의 SW이기 때문에, 컴퓨터 하드웨어의 전원이 켜지는 동시에, 메모리에 올라간다. 이 운영체제 SW는 규모가 큰 프로그램이기 때문에, 운영체제 전부를 메모리에 올린다면 메모리 공간 낭비가 심해진다.\n그래서 운영체제 중 항상 필요한 부분만 을 전원이 켜짐과 동시에 메모리에 올려놓고, 그렇지 않은 부분은 필요할 때 메모리로 올려서 사용한다. 메모리에 항상 상주하는 운영체제 부분 을 커널(kernel) 이라 한다. 이 커널을 좁은 의미의 운영체제 라고도 불리며, 넓은 의미의 운영체제 는 utility들(ex: copy)을 광범위하게 포함하는 개념이다.\n 2. 운영체제의 기능 하드웨어 그리고 사용자를 위한 운영체제의 역할 운영체제는 사용자 및 다른 소프트웨어와 하드웨어를 연결하는 소프트웨어 계층이라는 관점에서 운영체제의 기능을 생각해보면, 하드웨어를 위한 역할 과 사용자를 위한 역할 로 나눠진다.\n전자 는 사용자를 대신하여 운영체제가 하드웨어인 컴퓨터 시스템 내의 resource를 효율적으로 관리하는 역할 을 말한다.\n후자 는 사용자가 컴퓨터 시스템을 편리하게 사용하도록, 사용자에게 편리한 인터페이스를 제공하는 역할 을 말한다. 하드웨어를 직접 다루는 부분은 운영체제가 대행하여, 사용자 및 프로그램이 이에 대한 내용은 알지 못해도 프로그램을 실행해주는 기능을 말한다.\n❗운영체제의 핵심 역할: 효율적, 균형있게, 안전하게 자원 관리하기 운영체제의 기능은 전자와 후자 중 중요한 핵심기능은 바로 전자 다.\n그래서 운영체제를 자원 관리자(resource manager) 라고도 부른다. 여기서 자원이란 하드웨어 자원(ex: CPU, memory, HDD) 과 소프트웨어 자원을 모두 총칭하는 말이다. 운영체제는 이 자원들을 효율적으로 관리 하여 가장 좋은 성능 을 내도록 만든다.\n하지만, 전체적인 성능을 향상시켜려다보면 일부 프로그램 또는 사용자가 불이익을 당할 수 있다. 그래서 운영체제는 사용자 및 프로그램들 간에 자원이 형평성 있게 분배 되도록 하는 균형자 역할도 함께 수행해야 한다.\n또한, 더 중요한게 사용자와 운영체제 자신을 보호하는 보안 역할을 담당한다. 악의성 프로그램으로 다른 사용자 프로그램에 접근하지 않도록 보안 및 보호 기능을 수행해야 한다.\n 3. 운영체제의 분류 운영체제의 분류 중 하나는 multi-processing system 과 single-processing system 이다. CPU가 2개 이상 설치되면 전자, 1개만 설치되면 후자를 말한다. 여기서 분류는 후자를 가정으로 진행된다.\n운영체제의 분류에는 동시 작업을 지원하는지, 다중 사용자를 지원하는지, 실시간(real time)을 지원하는지에 따라 분류된다. 앞에서부터 차근 차근 알아보자.\n첫 번째 분류: 동시 작업의 지원 유무 동시 작업을 지원하는지의 여부에 따라 단일작업(single tasking)용 운영체제와 다중작업(multi tasking)용 운영체제로 나누어볼 수 있다. 각 설명은 다음 표와 같다.\n   운영체제 분류 동시 작업 지원 유무 예시     single tasking X (한 번에 하나) 초창기 운영체제, DOS   multi-tasking O (동시에 창 여러개) MS window, Unix    Multi-tasking: 시분할, 다중 프로그래밍, 대화형 system 다중 작업 시에는 여러 프로그램이 CPU와 memory를 공유한다.\nCPU의 경우, 처리 속도가 워낙 빨라서 여러 프로그램이 CPU의 작업시간을 조금씩 나누어 번갈아 쓰지만, 사용자 입장에서는 동시 실행처럼 보인다. 이를 시분할 시스템(time sharing system) 이라 한다.\n또한, 메모리의 경우 메모리 공간을 분할해 여러 프로그램들을 동시에 메모리에 올려놓고 처리하는 시스템을 사용한다. 이를 다중 프로그래밍 시스템(multi-programming system) 이라 한다.\n다중 작업의 경우, 여러 프로그램을 같이 실행하지만, 사용자 개개인의 관점에서는 각 프로그램에 대한 입력 결과를 곧바로 화면에 보여준다. 이를 대화형 시스템(interactive system) 이라 한다. 여러 사용자가 동시 접속 하는 서버의 경우에도, 각 사용자 입장에서는 혼자 사용하는 것처럼 느끼게 해주므로 대화형 시스템에 해당된다.\n두 번째 분류: 다중 사용자 동시지원 유무    운영체제 분류 다중 사용자 지원 추가 설명 예시     단일 사용자용 X 한 번에 한 사용자만 DOS, MS window   다중 사용자용 O 여러 사용자 동시 접속 가능 server(서버)    세 번째 분류: 작업 처리 방식(일괄처리 와 시분할 방식)    작업 처리 방식 의미 추가 설명 예     일괄 처리 (batch processing) 일정량씩 모아 한꺼번에 처리하는 방식 응답 시간이 길다. 초창기 컴퓨터에 사용하는 punch card   시분할 방식 (time sharing system) 여러 작업을 수행 시, 일정 시간 단위로 분할해 CPU를 사용하는 방식 짧은 응답시간을 갖는다. 유닉스 운영체제 하의 서버 컴퓨터    다섯 번째 분류: 실시간(real time) 운영체제 real time system은 정해진 시간 안에 처리를 보장하는 시스템에서 사용된다.\n   분류 설명 예     Hard realtime system 주어진 시간을 지키지 못할 경우, 매우 위험한 결과를 초래할 가능성 O 원자로, 공장 제어 시스템, 미사일 제어 시스템   Soft realtime system 데이터가 정해진 시간 단위로 되어야 올바른 기능을 수행할 수 있는 시스템. 위험한 결과 X 멀티 미디어 스트링     4. 운영체제의 예 MS Window와 Unix의 예를 통해 간단히 살펴보자.\nMS Window는 마이크로소프트에서 이전에 개발한 MS-DOS와 WINDOW 3.1을 발전시킨, 개인용 컴퓨터를 위한 운영체제다.\n마이크로소프트가 기존에 발표한 MS-DOS는 초보자가 사용하기 어려운 명령어 입력 방식을 지녔기 때문에, 좀 더 쉬운 사용을 위해 윈도우를 개발했다.\n그리고, WINDOW 3.1은 grapic interface와 mouse 기능을 지원하는 점에서 사용자에게 편리한 환경을 제공했지만, 독자적인 운영체제가 되지 못하고 MS-DOS 위에 수행된다는 점에서 여러 한계점을 가지고 있었다. 예를 들어 컴퓨터 시스템을 완전히 제어할 수 없는 것, 불안정하다는 것 그리고, WINDOW를 사용하면서도 DOS를 함께 사용해야 하는 부가적인 어려움이 있었다.\n그 이후 온전한 운영체제가 된 것이 윈도우 95다. 윈도우 XP부터는 인터페이스측면에서 그래픽 환경과 아이콘 방식을 기본적으로 채택하면서, 다양한 방식으로 지원해 자신에게 편한 방법으로 다룰 수 있게 했다.\nMS Window의 또 다른 큰 특징은 plug and play다. 시스템에 새로운 하드웨어를 장착하면 OS가 자동으로 감지하여, 새로운 하드웨어에 맞게 설정된다는 점이다.\n그러면 MS Window와 Unix를 비교해보겠다.\n이식성(protability) 이란?\n해당 소프트웨어를 다른 기종의 기계로 옮기는 것이 얼마나 용이한가를 나타내는 지표\n    MS Window Unix     대상 누구든지 손쉽게 사용(개인용 컴퓨터) 프로그램 개발 환경을 위해 설계된 OS, 오랜 전통, 대형 컴퓨터,전문적인 목적   특징 1 편리한 인터페이스 이식성(protability)이 좋음   특징 2 안정성 낮음 안정성이 좋음   특징 3  kernel의 크기가 작음   특징 4  souce code 공개됨 → 실제 연구에 이바지   특징 5  스스로 꾸밀 수 있음   특징 6  후에 GUI 제공됨     5. 운영체제의 자원 관리 기능 자원이란 하드웨어 자원과 소프트웨어 자원을 포함한다고 했다. 이번 소단원에서는 하드웨어 자원을 어떻게 관리하는지 알아보자.\n하드웨어 자원에는 CPU, 메모리, 그리고 입출력 장치들로 구성된다.\n5.1 CPU 관리 기법: 3가지 CPU 란 Central Processing Unit의 약자로, 명령어를 실행하는 연산 장치를 말한다. 이 CPU 는 통상적으로 컴퓨터 한 대에 하나가 장착되기 때문에, 여러 프로세스들이 CPU를 효율적으로 나누어 사용할 수 있도록 관리되어야 한다. 이 CPU의 대표적인 관리 방법 에는 선입선출(First Come First Served: FCFS), 라운드 로빈(Round Robin), 우선순위(Priority) 기법이 있다.\n5.1.1 CPU 관리 기법 첫 번째: 선입선출(FCFS) CPU를 사용하기 위해 먼저 온 process를 먼저 처리하는 방식이 선입선출 이다. 일상생활에서 줄을 서서 기다리는 것과 동일하다. 이 방법의 단점은 CPU를 필요로 하는 process가 여러 개 있을 때, CPU를 먼저 얻은 process가 원하는 작업을 완료할 때까지 다른 프로세스들은 CPU를 사용하지 못한다는 점이다. CPU 자체의 효율적인 측면에서는 문제 없지만, 전체 시스템의 관점에서는 비효율적인 결과를 초래할 수 있다. 장시간 이용해야 하는 프로세스가 먼저 오고, 그 뒤에 단시간 이용해야하는 프로세스가 올 경우 단시간 이용하면 되지만, 먼저 온 프로세스로 인해 계속 대기해야하는 상황이 발생된다.\n5.1.2 CPU 관리 기법 두 번째: 라운드 로빈(Round Robin) 위 선입선출의 단점을 보완하여 나온 방법이 라운드 로빈(Round Robin) 이다. 이 방법은 CPU를 한 번 할당 받아 사용할 수 있는 시간을 일정하게 고정된 시간으로 제한 한다. 각 프로세스는 이 정해진 시간 동안에만 CPU를 할당받는다. 작업이 완료되지 않았어도, 시간이 끝나면 CPU를 내려놓고, CPU 대기열의 제일 뒤에 가서 줄을 서야 한다. 먼저 온 프로세스의 작업 완료 시간이 길어도, 계속해서 기다릴 문제가 발생되지 않는다. 각 process마다 이 정해진 시간만큼 보장받을 수 있다.\n5.1.3 CPU 관리 기법 세 번째: 우선순위(Priority) 대기 중인 프로세스들에게 우선순위를 부여하고, 우선순위가 높은 process들에게 먼저 CPU를 할당 한다. 먼저 와서 CPU를 기다릴지라도, 우선순위에 따라 융통성 있게 process들에게 CPU를 할당할 수 있다. 또한, 지나치게 오래 기다리는 프로세스가 발생하지 않도록, 기다리는 시간에 비례하여 우선순위를 점차 높여주는 방안도 활용된다.\n5.2 Memory란?? 다른 중요 관리 대상으로 Memory가 있다.\n메모리는 CPU가 직접 접근할 수 있는 컴퓨터 내부 기억장치다. 프로그램이 CPU에서 실행될라면 해당 부분이 메모리에 올라 있어야 한다.\n메모리 역시 CPU처럼 한정된 용량만 존재하기 때문에, 서로 다른 다수의 프로세스들이 나누어 쓸 수 있도록 해야 한다. 이 한정된 용량을 효율적인 관리하기 위해 운영체제는 메모리의 어느 부분이 어떤 프로그램에 의해 사용되고 있는지를 주소(address) 를 통해 관리한다.\n5.2.1 운영체제가 Memory 관리가 필요한 이유 프로세스와 메모리의 관계는 다음과 같다.\n추가적으로 할당하여 프로세스가 빨리 수행될 수 있지만, 메모리 자원을 낭비하는 경우도 발생한다. 운영체제는 프로그램에 메모리가 필요할 때 할당하고, 필요하지 않으면 메모리를 회수한다.\n따라서 운영체제는 전체 메모리 공간이 효율적으로 사용될 수 있도록 잘 판단해야 한다.\n또한, 각 프로세스가 자신의 메모리 영역에만 접근할 수 있도록 보안 관리를 잘 해야 한다.\n5.2.2 Memory 관리 방식 3가지 memory 관리 방식에는 고정 분할(fixed partition) 방식, 가변 분할(variable partition) 방식, 가상 메모리(virtual memory) 방식이 있다. 각 방식에 대해 알아보자.\nMemory 관리 방식 첫 번째: 고정 분할 방식 고정 분할 방식은 명칭 그대로 물리적 메모리를 미리 고정된 크기로 나누어 관리한다. 여기에는 몇 가지 단점이 있다.\n첫 번째, 프로그램 크기에 맞게 융통성 있게 할당할 수가 없다\n두 번째, 고정된 크기이기 때문에 최대 할당할 수 있는 프로그램의 수가 정해져 있다.\n세 번째, 나눠진 메모리 크기보다 큰 프로그램은 적재가 불가능 하다.\n네 번째, 나눠진 크기보다 작은 프로그램에 할당하면 분할 내에 남는 영역 이 발생한다. 이 영역을 내부 조각(internal fragmentation) 이라 한다. 이 영역은 올라온 프로그램에 의해서도 사용될 수 없고, 다른 프로그램에 할당할 수 없어서 비효율적으로 낭비되는 공간 이다.\nMemory 관리 방식 두 번째: 가변 분할 방식 가변 분할 방식은 매 시점 프로그램의 크기에 맞게 메모리를 분할해서 사용하는 방식이다.\n이 방식 또한 전체 물리적 메모리 크기보다 큰 프로그램에는 여전히 할당할 수 없다. 그리고, 고정 분할 방식의 내부 조각은 발생되지 않지만, 외부 조각(external fragmentation) 이 발생할 수 있다.\n외부조각이란 프로그램에 할당되지는 않았지만, 그 크기가 작아 프로그램을 올리지 못하는 메모리 영역을 말한다.\n그래서 비효율적으로 낭비되는 공간이다.\nMemory 관리 방식 세 번째: 가상 메모리(Virtual Memory) 기법 현대 컴퓨터 환경에서 가장 널리 사용되는 메모리 관리 기법이다. 이 기법에서 실행될 수 있는 프로그램의 크기는 물리적 메모리가 아닌 가상 메모리 크기에 의해 결정된다. 그래서 물리적 메모리보다 큰 프로그램도 지원할 수 있다.\n모든 프로그램은 물리적 메모리와 독립적으로 가상 메모리를 가지고 있다. 운영체제는 이 가상 메모리의 주소를 물리적 메모리의 주소로 mapping(전환, 연결)하는 기술을 사용하여 전환 후, 물리적 메모리에 올린다.\n예를 들어보자.\n가상 메모리 기법을 사용하여 현재 물리적 메모리보다 더 큰 메모리를 요구하는 프로그램을 실행한다고 하자. 각 프로그램은 전체가 동시에 사용되는 게 아니다. 그러므로 사용되고 있는 부분만 물리적 메모리에 올리고, 나머지는 보조기억장치(disk)에 저장해두었다가 필요할 때 적재하는 방식으로 큰 프로그램을 사용할 수 있다. 이 때, 사용되는 보조기억장치의 영역을 스왑 영역(swap area) 라고 부른다. 프로그램을 구성하는 가상 메모리 공간은 페이징(paging) 기법을 사용하여 저장된다.\n5.3 입출력 장치 관리 기법 이 CPU와 메모리는 휘발성으로 전원이 꺼지면 처리 중이던 정보가 모두 지워지기 때문에, 비휘발성인 보조기억장치 에 파일 형태로 저장한다.\n이 보조기억장치의 예로는 하드디스크가 있으며, 그 외에는 키보드, 마우스, 모니터 등이 입출력 장치 로 OS 관리 대상에 포함된다.\n입출력 장치 관리는 인터룹트(interrupt) 를 통해 이뤄진다.\nInterrupt mechanism CPU는 CPU scheduling에 따라 주어진 작업을 수행하다가, 주변 입출력 장치로의 controller가 CPU에게 인터룹트를 발생시키면 CPU는 자신이 하던 작업을 중단한다. 그리고 현재 자신이 하던 작업 상태를 저장한다. 왜냐하면 다시 중단된 작업을 나중에 이어서 해야하기 때문이다.\nController란 입출력 장치가 가지고 있는 sub CPU라 생각하자.\n이 인터룹트가 발생된 순간, CPU의 사용권은 프로그램에서 운영체제로 넘어온다. 그러면, 운영체제는 발생된 인터룹트의 종류에 맞는 인터룹트 처리루틴을 kernel에서 찾아서 처리루틴에 기록된 코드에 따라 일을 처리한다. 그 후, 다시 중단되 업무에 CPU는 복귀한다.\n Reference  운영체제와 정보기술의 원리  ","permalink":"http://jeha00.github.io/post/os/os_chapter_02_%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C_%EA%B0%9C%EC%9A%94/","summary":"운영체제란 무엇이고, 무슨 역할을 하는지, 어떻게 분류되는지, 그리고 CPU, 메모리, 입출력 장치의 대략적인 관리 mechanism에 대해 알아본다.","title":"[TIL] OS Chapter 02: Introduction to Operating System"},{"content":"Dev-contents를 만든 목적과 이유는???  개발 관련 좋은 컨텐츠를 보관하고 섭취하기\n   컨텐츠의 종류는 한정되어 있지 않습니다.\n 유익한 개발 관련 컨텐츠를, 주제별로 나눠서 각 주제별로 앞으로 볼 것, 다 본 것들, 현재 보고 있는 것으로 나누고 어느 부분을 중점적으로 공부했는지 직관적으로 알 수 있기 때문입니다.    구매했던 업무와 일상을 정리하는 새로운 방법 Notion을 보고 notion으로 정리 후, 블로그에 업데이트했습니다.\n  정리수단으로 notion을 결정한 이유는 다음과 같습니다.\n block을 이동하기가 쉽습니다. 여러 단락으로 나눠서 사용할 수 있습니다. toggle button이 있어 훨씬 깔끔합니다. 이미지 첨부나, table 등등 만들기가 용이합니다. 나중에 협업 도구로 notion을 사용해볼 생각이라, 미리 익히고 싶었습니다. 디자인이 제 취향에 맞았습니다.    notion에 정리한 후, Github blog에 주기적으로 업로드할 예정입니다.\n 업데이트 날짜 또한 표시합니다.    📚은 서적을, 💻은 인터넷 강의를, 🖊️ 은 블로그 포스팅 글을 말합니다.\n  Doing과 Done의 경우, 위에 있을 수록 최신의 것을 말합니다.\n   OS   Will\n  Doing\n  Done\n 📚 운영체제와 정보기술의 원리 - 반효경 지음 - 💻 KOCW 운영체제 이화여자대학교 - 반효경 -     Network   Will\n 💻 KOCW 컴퓨터 네트워크 한양대학교 - 이석복 -    Doing\n 📚 성공과 실패를 결정하는 1%의 네트워크 원리    Done\n 💻 모든 개발자를 위한 HTTP 웹 기본 지식     DB  Will Doing  💻 갖고노는 MySQL 데이터베이스 by 얄코 💻 관계형 데이터 모델링 - 생활코딩   Done   Algorithum   Will\n 📚 알고리즘 문제해결전략 1,2 세트    Doing\n 📚 자료구조와 함께 배우는 알고리즘 입문 파이썬편    Done\n   Python   Will\n 💻 level 4 고수가 되는 파이썬: 동시성과 병렬성 문법 배우기 Feat. 멀티스레딩 vs 멀티프로세싱 (Inflearn Original)    Doing\n  Done\n  💻 level 3 모두를 위한 파이썬 : 필수 문법 배우기 Feat. 오픈소스 패키지 배포 (Inflearn Original)\n  💻 level 2 우리를 위한 프로그래밍 : 파이썬 중급 (Inflearn Original)\n  💻 level 1 프로그래밍 시작하기 : 파이썬 입문 (Inflearn Original)\n  📚 Do it! 첫 코딩 with 파이썬\n     Django   Will\n  Doing\n 💻 파이썬/장고 웹서비스 개발 완벽 가이드 with 리액트    Done\n   Linux   Will\n  Doing\n 📚 실습과 그림으로 배우는 리눅스 구조 -    Done\n   Cloud   Will\n 📚 따라하며 배우는 AWS 네트워크 입문    Doing\n  Done\n   Docker  Will Doing Done   생산성 도구   Will\n 📚 Pro Git 2 edition    Doing\n  Done\n 📚 업무와 일상을 정리하는 새로운 방법 Notion     개발 문화 \u0026amp; 개발 life \u0026amp; 공부법   Will\n 🖊️ 개발자가 공부로 살아남는 방법 🖊️ 나는 어떻게 공부했는가? 🖊️ 개발자의 평생공부 🖊️ 프로그래머로서의 성장을 도왔던 태도들 🖊️ 프레임 공부를 멈춰라 🖊️ 회사 밖에서 성장하기 🖊️ 어려운 것을 쉽게 배우는 방법: 슈퍼 파워 장착을 위한 3단계 학습법 🖊️ 개발자는 어떻게 성장해야 할까 🖊️ 어려운 것을 쉽게 배우는 방법 🖊️ 내게 실용적이었던 프로그래밍 공부 방법들 🖊️ 더 나은 개발자가 되는 8가지 방법 🖊️ 개발 배우기가 정말 어려운 이유 🖊️ 개발자의 성장에 대한 이야기 (주니어, 기술, 팀, 이직, 자기 PR) 🖊️ 초보 웹 개발자를 위한 학습 안내서 🖊️ 개발자를 꿈꾸는 취업 준비생에게    Doing\n  Done\n 🖊️ 프로그래밍 학습 방법 🖊️ 학습에 실패한 이야기 🖊️ 개발자가 실력을 향상시킬 방법은 OO뿐이에요. 반복     기술 면접  Will Doing Done   비전공자 \u0026amp; 신입   Will\n 🖊️ 주니어 개발자를 위한 취업 정보 모음 🖊️ Technical Interview Guidelines for beginners 🖊️ 개발자 블로그 모음 🖊️ 개발자 회고 모음 🖊️ iOS 개발에 대한 질문과 답변 모음    Doing\n  Done\n 🖊️ 3 번째 직장에 오기까지 시리즈 🖊️ 체대 출신 개발자의 연말 회고 시리즈 🖊️ 문돌이가 개발자가 되기까지 시리즈 🖊️ 문과생의 카카오 개발자 이직기 시리즈 🖊️ 늦은 나이, 개발자로 시작해도 좋을까요 - 30대 초반 비전공자의 고민 🖊️ 문과생 비전공자가 웹 개발자가 되기까지.. 🖊️ 32살에 개발에 입문한 비전공자가 인프런 창업한 이야기 (슬라이드) 🖊️ 야 너두 할 수 있어. 비전공자, COBOL 개발자를 거쳐 네이버에서 FE 개발하게 된 이야기 (영상) 🖊️ 비전공자로 개발자 커리어를 시작하는 사람들에게 (영상) 🖊️ 비전공자가 개발자가 되기까지(feat. Wecode) 💻 비전공자를 위한 개발자 취업 올인원 가이드 [통합편] 📚 비전공자를 위한 이해할 수 있는 IT 지식 📚 코딩 진로: IT 진로를 고민하는 이들을 위한 지침서     ","permalink":"http://jeha00.github.io/post/dev-contents/dev-contents/","summary":"Updated on June 17   /  개발 관련 좋은 컨텐츠를 보관하고 섭취하기","title":"Dev-Contents"},{"content":"Intro  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.    이번 chapter에서는 지난 HTTP header [TIL] Network HTTP Header 1에 이어서 관련 header에 대해 집중적으로 알아본다.\n  HTTP header의 용도는 [TIL] Network HTTP basic을 참고한다.\n   1. 캐시 기본 동작 1.1 캐시가 없을 때  클라이언트가 GET 메소드를 사용하여 /star.jpg 를 조회요청을 서버에 보낸다. 서버는 이에 응답하여 HTTP 메세지를 생성하고, HTTP body에 data를 담는다. data의 크기는 다음 같이 가정한다.  HTTP header의 data 크기: 0.1 Megabye HTTP body의 data 크기: 1.0 Megabyte   서버의 응답에 클라이언트는 star.jpg를 받는다.   그러면 캐시가 없는 상황에서 서버에 동일한 요청을 또 보내면 어떻게 될까??   처음과 동일하게, 총 1.1M의 크기를 다운받는다.   캐시가 없기 때문에  데이터가 변경되지 않아도, 계속 네트워크를 통해서 데이터를 다운받아야 한다. 인터넷 네트워크는 비싸고 매우 느리다. 브라우저 로딩 속도가 느리다. 결국, 사용자는 느린 사용 경험을 겪는다.    1.2 캐시를 적용할 때  브라우저에 캐시 저장 공간을 사용한다. 클라이언트의 요청에 서버는 응답 메세지를 생성한다. 그리고, 클라이언트에게 응답 메세지를 보내면서 결과를 캐시에 저장한다.   클라이언트의 두 번째 요청 시, 클라이언트는 서버에 요청을 바로 보내지 않는다. 먼저, 브라우저 캐시에서 캐시 유효 시간을 먼저 검증한다. 유효 시간이 일치하면 캐시에서 조회하여 원하는 데이터를 사용한다.   캐시가 존재하기 때문에  캐시 가능 시간 동안 네트워크를 사용하지 않아도 된다. 비싼 네트워크 사용량을 줄일 수 있다. 브라우저 로딩 속도가 매우 빠르다. 사용자는 빠른 네트워크 경험을 할 수 있다.    1.3 캐시 시간 초과했을 때  캐시 유효 시간을 검증 요청한다.   서버에서 다시 전송한다.    응답 결과를 다시 캐시에 저장한다.\n  캐시 유효 시간이 초과하면, 서버를 통해 데이터를 다시 조회하고, 캐시를 갱신한다.\n  이때 다시 네트워크 다운로드가 발생한다.\n   2. 검증 헤더와 조건부 요청 1  검증 헤더: 캐시 데이터와 서버 데이터가 같은지 검증하는 데이터. ex) Last-Modified header\n조건부 요청 헤더: 검증 헤더로 조건에 따른 분기. ex) if-modified-since: header\n   캐시 유효 시간이 초과해서 서버에 다시 요청하면 다음 두 가지 상황이 나타난다.\n 서버에서 기존 데이터를 변경하거나, 변경하지 않는 상황    캐시 만료 후에도 서버에서 데이터를 변경하지 않은 상황으로 가정하자.\n 데이터를 전송하는 대신에 저장해 두었던 캐시를 재사용할 수 있다. 단, 클라이언트와 서버의 각 데이터가 같다는 사실을 확인할 수 있는 방법이 필요하다.     캐시 시간 초과로 서버에 재요청 시, if-modified-since: header를 메세지에 넣어 보낸다. 이 header가 조건부 요청 header다. 이 header는 캐시가 가지고 있는, 데이터 최종 수정일을 말한다.   서버에서 클라이언트가 보낸 요청과 서버의 해당 data의 데이터 최종 수정일을 비교.   동일할 경우, HTTP body를 전송하지 않고 HTTP header만 전송한다. 데이터가 수정되지 않았기 때문에, 304 Not Modified 상태이며, 검증헤더인 Last-Modified header를 추가한다.    그러면 응답 결과를 재사용하여, header data를 갱신한다.\n  정리\n 캐시 유효 시간이 초과해도, 서버의 데이터가 갱신되지 않으면  304 Not Modified + Header Meta data만 응답하면 된다. 여기서 Header Meta data란 검증헤더를 말한다. 이 때, HTTP Body는 없어도 된다. -\u0026gt; 클라이언트는 서버가 보낸 응답 헤더정보로 캐시의 메타 정보를 갱신한다. -\u0026gt; 클라이언트는 캐시에 저장되어 있는 데이터를 재활용한다. 결과적으로, 네트워크 다운로드가 발생하지만 용량이 적은 헤더 정보만 다운로드.      실제 웹 브라우저에서 다음 경로를 통해서 조건부 요청 헤더를 볼 수 있다.\n 검사(F12) -\u0026gt; Network tab 클릭 -\u0026gt; Status 란에 글씨가 연한 게 Cache에서 불러온 것 다시 이미지 더블클릭 -\u0026gt; 검사 -\u0026gt; Network -\u0026gt; 새로고침(F5) -\u0026gt; 이미지 클릭 -\u0026gt; headers tab -\u0026gt; Request header -\u0026gt; if-modified-since 보기     3. 검증 헤더와 조건부 요청 2  검증 헤더: Last-Modified, ETag\n조건부 요청 헤더: If-Modified-Since:, Last-Modified, If-None-Match:ETag\n   Last-Modified header 의 단점을 해결하는 header에 대해 알아보자.\n  검증 헤더 (Validator)\n Last-Modified, ETag    조건부 요청 헤더\n If-Match, If-None-Match:ETag 값 사용 If-Modified-Since, If-Unmodified-Since: Last-Modified 값 사용 조건이 만족하면 200 OK 조건이 만족하지 않으면 304 Not Modified    예시\n If-Modified-Since: 이후에 데이터가 수정되었다면???  데이터 미변경 예시  캐시: 2020년 11월 10일 10:00:00 vs 서버:2020년 11월 10일 10:00:00 304 Not Modified, 헤더 데이터만 전송(BODY 미포함) 전송 용량 0.1M (헤더 0.1M, 바디 1.0M)   데이터 변경 예시  캐시: 2020년 11월 10일 10:00:00 vs 서버:2020년 11월 10일 11:00:00 200 OK, 모든 데이터 전송(BODY 포함) 전송 용량 1.1M (헤더 0.1M, 바디 1.0M)        3.1 If-Modified-Since:, Last-Modified 단점  1초 미만(0.x초) 단위로 캐시 조정이 불가능하다. 날짜 기반의 로직을 사용한다. 그래서 데이터를 수정해서 날짜가 다르면, 같은 데이터를 수정해서 데이터 결과가 똑같은 경우에도 다시 다운받아야 한다. 위 문제로 서버에서 별도의 캐시 로직을 관리하고 싶은 경우, 다음 Header들을 사용한다.  ex) 스페이스나 주석처럼 크게 영향이 없는 변경에서 캐시를 유지하고 싶은 경우    3.2 해결책: ETag, IF-None-Match  날짜 기반의 date가 기준이 아닌 데이터의 버전 이름이 기준\n  ETag: Entity Tag 캐시용 데이터에 임의의 고유한 버전 이름을 달아둔다.  ex) ETag: v1.0, ETag: a2jiodwjekij3   데이터가 변경되면 이 이름을 바꾸어서 변경한다. (Hash를 다시 생성한다.)  ex) ETag: \u0026lsquo;aaaaa\u0026rsquo;, -\u0026gt; ETag: \u0026lsquo;bbbbbb\u0026rsquo;   진짜 단순하게 ETag만 보내서 같으면 유지, 다르면 다시 받는다.   ETag: aaaaaaaaaa header 로 서버가 응답했다.   그리고 위 Tag 로 응답 결과를 캐시에 저장했다.   두 번째 요청을 했지만, 캐시 시간이 초과된 상황이다.   서버에 재요청을 보낼 때, 캐시가 가지고 있는 ETag의 내용을 If-None-Match: header로, 요청 message의 header에 함께 보낸다.   서버에서 응답하는 ETag의 내용과 If-None-Match:의 내용을 비교한다. 동일하다는 건, 아직 데이터는 수정되지 않았음을 의미한다.   데이터가 수정되지 않았기 때문에, HTTP 헤더만 보낸다.   응답 결과를 재사용하여, 캐쉬 데이터의 헤더 데이터를 갱신한다.   4. 캐시와 조건부 요청 헤더  캐쉬 제어 헤더의 종류에는 3가지가 있다.  Cache-Control: 캐시 제어 Pragma: 캐시 제어(하위 호환) Expires: 캐시 유효 기간(하위 호환)    4.1 Cache-Control  캐시 지시어(directives)\n   Cache-Control: max-age\n 초 단위로, 캐시 유효 시간을 알려준다.    Cache-Control: no-cache\n 데이터는 캐시해도 되지만, 항상 원(origin) 서버에 검증하고 사용해야 한다.  Origin 서버라 하는 이유는 중간에 여러 proxy 서버가 있기 때문이다.      Cache-Contrl: no-store\n 데이터에 민감한 정보가 있으므로 저장하면 안된다. (메모리에서 사용하고 최대한 빨리 삭제)    4.2 Pragma  캐시 제어(하위 호환)\n  Pragma:no-cache HTTP 1.0 의 하위 호환  하위 호환이라 지금은 대부분 사용하지 않는다. 하지만, 구글에서는 여러 국가를 지원하기 때문에 사용하고 있다.    4.3 Expires  캐시 만료일 지정(하위 호환)\nexpires: Mon, 01 Jan 1990 00:00:00 GMT\n  캐시 만료일을 정확한 날짜로 지정한다. HTTP 1.0부터 사용한다. 지금은 더 유연한 방법인 Cache-Control:max-age 를 권장한다. Cache-Control:max-age와 함께 사용하면 Expires는 무시된다.  4.4 검증 헤더와 조건부 요청 헤더   검증 헤더 (Validator)\n ETag: \u0026ldquo;v1.0\u0026rdquo;, ETag: \u0026ldquo;asid93jkrh2l\u0026rdquo; Last-Modified: Thu, 04 Jun 2020 07:19:24 GMT    조건부 요청 헤더\n If-Match, If-None-Match: ETag 값 사용 If-Modified-Since, If-Unmodified-Since: Last-Modified 값 사용     5. 프록시 캐시  Cache-Control\n캐시 지시어(directives) - 기타\n   Cache-Control: public\n 응답이 public 캐시에 저장되어도 된다.    Cache-Control: private\n 응답이 해당 사용자만을 위한 것이다. private 캐시에 저장해야 한다. (기본값)    Cache-Control: s-maxage\n  프록시 캐시에만 적용되는 max-age\n  Age: 60(HTTP 헤더)\n Origin 서버에서 응답 후, proxy 캐시 내에 머문 시간(단위:초) 우리가 데이터를 받아야 알 수 있다.     원 서버와 클라이언트 사이에 중간 서버 없이, Origin (원) 서버에 직접 접근하는 경우 데이터를 가져오는데 비교적 긴 시간이 걸린다.   하지만 이렇게 proxy 캐시 서버를 도입하면 한국에서 보다 빨리 데이터를 받을 수 있다.   6. 캐시 무효화  확실한 캐시 무효화 응답\nCache-Control: no-cache, Cache-Control: no-store, Cache-Control: must-revalidate\nPragma: no-cache : HTTP 1.0 하위호환\n   캐시 무효화가 필요한 이유:\n 캐쉬를 적용하려고 하지 않아도, 웹 브라우저들이 임의로 적용한다. 그래서, 이 페이지는 캐쉬를 넣으면 안된다면, 위 헤더들을 반드시 넣어야 한다.    Cache-Control directives(캐시 지시어) - 확실한 캐시 무효화\n  Cache-Control: no-cache\n 데이터는 캐시해도 되지만, 항상 원 서버에 검증하고 사용해야 한다. Header 이름 혼동 주의!    Cache-Control: no-store\n 데이터에 민감한 정보가 있으므로 저장하면 안된다.\n(메모리에서 사용하고 최대한 빨리 삭제)    Cache-Control: must-revalidate\n 캐시 만료 후, 최초 조회시 원 서버에 검증해야 한다. 원 서버 접근 실패시 반드시 오류가 발생해야한다. 504(Gateway Timeout) =\u0026gt; no-cache와의 차이점 must-revalidate는 캐시 유효 시간이라면 캐시를 사용함    Pragma: no-cache\n HTTP 1.0 하위 호환      no-cache vs must-revalidate  no-cache의 기본 동작 (데이터가 수정되지 않은 상황)   no-cache 상황에서, 프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우   must=revalidate 상황에서, 프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우    정리\n  프록시 캐시와 원 서버 간 네트워크 단절이 순간 발생한 경우\n  no-cache\n 원 서버에 접근할 수 없는 경우, 서버 설정에 따라서 프록시 서버에서 응답할 수 있다. 응답한 data가 오류보다 오래된 데이터라도 보여준다. 단, 오류인지는 알려주지 않는다.    must=revalidate\n 원 서버에 접근할 수 없는 경우, 항상 오류가 발생해야 한다. 504 Gateway Timeout 으로 응답한다. 오류인지 알려준다       Reference  모든 개발자를 위한 HTTP 웹 기본지식  ","permalink":"http://jeha00.github.io/post/network/network_http_8/","summary":"검증 헤더와 조건부 요청 헤더의 종류, 그중 캐시 관련 헤더에 대해서 알아본다. 그리고, 프록시 서버와 원(Origin) 서버의 차이와 캐시를 어떻게 무효화하는지 알아본다.","title":"[TIL] Network HTTP Header 2"},{"content":"Intro  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.    이번 chapter에서는 HTTP header 여러 종류에서 주로 사용하는 헤더에 대해 알아보겠다.\n  HTTP header의 용도는 [TIL] Network HTTP basic을 참고한다.\n  RFC2616(과거) - HTTP Header 분류  HTTP header 종류에 대해 알아보기 전, 과거 \u0026lsquo;RFC2616\u0026rsquo; 일 때 헤더 분류를 살펴보자.   General 헤더: 메시지 전체에 적용되는 정보, 예) Connection: close Request 헤더: 요청 정보, 예) User-Agent: Mozilla/5.0 (Macintosh; ..) Response 헤더: 응답 정보, 예) Server: Apache Entity 헤더: 엔티티 바디 정보, 예) Content-Type: text/html, Content-Length: 3423  RFC2616(과거) - HTTP body  메세지 본문(message body)은 엔티티 본문(entity body)을 전달하는데 사용 entity body는 요청이나 응답에서 전달할 실제 데이터 entity header는 entity 본문의 데이터를 해석할 수 있는 정보를 제공한다.  데이터 유형(html, json), 데이터 길이, 압축 정보 등등    RFC2616 폐지 그리고, RFC7230~7235 등장  RFC2616이 폐지되고, RFC7230~7235가 등장하면서 Entity 라는 표현이 Representation 으로 바꼈다. 그리고, Representation 이란 representation Metadata와 Representation Data를 합친 걸 의미한다. 엔티티(Entity) -\u0026gt; Representation  Representation = Representation Metadata + Representation Data    RFC7230 - HTTP Body  메시지 본문(message body)을 통해 표현 데이터를 전달한다. 메시지 본문을 다른 말로 페이로드(payload)라 한다. representation은 요청이나 응답에서 전달할 실제 데이터 representation header는 Representation Data를 해석할 수 있는 정보를 제공한다.  데이터 유형(html, json), 데이터 길이, 압축 정보 등등   참고: Representation header는 representation metadata 와 payload message를 구분해야 하지만, 여기서는 생략한다.   그러면 이 representation이 뭔지 알아보자.   1. 표현(representation) 1.0 Representation header 란??  client와 server 간에 주고 받는 resource의 data를 어떻게 표현할지 결정하는 header\n   예) DB에 있는 binary data를 바로 서버에 전송하는 게 아니라, HTML 또는 XML 또는 JSON 형태로 전달한다.\n  Representation header는 전송, 응답 둘 다 사용한다.\n  그래서 representation header 에는 여러 정보들이 담긴다.\n Content-Type: 표현 데이터의 형식 설명 Content-Encoding: 표현 데이터의 압축 방식 Content-Language: 표현 데이터의 자연 언어 Content-Length: 표현 데이터의 길이    1.1 Content-Type  표현 데이터의 형식 설명\n  미디어 타입, 문자 인코딩 예)  text/html; charset =utf-8 application/json image/png    1.2 Content-Encoding  표현 데이터의 압축 방식 설명\n  표현 데이터를 압축하기 위해 사용 데이터를 전달하는 곳에서 압축 후 인코딩 헤더 추가 데이터를 읽는 쪽에서 인코딩 헤더의 정보로 압축 해제 예)  gzip deflate identity    1.3 Content-Language  표현 데이터의 자연어 설명\n  표현 데이터의 자연 언어를 표현 예)  ko en en-US    1.4 Content-Length  표현 데이터의 길이 설명\n  바이트 단위 Transfer-Encoding(전송 코딩)을 사용하면 Content-Length를 사용하면 안된다.   2. 콘텐츠 협상  클라이언트가 선호하는 표현을 서버에게 요청하는 것\n   서버에 요청 사항이 다양하다면, 우선 순위에 맞춰 서버에서 만든다.\n  클라이언트가 요청할 때 작성하기 때문에, 요청 시에만 사용한다.\n  협상 헤더 종류\n Accept: 클라이언트가 선호하는 미디어 타입 전달 Accept-Charset: 클라이언트가 선호하는 문자 인코딩 Accept-Encoding: 클라이언트가 선호하는 압축 인코딩 Accept-Language: 클라이언트가 선호하는 자연 언어    2.1 Accept-Language 적용 전과 후  적용 전   적용 후   복잡한 예시  2.2 협상과 우선순위 (Quality Values(q)) 2.2.1 협상과 우선순위 첫 번째  첫 번째: Quality Values(q)가 높을 수록 우선순위가 높다.\n   Quality Values(q) 값 사용\n 0~1, 클수록 높은 우선순위 생략하면 1    Accept-Language: ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7\n   ko-KR;q=1 (q생략)    ko;q=0.9    en-US;q=0.8    en:q=0.7      인터넷 창 -\u0026gt; 검사 -\u0026gt; Network -\u0026gt; Headers -\u0026gt; Request Headers 창에 들어가면 사용하는 도메인의 우선순위를 볼 수 있다.\n  2.2.2 협상과 우선순위 두 번째  두 번째: 구체적인 것이 우선된다. GET /event\nAccept: text/*, text/plain, text/plain;format=ﬂowed, */*\n   Accept: text/_, text/plain, text/plain;format=flowed, _/*\n text/plain;format=flowed text/plain text/* */*    2.2.3 협상과 우선순위 세 번째  세 번째: 구체적인 것을 기준으로 미디어 타입을 맞춘다.\n  Media Type 우선도  Accept: text/*;q=0.3, text/html;q=0.7, text/html;level=1,text/html;level=2;q=0.4, */*;q=0.5     3. 전송 방식  전송 방식에는 4 종류가 있다.  단순 전송(Content-Length) 압축 전송(Content-Encoding) 분할 전송(Transfer-Encoding) 범위 전송(Range, Content-Range)    3.1 단순 전송(Content-Length)  content의 길이를 알 수 있을 때 사용한다. 한 번에 요청하고,한 번에 받는다.  3.2 압축 전송(Content-Encoding)  서버에서 메세지 바디를 압축해서 전달하는 방식 Content-Encoding에 어떻게 압축했는지 알려줘야, 웹 브라우저에서 이에 맞게 풀어서 접근할 수 있다.  3.3 분할 전송(Transfer-Encoding)  용량이 커서 한 번에 보내면 받는데 시간이 걸리기 때문에, 분할하여 보내서 오는 대로 바로 구현한다. 이 때는 content-length를 넣으면 안된다. 전체 길이를 알 수 없기 때문이다. 5 byte 씩 나눠서 보내고, 마지막에는 보낼 게 없어서 0이다.  3.4 범위 전송(Range, Content-Range)  4. 일반 정보 4.1 From  유저 에이전트의 이메일 정보\n  일반적으로 잘 사용되지 않는다. 검색 엔진 같은 곳에서, 주로 사용한다. 요청에서 사용한다.  4.2 Referer  이전 웹 페이지 주소\n  유입 경로 분석을 위해 많이 사용한다. 현재 요청된 페이지의 이전 웹 페이지 주소 A -\u0026gt; B로 이동하는 경우 B를 요청할 때 Referer: A 를 포함해서 요청한다. Referer를 사용해서 유입 경로 분석이 가능하다. 요청에서 사용한다. 참고: referer는 단어 referrer의 오타다. 이미 너무 많은 곳에서 사용해서 그냥 사용한다.  4.3 User-Agent  유저 에이전트 애플리케이션 정보\nuser-agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.183 Safari/537.36\n  검사(F12) -\u0026gt; Network -\u0026gt; Headers -\u0026gt; User-Agent 확인 클리이언트의 애플리케이션 정보(웹 브라우저 정보, 등등) 통계 정보 어떤 종류의 브라우저에서 장애가 발생하는지 파악 가능 요청에서 사용  4.4 Server  요청을 처리하는 ORIGIN 서버의 소프트웨어 정보\n여러 proxy server를 거치고, 최종적으로 나의 요청을 처리하는 서버를 ORIGIN 서버라 한다.\n  Server: Apache/2.2.22 (Debian) server: nginx 응답에서 사용한다.  4.5 Data  메시지가 생성된 날짜\n  Date: Tue, 15 Nov 1994 08:12:31 GMT 응답에서 사용한다.   5. 특별 정보  Host: 요청한 호스트 정보(도메인) Location: 페이지 리다이렉션 Allow: 허용 가능한 HTTP 메서드 Retry-After: 유저 에이전트가 다음 요청을 하기까지 기다려야 하는 시간  5.1 Host  GET /search?q=hello\u0026amp;hl=ko HTTP/1.1\nHost: www.google.com\n  요청에서 사용 필수 하나의 서버가 여러 도메인을 처리할 때  하나의 IP 주소에 여러 도메인이 적용되어 있을 때     가상 호스트를 통해 여러 도메인을 한 번에 처리할 수 있는 서버에서는 실제 애플리케이션이 여러 개 구동될 수 있다. 이럴 때 HOST가 없이 요청을 하면 어느 도메인으로 들어가야하는지 알 수 없다. 이럴 때, 헤더 정보에 host를 추가하여 어느 도메인으로 들어가야 할지 알 수 있다.  5.2 Location  페이지 리다이렉션\n  웹 브라우저는 3xx 응답의 결과에 Location 헤더가 있으면, Location 위치로 자동 이동 (리다이렉트) 응답코드 3xx에서 설명 201 (Created): Location 값은 요청에 의해 생성된 리소스 URI 3xx (Redirection): Location 값은 요청에 의해 생성된 리소스 URI  5.3 Allow  허용 가능한 HTTP 메서드를 명시한다.\n하지만, 실제로 많이 구현되어 있지 않으므로 이런 게 있다 정도만 알자.\n  405 (Method Not Allowed) 에서 응답에 포함해야 한다. Allow: GET, HEAD, PUT  5.4 Retry-After  유저 에이전트가 다음 요청을 하기까지 기다려야 하는 시간\n하지만, 실제로는 사용하기 어렵다.\n  503 (Service Unavailable): 서비스가 언제까지 불능인지 알려줄 수 있음 Retry-After: Fri, 31 Dec 1999 23:59:59 GMT (날짜 표기) Retry-After: 120 (초단위 표기)   6. 인증 6.1 Authorization  클라이언트 인증 정보를 서버에 전달한다.\n  Authorization: Basic xxxxxxxxxxxxxxxx 인증 관련해서 여러 매커니즘이 있다. 각 매커니즘마다 넣는 헤더가 다르다. 추가적으로 알아보자.  6.2 WWW-Authenticate  리소스 접근시 필요한 인증 방법 정의한다.\n  401 Unauthorized 응답과 함께 사용한다. WWW-Authenticate: Newauth realm=\u0026ldquo;apps\u0026rdquo;, type=1, title=\u0026ldquo;Login to \u0026quot;apps\u0026quot;\u0026rdquo;, Basic realm=\u0026ldquo;simple\u0026rdquo;  인증할려면 : 이후의 내용들을 참고해서 인증 방법을 만들라는 의미다.     7. 쿠키(중요) 7.1 쿠키란??  쿠키: HTTP의 stateless 성질 때문에 필요 하에, 서버가 자동 생성하여 클라이언트에 저장하는 데이터\n캐시: 클라이언트 자체에서 페이지 로드를 효율적으로 하려고 저장하는 데이터\n   매우 많이 사용하고, 많이 중요하다.\n  웹 브라우저는 서버에서 보낸 이 쿠키를 웹 브라우저 내부에 쿠키 저장소에 저장해 놓았다가, 서버의 응답에 클라이언트가 HTTP 메세지를 보낼 때, 이 쿠키 정보를 포함하여 보내는 용도\n  Cookie 를 사용할 때는 2가지 header를 사용한다.\n Set-Cookie: server에서 client로 쿠키를 전달할 때(응답) Cookie: client가 server에서 받은 쿠키를 저장하고, HTTP 요청 시 서버로 전달할 때    그러면 먼저 쿠키를 사용하지 않으면 어떻게 되는지 알아보자.\n   GET으로 /welcome resource를 조회한다. 서버에서는 손님으로 인식한다. 로그인을 해야 서버에서 가입된 유저로 인식한다.   하지만, 로그인후 다시 welcome page에 접근하면 다시 손님으로 인식한다.   HTTP는 stateless 프로토콜이기 때문에, 클라이언트와 서버가 요청과 응답을 주고 받으면 연결이 끊어진다. 그래서 클라이언트가 다시 요청하면 서버는 이전 요청을 기억하지 못하기 때문에, 클라이언트와 서버는 서로 상태를 유지하지 않는다.   이에 대한 대안으로 모든 요청에 사용자 정보가 포함되도록 개발한다면??  현실적으로 매우 힘들다. 그래서 이에 대한 대책으로 만든게 쿠키(cookie)다.     쿠키를 사용하면 어떻게 되는지 알아보자.   웹 브라우저 내부에 쿠키 저장소가 있어서, 서버가 만든 쿠키를 이 저장소에 저장한다.   서버에 요청을 보낼 때마다 쿠키 저장소를 조회하여 Cookie HTTP header를 생성한다.   모든 요청에 쿠키 정보를 자동으로 포함한다.  7.2 쿠키의 사용처와 문제점  ex) set-cookie: sessionId=abcde1234; expires=Sat, 26-Dec-2020 00:00:00 GMT; path=/; domain=.google.com; Secure\n   사용처\n 사용자 로그인 세션 관리 (위 이미지 사례) 광고 정보 tracking  이 웹 브라우저의 사용자는 이런 광고를 주로 클릭한다는 걸 추적한다.      문제점\n 네트워크 트래픽 추가 유발한다. 그래서 최소한의 정보만 사용한다.  (세션 id, 인증토큰)   서버에 전송하지 않고, 웹 브라우저 내부에 데이터를 저장하고 싶으면 웹 스토리지 (localStorage, sessionStroage) 참고    주의사항!\n 보안에 민감한 데이터는 저장하면 안된다.  ex) 주민번호, 신용카드 번호 등등      7.3 쿠키 - 생명주기 header  쿠키가 언제까지 지속되는지 알려주는 header\nExpries, max-age\n   Set-Cookie: expires = Sat, 26-Dec-2020 04:39:21 GMT\n 만료일이 되면 쿠키를 삭제한다.    Set-Cookie: max-age = 3600 (3600초)\n 0이나 음수를 지정하면 쿠키 삭제    세션 쿠키: 만료 날짜를 생략하면 브라우저 종료 시까지만 유지\n  영속 쿠키: 만료 날짜를 입력하면 해당 날짜까지 유지\n  7.4 쿠키 - domain header  ex) domain = example.org\n   쿠키는 도메인을 지정할 수 있다.\n  2가지 방법\n  명시: 명시한 문서 기준 도메인 + 서브 도메인을 포함한다.\n domain = example.org 를 지정해서 쿠키 생성  example.org는 물론이고, dev.example.org도 쿠키 접근한다.      생략: 현재 무선 기준 도메인만 적용한다.\n example.org에서 쿠키를 생성하고 domain 지정을 생략한다.  exmple.org 에서만 쿠키 접근 가능하다. dev.example.org는 쿠키 미접근  하위 도메인은 접근 불가능하다.          7.5 쿠키 - 경로 header  예) path = /home\n  이 경로를 포함한 하위 경로 페이지만 쿠키 접근 가능하다. 일반적으로 path=/ 루트로 지정한다. 예  path =/home 지정  /home -\u0026gt; 가능 /home/level1 -\u0026gt; 가능 /home/level1/level2 -\u0026gt; 가능 /hello -\u0026gt; 불가능      7.6 쿠키 - 보안 header  Secure, HttpOnly, SameSite\n   Secure\n 쿠키는 http, https를 구분하지 않고 전송한다. Secure를 적용하면 https인 경우에만 전송    HttpOnly\n xSS 공격 방지 자바스크립트에서 접근 불가(document.cookie) HTTP 전송에만 사용    SameSite\n XSRF 공격방지 요청 도메인과 쿠키에 설정된 도메인이 같은 경우만 쿠키 전송     Reference  모든 개발자를 위한 HTTP 웹 기본지식 HTTP 헤더1- 일반 헤더  ","permalink":"http://jeha00.github.io/post/network/network_http_7/","summary":"representation, 콘텐츠 협상, 전송 방식, 일반 정보, 특별 정보, 인증 그리고 쿠키에 대해 알아본다.","title":"[TIL] Network HTTP Header 1"},{"content":"Introduction  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.  이번 시간에는 상태 코드에 대해 알아본다.  상태 코드란??\n클라이언트가 보낸 요청의 처리 상태를 응답에서 알려주는 기능\n 상태 코드의 종류에는 다음과 같다.  1xx (Informational): 요청이 수신되어 처리중 2xx (Successful): 요청 정상 처리 3xx (Redirection): 요청을 완료하려면 추가 행동이 필요 4xx (Client Error): 클라이언트 오류, 잘못된 문법등으로 서버가 요청을 수행할 수 없음 5xx (Server Error): 서버 오류, 서버가 정상 요청을 처리하지 못함    만약 모르는 상태 코드가 나타나면??\n 클라이언트가 인식할 수 없는 상태코드를 서버가 반환하면?? 클라이언트는 상위 상태 코드로 해석해서 처리한다. 미래에 새로운 상태 코드가 추가되어도 클라이언트를 변경하지 않아도 된다. 예)  299 ??? -\u0026gt; 2xx (Successful) 451 ??? -\u0026gt; 4xx (Client Error) 599 ??? -\u0026gt; 5xx (Server Error)      그러면 각 상태 코드에 대해 알아보자.\n(1xx는 거의 사용하지 않으므로 생략한다. )\n   2xx (Successful)  클라이언트의 요청을 성공적으로 처리한 상태\n   2xx state code 종류  200 OK 201 Created 202 Accepted 204 No Content    200 OK    요청이 성공한 상태\n  200번대 모든 코드들을 사용하지 않고, 200과 201만 사용하는 경우가 많다. 그래서, 팀 내에서 코드를 어디까지 사용할지 결정한다.    201 Created    요청이 성공하여 새로운 리소스가 생성된 상태\n   202 Accepted    요청이 접수되었으나 처리가 완료되지 않은 상태\n  배치 처리(batch processing) 같은 곳에서 사용한다. 예) 요청 접수 후, 1시간 뒤에 배치 프로세스가 요청을 처리한다.   배치 처리(batch processing)란??\n일괄 처리라 하며, 데이터를 일괄적으로 모아서 처리하는 작업을 말한다.\n   204 No Content    서버가 요청을 성공적으로 수행했으나, 응답 페이로드 본문에 보낼 데이터가 없는 상태\n  예) 웹 문서 편집기에서 save 버튼 save 버튼의 결과로 아무 내용이 없어도 된다. save 버튼을 눌러도 같은 화면을 유지해야 한다. 결과 내용이 없어도, 204 메시지(2xx)만으로 성공을 인식할 수 있다.   3xx (Redirection)  요청을 완료하기 위해 유저 에이전트(웹 브라우저)의 추가 조치가 필요한 상태\n   3xx status code 종류  300 Multiple Choices 301 Moved Permanently 302 Found 303 See Other 304 Not Modified 307 Temporary Redirect 308 Permanent Redirect    리다이렉트란???\n 웹 브라우저가 3xx 응답의 결과에 Location 헤더가 있으면, Location 위치로 자동 이동하는 것      리다이렉션의 종류   영구 리다이렉션:\n 특정 리소스의 URI가 영구적으로 이동 예) /members -\u0026gt; /users 예) /event -\u0026gt; /new-event    일시 리다이렉션:\n 일시적인 변경 주문 완료 후 주문 내역 화면으로 이동한다. 자주 쓰이는 패턴: PRG (Post/Redirect/Get)    특수 리다이렉션:\n 결과 대신 캐시를 사용한다. 클라이언트가 캐시 사용 시간을 확인하기 위해 서버에게 보내어 서버가 캐시 생성일자로 응답하는 것을 말한다.        영구 리다이렉션 (301, 308)  리소스의 URI가 영구적으로 이동 원래의 URL를 사용X, 검색 엔진 등에서도 변경 인지      301 Moved Permanently  리다이렉트 시, 요청 메서드가 POST에서 GET으로 변하고, 본문이 제거될 수 있음(MAY) 본문이 제거될 수 있다는 문제점을 308이 해결할 수 있으나, 대부분 301을 사용한다. 왜냐하면 경로가 /new-event로 바뀌면 내부적으로 전달하는 데이터가 다 바뀌는 것이기 때문에, POST로 와도 GET으로 되돌리는 게 맞다.    308 Permanent Redirect   301과 기능은 같음\n  리다이렉트시 요청 메서드와 본문 유지\n(처음 POST를 보내면 리다이렉트도 POST 유지)\n  스펙에 나와 있어 설명한다. 실무에서는 거의 이렇게 사용하지 않는다.\n      일시적인 리다이렉션 (302, 307, 303)  리소스의 URI가 일시적으로 변경 따라서 검색 엔진 등에서 URL을 변경하면 안됨 302 Found  리다이렉트시 요청 메서드가 GET으로 변하고, 본문이 제거될 수 있음(MAY)   307 Temporary Redirect  302와 기능은 같음 리다이렉트시 요청 메서드와 본문 유지\n(요청 메서드를 변경하면 안된다. MUST NOT)   303 See Other  302와 기능은 같음 리다이렉트시 요청 메서드가 GET으로 변경        PRG 예시 (전, 후)   POST로 주문 후, 웹 브라우저를 새로고침하면??\n 새로 고침은 다시 요청하는 것이기 때문에, 중복 주문이 될 수 있다.    이를 해결하기 위해 자주 사용하는 패턴이 PRG다.\n PRG: POST/Redirect/Get    PRG 사용 전\n   PRG 사용 후   302 또는 303 사용한다. POST로 주문 후에도 새로 고침으로 인한 중복 주문을 방지한다. POST로 주문 후에도 주문 결과 화면을 GET method로 리다이렉트하여, 새로 고침해도 결과 화면을 GET 으로 조회한다. 즉, 중복 주문 대신에 결과 화면만 GET으로 다시 요청한다. PRG를 사용해서 경고창이 안뜨고, 서버 입장에서는 오류가 줄어든다.      [Summary]\n 302 Found -\u0026gt; GET으로 변할 수 있다. 307 Temporary Redirect -\u0026gt; 메서드가 변하면 안된다. 303 See Other -\u0026gt; 메서드가 GET으로 변경한다.    [History]\n 처음 302 스펙의 의도는 HTTP 메서드를 유지하는 것이다. 그런데 웹 브라우저들이 대부분 GET으로 바꿨다.(일부는 다르게 동작) 그래서 모호한 302를 대신하는 명확한 307, 303이 등장했다.\n(301 대응으로 308도 등장)    [Now]\n 307, 303을 권장하지만 현실적으로 이미 많은 애플리케이션 라이브러리들이 302를 기본값으로 사용 자동 리다이렉션시에 GET으로 변해도 되면 그냥 302를 사용해도 큰 문제 없음    기타 리다이렉션 (300, 304)  300 Multiple Choices: 안쓴다. 304 Not Modified  매우 많이 사용한다. 캐시를 목적으로 사용 클라이언트에게 리소스가 수정되지 않았음을 알려준다. 따라서 클라이언트는 로컬PC에 저장된 캐시를 재사용한다. (캐시로 리다이렉트 한다.) 304 응답은 응답에 메시지 바디를 포함하면 안된다. (로컬 캐시를 사용해야 하므로) 조건부 GET, HEAD 요청시 사용     4xx (Client Error)  오류의 원인이 \u0026lsquo;클라이언트\u0026rsquo;에게 있어서, 발생하는 클라이언트 오류\n  클라이언트의 요청에 잘못된 문법 등으로 서버가 요청을 수행할 수 없다. 클라이언트가 이미 잘못된 요청,데이터를 보내고 있어서, 똑같은 재시도는 실패한다.  400 Bad Request  클라이언트가 잘못된 요청을 해서 서버가 요청을 처리할 수 없다.\n  요청 구문, 메시지 등등으로 인한 오류가 발생한 상태다. 클라이언트는 요청 내용을 다시 검토하고, 보내야 한다. 예) 요청 파라미터가 잘못되거나, API 스펙이 맞지 않을 때  401 Unauthorized  클라이언트가 해당 리소스에 대한 인증이 필요하다.\n  인증(Authentication) 되지 않은 상태를 말한다.  401 오류 발생시 응답에 WWW-Authenticate 헤더와 함께 인증 방법을 설명한다.     [참고]\n 인증(Authentication): 본인이 누구인지 확인, (로그인) 인가(Authorization): 권한부여 (ADMIN 권한처럼 특정 리소스에 접근할 수 있는 권한, 인증이 있어야 인가가 있음) 오류 메시지가 Unauthorized 이지만 인증 되지 않음 (이름이 아쉬움)   403 Forbidden  서버가 요청을 이해했지만, 승인을 거부함\n  주로 인증 자격 증명은 있지만, 접근 권한이 부충분한 경우  예) Admin 등급이 아닌 사용자가 로그인하여, admin 등급의 resource에 접근하는 경우    404 Not Found  요청 리소스를 찾을 수 없다.\n  요청 리소스가 서버에 없다. 클라이언트가 권한이 부족한 리소스에 접근할 때 해당 리소스를 숨기고 싶을 때   5xx (Serve Error)  오류의 원인이 \u0026lsquo;서버\u0026rsquo;에게 있어서, 발생하는 서버 오류\n  Client Error와 달리 서버에 문제가 있기 때문에, 재시도하면 성공할 수 있다. 500대 에러는 서버에 심각한 문제가 터졌을 때를 의미한다. 고객의 잔고가 부족할 경우, 20세 이상만 이용 가능한데 15세가 들어왔을 경우 등등은 500번대 에러가 아니다.  500 Internal Server Error  서버 문제로 오류 발생, 애매하면 500 오류\n  서버 내부 문제로 오류가 발생한 상황 애매하면 500 오류를 사용  503 Service Unavailable  서비스 이용 불가\n  서버가 일시적인 과부하 또는 예정된 작업으로 잠시 요청을 처리할 수 없는 상황 Retry-After 헤더 필드로 얼마 뒤에 복구되는지 보낼 수 있다. 대부분의 서비스 에러는 예측 불가하기 때문에 500번이다.   Reference  모든 개발자를 위한 HTTP 웹 기본지식  ","permalink":"http://jeha00.github.io/post/network/network_http_6/","summary":"HTTP status 2xx, 3xx, 4xx, 5xx에 대해 각각 알아본다.","title":"[TIL] Network HTTP status"},{"content":"0. Introduction  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.  1. 클라이언트에서 서버로 데이터 전송  클라이언트에서 서버로 데이터를 전달하는 방식은 크게 2가지가 있다.  쿼리 파라미터를 통한 데이터 전송  GET을 많이 사용한다. 예) 주로 정렬 필터나 검색어를 사용할 때 쿼리 파라미터를 많이 사용한다.   메시지 바디를 통한 데이터 전송  POST, PUT, PATCH를 사용한다. 예) 회원 가입, 상품 주문, 리소스 등록, 리소스 변경하는데 사용한다.       그리고, 클라이언트가 서버로 데이터를 전송하는 4가지 상황이 있다. 각 상황에서 어떻게 클라이언트가 서버에 데이터를 전달하는지 알아보자.   1.1 정적 데이터 조회  예) 이미지, 정적 텍스트 문서 정적 데이터는 일반적으로 쿼리 파라미터 없이 GET method로 resource path만 적어, 단순하게 조회가 가능하다.   1.2 동적 데이터 조회  예) 주로 검색,게시판 목록에서 검색어를 사용하여 정렬 필터한다. (검색어) 조회 조건을 줄여주는 필터, 조회 결과를 정렬하는 정렬 조건에 주로 사용한다. 조회이기 때문에 GET 사용하지만, 정적 데이터가 아닌 동적 데이터이므로, 쿼리 파라미터를 사용해서 데이터를 클라이언트가 서버에게 넘겨줘야 한다. GET도 메세지 바디를 사용할 수 있지만, 지원하지 않는 경우가 많아서 사용하지 않는다.   1.3 HTML Form을 통한 데이터 전송  HTML Form 전송은 GET, POST만 지원한다. 예) 회원 가입, 상품 주문, 데이터 변경  POST 전송 - 저장  예) 회원 가입, 상품 주문, 데이터 변경 상황 전송 버튼을 누르면 웹 브라우저가 form 태그 정보를 읽어서, HTTP message를 생성한다. 그리고, action에 작성된 경로로 해당 method 요청을 보낸다. 쿼리 파라미터랑 동일한 형식으로 HTTP message body에 넣어 서버에 전송된다.  username=kim\u0026amp;age=20    GET 전송 - 저장 (오류)  GET이라 메세지 바디를 안쓰기 때문에, url 경로에다가 data를 넣는다. 즉, Query parameter 형식으로 넣어준다. 또한, GET은 조회용으로만 사용가능하므로 저장하는 곳에 사용하면 안된다. GET은 조회이므로, /members 등으로 조회가 가능한 곳으로 보내야 정상적으로 처리된다.   [결론]\nFORM에서 GET / POST의 사용에 맞춰서 웹 브라우저가 알아서 HTTP 요청 메세지의 구성을 Query 또는 Body 등으로 맞춰서 생성한다.\n multipart/form-data  다른 종류의 여러 파일과 폼의 내용을 함께 전송이 가능해서 이름이 multipart다. 주로 binary data를 전송할 때 사용한다. 웹브라우저가 생성한 요청 HTTP 메시지의 content-type에 boundary 가 명시되어 있는데, form data 간 구분을 지어준다.   1.4. HTTP API를 통한 데이터 전송  HTML Form을 쓰지 않는 모든 상황을 말한다. 예) 회원 가입, 상품 주문, 데이터 변경에 사용 그러면 언제 사용하는가???  서버 to 서버: 백엔드 시스템 통신 앱 클라이언트에서 전송 시 (아이폰,안드로이드) 웹 클라이언트에서 HTML Form 전송 대신 자바 스크립트를 통한 통신에 사용 (AJAX)  예)React, Vue.JS 같은 웹 클라이언트와 API 통신     POST, PUT,PATCH: 사용하며, 메시지 바디를 통해 데이터를 전송 GET: 조회, 쿼리 파라미터로 데이터를 전달 Content-type: application/json을 주로 사용 (사실상 표준)  TEXT, XML, JSON 등등이 있지만, XML이 읽기 어렵고, 복잡해서 지금은 JSON을 사용한다. 데이터 크기도 상대적으로 XML보다 작아서, 사실상 JSON이 표준이다.     2. HTTP API 설계  HTTP API 설계에는 3가지 종류가 있다.  HTTP API - collection  POST 기반 등록 서버가 리소스 URI 결정   HTTP API - store  PUT 기반 등록 클라이언트가 리소스 URI 결정   HTML FORM 사용  순수 HTML + HTML form 사용 GET, POST만 지원       이 3가지에 대해 각각 알아보자.  2.1 HTTP API - collection  서버가 새로 등록된 리소스 URI를 생성하고 관리하는 구조: Collection\n  회원 관리 시스템: API 설계 - POST 기반 등록  회원 목록 /members -\u0026gt; GET 회원 등록 /members -\u0026gt; POST 회원 조회 /members/{id} -\u0026gt; GET (회원 단권 조회) 회원 수정 /members/{id} -\u0026gt; PATCH, PUT, POST 회원 삭제 /members/{id} -\u0026gt; DELETE     실제로는 위의 경우처럼 명확하게 구분되지 않기 때문에, 컨트롤 URI 를 사용할 수 밖에 없다.\n  클라이언트는 등록될 리소소의 URI를 모른다.  회원 등록 /members -\u0026gt; POST POST /members   서버가 새로 등록된 리소스 URI를 생성한다.  HTTP/1.1 201 Created\nLocation: /members/100   Collection  서버가 관리하는 리소스 디렉토리 서버가 리소스의 URI를 생성하고 관리 여기서 collection은 /members     2.2 HTTP API - store  클라이언트가 직접 resource uri를 지정하고, 관리하는 구조: Store\n  파일 관리 시스템: API 설계 - PUT 기반 등록  파일 목록 /files -\u0026gt; GET 파일 조회 /files/{filename} -\u0026gt; GET 파일 등록 /files/{filename} -\u0026gt; PUT 파일 삭제 /files/{filename} -\u0026gt; DELETE 파일 대량 등록 /files -\u0026gt; POST  파일 등록에 PUT을 썼기 때문에, 대량 등록에는 POST를 썼다. 왜냐하면 POST는 임의로 의미를 만들 수 있다.       클라이언트가 리소스 URI를 알고 있어야 한다.  파일 등록/files/{filename} -\u0026gt; PUT PUT/files/star.jpg   클라이언트가 직접 리소스의 URI를 지정한다. Store  클라이언트가 관리하는 리소스 디렉토리 클라이언트가 리소스의 URI를 생성하고 관리 여기서 store는 /files     그럼 위 두 방식(Collection, Store) 중 무엇을 많이 사용할까??\n대부분 실무에서는 POST를 사용하는 Collection 구조를 사용한다. 하지만, file 관리의 경우, Store를 사용한다.\n  2.2 HTML FORM 사용  회원 목록 /members -\u0026gt; GET 회원 등록 폼 /members/new -\u0026gt; GET 회원 등록 /members/new, /members -\u0026gt; POST  위에 등록 폼과 같은 url을 쓰는 것을 추천한다.   회원 조회 /members/{id} -\u0026gt; GET 회원 수정 폼 /members/{id}/edit -\u0026gt; GET  실제로 수정일 일어나는 게 아니기 때문에, GET 을 사용한다.   회원 수정 /members/{id}/edit, /members/{id} -\u0026gt; POST  위에 수정 폼과 같은 url을 쓰는 것을 추천한다.   회원 삭제 /members/{id}/delete -\u0026gt; POST   HTML FORM은 GET, POST만 지원 하므로 제약이 있다. 이런 제약을 해결하기 위해 동사로 된 리소스 경로를 사용한다.  최대한 리소스 개념을 가지고 사용하지만, 안될 때 대체제로 컨트롤 URI를 사용한다.   AJAX 같은 기술을 사용해서 해결 가능하다 -\u0026gt; 회원 API 참고 여기서는 순수 HTML, HTML FORM 이야기다.   3. 참고하면 좋은 URI 설계 개념   문서(document)\n 단일 개념(파일 하나, 객체 인스턴스, 데이터베이스 row) 예) /members/100, /files/star.jpg    컬렉션(collection)\n 서버가 관리하는 리소스 디렉터리 서버가 리소스의 URI를 생성하고 관리 예) /members    스토어(store)\n 클라이언트가 관리하는 자원 저장소 클라이언트가 리소스의 URI를 알고 관리 예) /files    컨트롤러(controller), 컨트롤 URI\n 문서, 컬렉션, 스토어로 해결하기 어려운 추가 프로세스 실행 동사를 직접 사용 예) /members/{id}/delete     REST API를 보면 해결이 안되는 경우가 있다.\n그럴 때, 네 번째 개념인 컨트롤 URI가 꼭 있어야 한다.\n문서, collection, store 만으로 부족할 때, 컨트롤 URI 를 사용한다.\n  https://restfulapi.net/resource-naming 참고하기  여러 사람들이 HTTP API를 하다보니, 좋은 practice가 있다.     Reference  모든 개발자를 위한 HTTP 웹 기본지식 HTTP 메서드 활용  ","permalink":"http://jeha00.github.io/post/network/network_http_5/","summary":"HTTP method를 가지고 클라이언트가 서버에 어떻게 데이터를 전송하는지, 그리고 API 설계에는 무슨 종류가 있는지 알아본다.","title":"[TIL] Network HTTP method use"},{"content":"0. Introduction  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.   1. HTTP API 설계해보기   API 설계에서 가장 중요한 것은 resource를 식별하는 게 중요하다.\n  그 다음으로 해야할 것이 resource와 행위를 분리하는 것 이다.\n  회원 정보 관리 API를 만든다고 가정하자.\n 회원 목록 조회 회원 조회 회원 등록 회원 수정 회원 삭제      그러면 초보 개발자인 경우, 다음과 같이 API URI 설계할 수 있다.\n 회원 목록 조회 /read-member-list 회원 조회 /read-member-by-id 회원 등록 /create-member 회원 수정 /update-member 회원 삭제 /delete-member    위 방식의 문제점은 URI의 정의를 정확히 살리지 못하는 방법이다.\n URI = Uniform Resource Identifier    가장 중요한 것은 resource 식별 이다.\n  resource의 의미는\n 회원을 등록하고, 수정하고 조회하는 게 리소스가 아니다.  예) 미네랄을 캐라 -\u0026gt; 미네랄이 resource   회원이라는 개념 자체가 바로 resource다.    그러면 resource를 어떻게 식별하는게 좋을까??\n 회원을 등록하고, 수정하고, 조회하는 것을 모두 배제한 다음 회원이라는 resource만 식별하면 된다 -\u0026gt; 회원 resource를 URI에 매핑한다.       위 사항들을 반영하면 다음과 같다. (resource 식별, URI 계층 구조 활용)\n  참고: 계층 구조상 상위를 컬렉션으로 보고 복수단어 사용 권장(member -\u0026gt; members)\n 회원 목록 조회 /members 회원 조회 /members/{id} 회원 등록 /members/{id} 회원 수정 /members/{id} 회원 삭제 /members/{id}    그러면 회원 조회부터 삭제는 어떻게 구분할 수 있을까???\n resource와 행위를 분리 하여 구분한다. resource: 회원 행위: 조회, 등록,삭제, 변경 resource는 명사, 행위는 동사     행위는 어떻게 구분할 수 있을까??  HTTP method를 사용하여 구분한다. HTTP method에 대해 알아보자.     2. HTTP method - GET, POST   HTTP 주요 method\n GET: resource 조회 POST: 요청 데이터 처리, 주로 등록에 사용 PUT: 리소스를 대체, 해당 리소스가 없으면 생성 PATCH: resource 부분 변경 DELETE: resource 삭제    HTTP 기타 method\n HEAT: GET과 동일하지만 메시지 바디 부분을 제외하고, 상태 줄과 헤더만 반환 OPTIONS: 대상 리소스에 대한 통신 가능 옵션(메서드)을 설명(주로 CORS에서 사용) CONNECT: 대상 자원으로 식별되는 서버에 대한 터널을 설정 TRACE: 대상 리소스에 대한 경로를 따라 메시지 루프백 테스트를 수행  CONNECT 와 TRACE는 거의 사용안한다.       이번 단원에서는 GET과 POST에 대해 자세히 알아보자.   2.1 HTTP method - GET GET /search?q=hello\u0026amp;hl=ko HTTP/1.1 Host: www.google.com  resource 조회 (/search?q=hello\u0026amp;hl=ko에 있는 자원을 가져와라.) 서버에 전달하고 싶은 데이터는 query (쿼리 파라미터, 쿼리 스트링)를 통해서 전달 메시지 바디를 사용해서 데이터를 전달할 수 있다. 하지만, 지원하지 않는 곳이 많아서 권장하지 않는다.  실무에서는 GET에 메시지 바디를 안넣는다.     resource 조회 예시   클라이언트에서 /members/100 으로 100번 유저를 조회한다. 그 후, 정보를 달라고 GET 요청을 보낸다. 서버에서는 받은 메세지를 분석하여 내부의 유저 정보를 조회한다. 그 후, JSON data 형태로 결과 Response를 만든다. 응답 메세지를 받았고, 정상적으로 받았기에 200 OK status를 가진다. 또한, 회원 정보도 담겨있다.  위 에시에는 JSON이지만, 실제로는 HTML일수도 있고, 다양한다.     2.2 HTTP method - POST 2.2.1 POST란? POST /members HTTP/1.1 Content-Type: application/json { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 }  요청 데이터 처리하는 method 메시지 바디를 통해 서버로 요청 데이터를 전달한다.  GET과의 차이점   서버는 요청 데이터를 처리  메시지 바디를 통해 들어온 데이터를 처리하는 모든 기능을 수행한다.   주로 전달된 데이터로 신규 resource 등록, 프로세스 처리에 사용  2.2.2 POST를 사용한 resource 등록 과정  첫 번째: 메세지 전달   클라이언트는 메세지 바디에 등록할 회원 정보를 JSON형태로 만들어 담는다. 그리고 해당 정보를 서버로 전송한다.\n( 정보를 전달하기 전에, 사전에 서버가 무엇을 할지 미리 약속이 되어 있어야 한다.)   두 번째: 신규 resource 생성   서버에서 받는 메세지를 분석해 데이터베이스에 등록한다. 이 때 신규 아이디도 생성.   세 번째: 응답 데이터   Location이라는 헤더 정보로 회원이 생성된 경로를 첨부한다. 신규회원에 대한 데이터를 바디에 담아서 보내준다. 만들어졌기 때문에 Created라 뜬다. 그리고, 자원의 신규 생성된 URL을 보내준다.  2.2.3 요청 데이터를 어떻게 처리한다는 뜻일까??  리소스 URI에 POST 요청이 오면, 요청 데이터를 어떻게 처리할지 리소스마다 따로 정해야한다 -\u0026gt; 정해진 것이 없다.\n  예를 들어 POST는 다음과 같은 기능에 사용된다.  HTML 양식에 입력된 필드와 같은 데이터 블록을 데이터 처리 프로세스에 제공  예) HTML, FORM에 입력한 정보로 회원 가입, 주문 등에서 사용   게시판, 뉴스 그룹, 메일링 리스트, 블로그 또는 유사한 기사 그룹에 메시지 게시  예) 게시판 글쓰기, 댓글 달기   서버가 아직 식별하지 않은 새 resource 생성  예) 신규 주문 생성   기존 자원에 데이터 추가  예) 한 문서 끝에 내용 추가하기      2.2.4 POST method 정리 1. 새 resource 생성(등록)\n 서버가 아직 식별하지 않은 새 resource 생성  2. 중요! 요청 데이터 처리\n 단순히 데이터를 생성하거나, 변경하는 것을 넘어서 프로세스를 처리해야 하는 경우 상태가 변하기 위해서 POST를 사용하기 때문에, 새로운 리소스가 생성되지 않을 수 있다. 그렇다 할지라도, 서버에 큰 변화를 일으킬 때는 POST를 생성해야 한다.  예) 주문에서 결제완료 -\u0026gt; 배달시작 -\u0026gt; 배달완료처럼 단순히 값 변경을 넘어 프로세스의 상태가 변경되는 경우   POST의 결과로 새로운 리소스가 생성되지 않을 수도 있음  예) POST/orders/{orderld}/start-delivery (컨트롤 URI)  URI를 설계할 때는 resource 단위로 설계해야 하지만, 어쩔 수 없이 행동으로 할 때가 있다. 이 때 동사의 URI가 나올 수 있다. 이 URI를 컨트롤 URI 라 한다.      3. 다른 메서드로 처리하기 애매한 경우\n 예) JSON으로 조회 데이터를 넘겨야 하는데, GET 메서드를 사용하기 어려운 경우 애매하면 POST   3. HTTP method - PUT,PATCH,DELETE 3.1 HTTP method - PUT PUT /members/100 HTTP/1.1 Content-Type: application/json { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 }   _리resource resource\n 리소스가 있으면 대체하고, 없으면 생성한다. (Overwirte)    POST와의 차이점: 클라이언트가 리소스를 식별한다.\n 클라이언트가 resource 위치를 알고 URI 지정한다.     예) 리소스가 없는 경우  /members/100 이라는 신규 리소스를 생성한다. 신규 리소스의 내용은 다음과 같다.    { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 }  예) 리소스가 있는 경우  /members/100 경로에 아래 내용으로 리소스가 있다면    { \u0026#34;username\u0026#34;: \u0026#34;young\u0026#34;, \u0026#34;age\u0026#34;: 50 }  PUT method로 보내면 다음과 같이 대체된다.  { \u0026#34;username\u0026#34;: \u0026#34;hello\u0026#34;, \u0026#34;age\u0026#34;: 20 }  하지만 아래 내용으로 리소스를 보낸다면 아래 내용으로 완전히 대체된다. username 필드가 삭제된다.  { \u0026#34;age\u0026#34;: 50 }  3.2 HTTP method - PATCH PUT /members/100 HTTP/1.1 Content-Type: application/json { \u0026#34;age\u0026#34;: 50 }  그러면 기존 리소스를 갈아치우는 게 아니라, 수정하고 싶으면 어떻게 해야할까?? PATCH method 를 사용한다.  만약 PATCH가 지원되지 않은 서버라면 POST를 사용한다.   PUT과 양식은 비슷하지만, 서버에서 PATCH로 전송된 경우 필요한 부분만 업데이트된다.   그 결과, PUT과는 다르게 회원 정보에서 age만 변경된다.  { \u0026#34;age\u0026#34;: 50 }  3.3 HTTP method - DELETE DELETE /members/100 HTTP/1.1 Host: localhost:8080  클라이언트가 보내면 위 resource url에 해당되는 회원 정보를 서버에서 삭제한다.   4. HTTP method의 속성   HTTP 메서드별 속성   메서드의 속성\n 안전(Safe Methods) 멱등(idempotent Methods) 캐시가능(Cacheable Methods)     4.1 안전(Safe)  호출해도 리소스를 변경하지 않는 속성\n  GET은 단지 조회만 하기 때문에 안전하지만, 나머지는 아니다.  Q. 그래도 변경을 요청하면 변경되진 않아도, 로그에 계속 남게되어 터지지 않을까?? A: 안전은 해당 리소스만 고려한다. 그런 부분까지 고려하지 않는다.     4.2 멱등(Idempotent Methods)   f(f(x)) = f(x) 몇 번을 호출하든 결과가 똑같은 속성    멱등 메서드  GET: 몇 번을 조회하든 같은 결과가 조회된다. PUT: 결과를 대체한다. 따라서 같은 요청을 여러번 해도 최종 결과는 동일. DELETE: 결과를 삭제한다. 같은 요청을 여러번 해도 결과는 동일. POST : 멱등이 아니다! 두 번 호출하면 같은 결제가 중복해서 발생할 수 있다.     활용  자동 복구 메커니즘 서버가 TIMEOUT 등으로 정상 응답을 못 주었을 때, 클라이언트가 같은 요청을 다시 해도 되는가?? 판단근거     멱등은 외부 요인으로 인해 리소스가 변경되는 건 고려하지 않는다.  내가 호출하는 것에 한정한다. 예시:  사용자1: GET -\u0026gt; username:A, age:20 사용자2: PUT -\u0026gt; username:A, age:30 사용자1: GET -\u0026gt; username:A, age:30 -\u0026gt; 사용자2의 영향으로 바뀐 데이터 조회   이런 부분은 멱등하지 않다고 생각하자.     4.3 캐시가능(Cacheable Methods)  응답 결과 리소스를 캐시해서 사용해도 될까? GET, HEAD, POST, PATCH 캐시가 가능하지만, 실제로는 GET, HEAD 정도만 캐시로 사용한다.  POST, PATCH는 본문 내용까지 캐시 키로 고려해야 하는데, 구현이 쉽지 않다. GET은 URL만 캐시 키로 관리하면서 구현이 쉽기에 사용이 편하다.     Reference  모든 개발자를 위한 HTTP 웹 기본지식 HTTP 메서드  ","permalink":"http://jeha00.github.io/post/network/network_http_4/","summary":"HTTP method인 GET, POST, PUT, PATCH, DELETE 그리고 속성에 대해 알아본다.","title":"[TIL] Network HTTP method"},{"content":"Intro  HTTP 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 이다. 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고자 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.  1. 모든 것이 HTTP 1.1 HTTP란? (지금은 HTTP 시대!) : 링크를 통해 HTML 같은 문서를 연결할 수 있는 프로토콜을 의미한다. 하지만, 이제는 문서 뿐만 아니라 HTTP 메세지에 모든 것을 전송한다.\n HTML, TEXT IMAGE, 음성, 영상, 파일 JSON, XML (API) 거의 모든 형태의 데이터를 저장하여 전송 가능하다. 서버 간에 데이터를 주고 받을 때도 대부분 HTTP를 사용한다.  1.2 HTTP 역사 (HTTP/1.1을 기준으로 학습)  HTTP/0.9 1991년: GET 메서드만 지원, HTTP 헤더X HTTP/1.0 1996년: 메서드, 헤더 추가 HTTP/1.1 1997년: 가장 많이 사용, 우리에게 가장 중요한 버전  HTTP 강의는 이 버전을 기준으로 설명한다. RFC2068 (1997) -\u0026gt; RFC2616 (1999) -\u0026gt; RFC7230~7235 (2014) 현재는 RFC7230 버전부터 본다.   HTTP/2 2015년: 성능 개선 HTTP/3 진행중: TCP 대신에 UDP 사용, 성능 개선  1.3 기반 프로토콜  TCP 기반으로 작동하는 프로토콜은 HTTP/1.1, HTTP/2 다. UDP 기반으로 작동하는 프로토콜은 HTTP/3 다.  기본적으로 HTTP/1.1에서 개선된 것이므로 우리는 HTTP/1.1을 공부한다.   현재 HTTP/1.1 주로 사용한다.  HTTP/2, HTTP/3도 점점 증가하고 있다.     [HTTP/3가 UDP 기반인 이유]\n기본 TCP는 3 way handshake로 신뢰성이나 연결성이 보장되지만, 속도가 떨어진다. 그래서 UDP를 애플리케이션 레벨에서 재설계되어 나온게 HTTP/3다.\n  사이트에서 기반 프로토콜을 확인하려면 검사(F12)에 들어가 Network tab을 클릭 한다. 하단에 Name tab을 오른쪽 마우스 클릭하여 Protocol을 체크한다. h3는 http/3 고, h2는 http/2 를 의미한다. 구글은 h3를 사용하고, 네이버는 h2를 사용한다.  1.4 HTTP 특징  클라이언트 서버 구조 무상태 프로토콜(stateless), 비연결성 HTTP 메시지 단순함, 확장 가능  HTTP는 단순하고, 스펙도 읽어볼만 하다. HTTP 메시지도 매우 단순하다. 크게 성공하는 표준 기술의 하나의 예로, 단순하지만 확장 가능한 기술이다.    각 특징들에 대해 알아보자.\n 2. 클라이언트 서버 구조  HTTP는 클라이언트와 서버 구조로 되어있다. 클라이언트는 HTTP 메세지를 만들어서 서버에 요청(request)을 보낸 후, 서버로부터 응답(response)이 올 때까지 기다린다. 서버는 클라이언트로부터 온 요청(request)에 대한 결과를 만들어서 응답(response)한다.   [클라이언트 서버 구조가 중요한 이유]\n독립적 구조 -\u0026gt; 각자의 역할에 집중\n옛날에는 클라이언트와 서버가 분리되어 있지 않고, 합쳐져 있었다. 분리되고 나서 비지니스 로직과 데이터는 서버가 담당하여 집중하고, 클라이언트는 UI 사용성에 집중했다. 이로 인해서 클라이언트와 서버는 각각 독립적으로 진화할 수 있었다.\n  3. Stateful, Stateless 3.1 Stateful  Stateful 이란??  한 서버가 클라이언트의 이전 상태를 보존(기억)하기 때문에, 클라이언트의 요청에 응답하는 서버가 항상 같은 서버로 유지 되어야 하는 상태를 말한다.\n Stateful(상태 유지) 의 문제점은 무엇일까??  서버가 멈추거나 하는 여러 이유로 해당 서버를 쓸 수가 없는 상황이 발생했다. 다른 서버를 이용해야 한다. 이런 경우, 새로운 서버에서 이전 서버에 가지고 있던 상태값들을 가지고 있지 않아 에러가 발생된다.\n  예시: 고객을 클라이언트, 점원을 서버라고 생각하자.\n 서버가 문제 없이 유지되는 경우   고객: 이 `노트북` 얼마인가요?  점원: 100만원 입니다. (노트북 상태 유지)   고객: `2개` 구매하겠습니다.  점원: 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요?  (노트북, 2개 상태 유지)   고객: `신용카드`로 구매하겠습니다.  점원: 200만원 결제 완료되었습니다. (노트북, 2개, 신용카드 상태 유지)  서버가 바뀔 경우   고객: 이 `노트북` 얼마인가요?  점원 A: 100만원 입니다.   고객: `2개` 구매하겠습니다.  점원 B: ? 무엇을 2개 구매하시겠어요? (상태유지 X)   고객: `신용카드`로 구매하겠습니다.  점원C: ? 무슨 제품을 몇 개 신용카드로 구매하시겠어요? (상태 유지 X)   한 서버에서만 클라이언트의 상태를 기억하기 때문에, 서버가 변경되면 기존 서버에 저장된 클라이언트의 상태를 기억하지 못하여 에러가 발생했다. 그래서 항상 같은 서버로 유지 되어야 한다.\n3.2 Stateless  Stateless 란??  서버가 클라이언트의 이전 상태를 보존(기억)하지 않고, 클라이언트가 요청할 때마다 매번 모든 상태 값들을 전달 하기 때문에, 서버 변경이 용이 하다.\n  예시: 고객을 클라이언트, 점원을 서버라고 생각하자.\n 서버가 문제 없이 유지되는 경우   고객: 이 `노트북` 얼마인가요?  점원: 100만원 입니다.   고객: `노트북 2개` 구매하겠습니다.  점원: 노트북 2개는 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요?   고객: `노트북 2개`를 `신용카드`로 구매하겠습니다.  점원: 200만원 결제 완료되었습니다.  서버가 바뀔 경우   고객: 이 \u0026#39;노트북\u0026#39; 얼마인가요?  점원A: 100만원 입니다.   고객: \u0026#39;노트북 2개\u0026#39; 구매하겠습니다.  점원B: 노트북 2개는 200만원 입니다. 신용카드, 현금중에 어떤 걸로 구매 하시겠어요?   고객: \u0026#39;노트북 2개\u0026#39;를 \u0026#39;신용카드\u0026#39;로 구매하겠습니다.  점원C: 200만원 결제 완료되었습니다.   클라이언트가 모든 상태 값을 서버에 전달하기 때문에, 서버가 중간에 바뀌어도 문제가 되지 않는다. 항상 같은 서버로 유지될 필요없다. 그래서 서버 변경이 용이하기 때문에, stateless 는 무한한 서버 증설이 가능하다.\n그러면 서버 증설이 무한히 가능하다면 어떤 이점이 있을까???\n같은 기능을 하는 서버들 안에서 서버의 수평 확장(scale out) 에 유리하다.\n좋은 이점들이 많지만, 모든 것을 stateless(무상태) 로 할 수 없다. 실무 한계가 존재한다.\n 무상태 예시: 로그인이 필요 없는 단순한 서비스 소개 화면 상태 유지 예시: 로그인  로그인한 사용자의 경우, 로그인 했다는 상태를 서버에 유지해야 한다.   일반적으로 브라우저 쿠키와 서버 세션등을 사용해서 상태를 유지한다. 그래서 상태유지는 최소한만 사용하고, 최대한 무상태로 서버를 설계한다.   수평 확장(scale out)과 수직 확장(scale up)의 차이: 스케일 아웃과 스케일 업\n 3.3 정리   Stateful (상태유지): 중간에 서버가 변경되면 안된다.\n (만약 서버가 변경되야 한다면 상태 정보를 전부 다른 서버에게 미리 알려줘야 한다.)    Stateless (무상태): 중간에 서버가 바뀌어도 된다.\n 그래서 서버는 수평적 확장에 유리한다. (scale out) 하지만 모든 것을 무상태로 할 수 없기 때문에, 무상태로 서버를 최대한 설계하며, 상태 유지로 서버를 최소한 설계한다.    4. 비연결성 (connectionless) 4.1 연결을 유지하는 모델  TCP/IP 연결로 새로운 클라이언트와 연결하면서 이전 클라이언트와의 연결을 유지한다. 연결된 클라이언트가 놀고 있어도 서버가 유지해야 하는게 단점이다. 왜냐하면 서버의 자원이 연결을 유지하는데 계속 소모 되기 때문이다.  4.2 연결을 유지하지 않는 모델 (비연결성)  TCP/IP 연결 후, 클라이언트와 서버의 단 하나의 요청 응답 흐름이 끝나면 연결을 바로 종료한다. 그리고 다른 클라이언트와 연결 시, 이전 클라이언트와의 연결은 유지하지 않는다. 즉, 서버는 연결 유지를 하지 않아 최소한의 자원만 사용 할 수 있다.    HTTP의 비연결성\n HTTP는 기본이 연결을 유지하지 않는 모델이고, 일반적으로 초 단위 이하의 빠른 속도로 응답한다. 그래서 1시간 동안 수천명이 서비스를 사용해도 실제 서버에서 동시에 처리하는 요청은 수십개 이하로 매우 적다.  예) 웹 브라우저에서 계속 연속해서 검색 버튼을 누르지 않는다.   즉, 서버 자원을 매우 효율적으로 사용할 수 있다.     비연결성의 한계와 해결 방법  한계  TCP/IP 연결을 새로 맺어야 하기 때문에, 3 way handshake 시간이 추가된다. 웹 브라우저로 사이트를 요청하면 HTML 뿐만 아니라 JavaScript, css, 추가 이미지 등 수많은 자원이 함께 다운로드된다.   해결 방법  지금은 HTTP 지속 연결(Persistent Connections)로 문제 해결했다. HTTP/2 와 HTTP/3에서 더 많은 최적화를 한다.      4.3 HTTP 지속 연결: 비연결성의 한계 해결 방법 비연결성의 한계를 해결한 방법인 HTTP 지속 연결에 대해 알아보자.\nHTTP 초기에는 모든 자료에 대해서 비연결성으로 \u0026lsquo;연결 -\u0026gt; 응답 -\u0026gt; 종료\u0026rsquo; 를 반복하여, 시간이 대략적으로 1초 가량 소모되었다고 한다.\n아래 이미지를 참조하자.\n그러면 HTTP 지속 연결로 어떻게 변했을까??\n클라이언트는 서버와 연결을 한 다음, 필요한 자원들을 모두 다운받을 때까지 요청/응답이 반복된 뒤 종료된다.\n또한, HTTP/2,3으로 오면서 더 빨라졌다. 특히, HTTP 3으로 오면서 UDP를 사용하여 연결 속도 자체도 줄어들었다.\n _실무 상황에서 특정 시간에 발생하는 대용량 트랙픽의 경우, 수만명이 동시 요청하기 떄문에 무상태와 HTTP 지소 연결로 서버를 설계해야 대응할 수 있는 부분이 매우 많아진다. _\n예) 선착순 이벤트, 명절 KTX 예약, 학과 수업 등록, 선착순 할인 이벤트\n  5. HTTP 메시지  HTTP 메시지 구조를 알아보자.  공백 라인은 아래 순서로, 필수로 존재해야 한다.    5.1 시작 라인(start line)   start line은 요청 메시지와 응답 메시지 로 나눠진다.\n  start line = request - line (요청 메시지) / status - line (응답 메시지)\n request-line = method SP(공백) request-target SP HTTP-version CRLF(엔터) status-line = HTTP-version SP status-code SP reason-phrase CRLF    5.1.1 요청 메시지   start line = request - line (요청 메시지) / status - line (응답 메시지)\n  request-line = method SP(공백) request-target SP HTTP-version CRLF(엔터)\n  HTTP method (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\n 종류: GET, POST, PUT, DELETE \u0026hellip; 서버가 수행해야 할 동작 지정  GET: 리소스 조회 / POST: 요청 내역 처리      request-target (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\n absolute-path[?query] (절대경로[?쿼리]) 절대경로= \u0026ldquo;/\u0026rdquo; 로 시작하는 경로 참고: *, http://\u0026hellip;?x=y 와 같이 다른 유형의 경로지정 방법도 있다.    HTTP verison (GET /search?q=hello\u0026amp;hl=ko HTTP/1.1)\n    5.1.2 응답 메시지  start line = request - line (요청 메시지) / status - line (응답 메시지)  status-line = HTTP-version SP status-code SP reason-phrase CRLF HTTP version HTTP 상태 코드: 요청 성공, 실패를 나타냄  200: 성공 400: 클라이언트 요청 오류 500: 서버 내부 오류   이유 문구: 사람이 이해할 수 있는 짧은 상태 코드 설명 글    5.2 HTTP header  header - field = field - name \u0026ldquo;:\u0026rdquo; OWS field - value OWS\n(OWS: 띄어쓰기 허용)\n  field - name: 대소문자 구분 없음 field - value: 대소문자 구문 있음 용도  HTTP 전송에 필요한 모든 부가정보가 담겨져 있다.  예) 메시지 바디의 내용, 크기, 압축, 인증 예) 요청 클라이언트(브라우저) 정보, 서버 애플리케이션 정보, 캐시 관리 정보   표준 헤더가 너무 많다. (https://en.wikipedia.org/wiki/List_of_HTTP_header_fields) 필요한 경우, 임의의 헤더 추가 가능    5.3 HTTP message body  실제 전송할 데이터 HTML 문서, 이미지, 영상, JSON 등등 byte로 표현할 수 있는 모든 데이터 전송 가능   HTTP 정리  HTTP 메시지에 모든 것을 전송한다. HTTP 역사: HTTP/1.1을 기준으로 학습한다. 클라이언트 서버 구조이다. 무상태 프로토콜(stateless)다. HTTP 메시지 단순하며 확장 가능하다. 지금은 HTTP 시대다.   Reference  모든 개발자를 위한 HTTP 웹 기본지식 HTTP 기본 스케일 아웃과 스케일 업  ","permalink":"http://jeha00.github.io/post/network/network_http_3/","summary":"HTTP란 무엇이고, HTTP의 특징인 클라이언트 서버 구조, stateless, connectionless, HTTP mesage에 대해 알아본다.","title":"[TIL] Network HTTP basic"},{"content":"0. Introduction  HTTP에 관한 학습내용의 기본 출처: 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다. 이 강의는 HTTP에 대한 웹 기본지식을 설명하는 강의이므로, 내용이 간략할 수 있다.   학습 이유: 프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고 시작하고 싶어 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 공부한다.   1. URI  URI (Uniform Resource Identifier)란??  로케이터(locater), 이름(name) 또는 둘 다 추가로 분류될 수 있다.  from https://www.ietf.org/rfc/rfc3986.txt - 1.1.3. URI, URL, and URN      1.1 URI, URL, URN의 각 의미   URI의 단어 뜻\n 통일된 방식으로 다른 자원들과 구별할 수 있는 정보 Uniform: 리소스를 식별하는 통일된 방식 Resource: URI로 식별하는 수 있는 모든 자원으로, 제한 없다. Identifier: 다른 항목과 구분하는데 필요한 정보 (식별자)    URL\n Locator: resource가 있는 위치를 지정한다.    URN\n Name: resource에 이름을 부여한다. urn:isbn:8960777331 (어떤 책의 isbn URN) URN 이름만으로 실제 리소스를 찾을 수 있는 방법이 보편화 되지 않았다. 위치는 변할 수 있지만, 이름은 변하지 않는다.    그래서 앞으로 URI를 URL과 같은 의미로 이야기하겠다\n  1.2 URL 분석  URL 전체 문법 구조\nscheme://[userinfo@]host[:port][/path][?query][#fragment]\n  예시: https://www.google.com:443/search?q=hello\u0026amp;hl=ko 프로토콜: https 호스트명: google.com 포트번호: 443 path: \\search query parameter: ?q=hello\u0026amp;hl=ko  1.2.1 scheme  scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search?q=hello\u0026amp;hl=ko\n  주로 프로토콜을 사용한다.  프로토콜이란 어떤 방식으로 자원에 접근할건지 약속된 규칙이다. 예: http, https, ftp 등등   http는 80포트, https는 443포트를 주로 사용하며 포트는 생략 가능하다. https는 http에 보안 사용을 추가한 것이다. (HTTP Secure)  1.2.2 userinfo  scheme:// [userinfo@] host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search?q=hello\u0026amp;hl=ko\n  URL에 사용자 정보를 포함해서 인증할 때 사용한다. 하지만 거의 사용하지 않는다.  1.2.3 host  scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps:// www.google.com :443/search?q=hello\u0026amp;hl=ko\n  호스트명이다. domain 명 또는 IP 주소를 직접 입력한다.  1.2.4 PORT  scheme://[userinfo@]host [:port][/path][?query][#fragment]\nhttps://www.google.com :443 /search?q=hello\u0026amp;hl=ko\n  접속 포트 일반적으로 생략한다. 생략시 http는 80, https는 443이다.  1.2.5 path  scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443 /search ?q=hello\u0026amp;hl=ko\n  리소스의 경로다. 계층적 구조로 되어있다.  /home/file1.jpg /members /members/100, /item/iphone12    1.2.6 query  scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://www.google.com:443/search ?q=hello\u0026amp;hl=ko\n  key = value 형태로 되어 있다. ?로 시작하며 \u0026amp;로 추가 가능하다.  ex) ?keyA=valueA\u0026amp;keyB=valueB   query parameer, query string 등으로 불린다. 웹서버에 제공하는 파라미터, 문자형태다.\n  1.2.7 fragment  scheme://[userinfo@]host[:port][/path][?query][#fragment]\nhttps://docs.spring.io/spring-boot/docs/current/reference/html/gettingstarted.html #getting-started-introducing-spring-boot\n  html 내부 북마크 등에 사용한다. 서버에 전송하는 정보가 아니다.   2. 웹 브라우저 요청 흐름 다음 URL을 가지고 https://www.google.com:443/search?q=hello\u0026amp;hl=ko 웹 브라우저가 어떻게 요청해서 진행되는지 흐름을 파악해보자.\n DNS 조회: google.comd을 DNS에서 조회하여 해당 IP 주소를 찾는다. HTTPS PORT는 생략한다. 443 HTTP 요청 메시지를 클라이언트가 생성한다. HTTP 요청 메시지는 다음과 같다.  그러면 \u0026lsquo;Introduction 1: Internet Network\u0026rsquo; 에서 학습한 과정이 진행된다.\nHTTP 메시지 전송  resource 요청 시, Application layer에서 HTTP 메세지를 생성한다. 3 way handshake를 통해 socket에 연결한다. socket library를 통해 transport layer으로 데이터를 전송한다. transport layer에서 HTTP를 포함한 TCP 정보를 씌운다. Internet layer에서 TCP 정보를 포함하는 IP 패킷을 생성한다.  패킷이 도착하면 서버는 패킷 내부 HTTP method를 해석하여 정보에 맞는 동작을 한다. 서버에서 HTTP 응답 메세지를 생성한다.  클라이언트에서는 응답 메세지를 받아 HTML 렌더링을 한다.   Reference  모든 개발자를 위한 HTTP 웹 기본지식 URI와 웹 브라우저 요청 흐름  ","permalink":"http://jeha00.github.io/post/network/network_http_2/","summary":"URI, URL, URN 에 대해 알아보고, 웹 브라우저의 요청 흐름에 대해 알아본다.","title":"[TIL] Network HTTP intro. 2: URI 와 웹 브라우저 요청 흐름"},{"content":"0.Introduction HTTP에 관한 학습내용의 기본 출처는 김영한님의 모든 개발자를 위한 HTTP 웹 기본지식 이다. 강의를 듣고 정리한 내용과 모르는 부분에 대한 추가 내용을 합쳐 올린다.\n이 강의는 HTTP에 대한 웹 기본지식으르 설명하는 강의이므로, 내용이 간략할 수 있다.\n프레임워크를 사용하여 웹 개발을 배우기 전에, HTTP에 대해 기본적인 지식을 알고 시작하고 싶어 HTTP 공부를 시작한다. 이 강의에 대해 공부 후, 네트워크 전반에 대해 학습한다.\n 1. IP에 대해서 컴퓨터는 랜선 또는 인터넷 망을 통해서 통신한다. 그리고 인터넷 망은 수 많은 서버들로 구성되어 있으며, 이 서버들을 node(노드)라 한다.\n그러면 수 많은 node들을 거쳐서 \u0026lsquo;어떻게\u0026rsquo; data를 보낼 수 있을까??\n바로 IP 라는 규약을 통해서 보낸다.\n1.1 IP란??  Internet Protocol 약어로, 인터넷 데이터 통신을 원활히 하기 위해 필요한 통신 \u0026lsquo;규약\u0026rsquo;\n IP의 역할은\n 지정한 IP 주소로, packet이라는 통신 단위로, 데이터를 전달하는 역할이다.  그래서, 원하는 서버와 클라이언트에 데이터가 도달하기 위해서는 컴퓨터를 구분하는 고유 IP 주소(IP address)를 부여받아야 한다. 이 IP 주소의 형식은 100.100.100.1 같이 각 부분을 점으로 구분하여 표현한다.\n IP 주소 형식에 대해서도 IPv4, IPv6 로 분류된다. IPv4는 점으로 구분된 부분이 4개의 part고, IPv6는 6개의 파트로 구분된다. IPv4로는 주소 수가 부족하여 IPv6가 등장했다.   1.2 Packet이란?  수화물을 의미하는 Package와 덩어리를 의미하는 bucket의 합성어로, 통신 단위 packet에는 여러 데이터가 담겨져 있지만, 기본적으로 \u0026lsquo;주소지 정보(출발지의 IP 주소, 도착지의 IP 주소)\u0026rsquo; 그리고, 전달하려는 \u0026lsquo;전송 데이터\u0026rsquo;가 있다.\n 인터넷 망을 구성하는 node들은 다 IP를 따르기 때문에, node들은 출발지가 어디고, 어디가 도착지인지 이해할 수 있다. 그래서 node들이 IP를 참고하여 서로 packet을 던지면서 원하는 목적지로 보내진다.\n위의 이미지는 클라이언트의 패킷을 전달하는 내용이다.\n서버의 패킷을 전달하는 것도 동일한 원리다.\n 2. IP 문제점의 해결책: TCP 이 IP는 3가지 문제점(한계)이 있다.\n  비연결성 문제\n 상대방이 받을 수 없는 상태여도 패킷을 전송한다.  패킷을 받는 대상이 없거나 (컴퓨터가 off된 경우), 서비스 불능 상태여도 패킷을 전송한다. 연결이 안되도 보내지는 문제점이 존재한다. ex) 우편물을 A 주소로 보냈지만, 도착해서 보니 A 주소에 집이 없는 경우를 말한다.      비신뢰성 문제\n 손실 문제: packet이 전송되는 과정에 중간에 사라지는 경우  ex) 노드 서버에 도착했는데, 갑자기 케이블이 끊어지는 경우   순서 바뀜 문제: packet의 용량 문제로 나눠 보낼 때 순서에 문제가 발생한 경우    프로그램 구분 문제\n 한 IP 주소에서 2개 이상의 application을 사용하고 있을 때, 무슨 application에 관한 정보인지 어떻게 구분하는가??    2.1 인터넷 프로토콜 스택의 4계층 이를 해결한 것이 바로 TCP 다.\nTCP에 대해 알기에 앞서 인터넷 프로토콜 스택의 4계층에 대해 알아보자.\n인터넷 프로토콜은 4계층으로, 순서는 애플리케이션(응용) 계층 \u0026gt; 전송 계층 \u0026gt; 인터넷 계층 \u0026gt; 네트워크 인터페이스 순으로 구성된다.\n 애플리케이션 계층(Application layer) - HTTP, FTP 전송계층(Transport layer) - TCP, UDP 인터넷 계층(Internet layer) - IP 네트워크 인터페이스 계층(Network Access layer)  이 계층 순서로 어떻게 packet을 보내는지 알아보자.\n  resource 요청 시, Application layer에서 HTTP 메세지를 생성한다.\n-\u0026gt; 3 way handshake를 통해 socket에 연결한다.\n-\u0026gt; socket library를 통해 transport layer 계층으로 데이터를 전송한다.\n-\u0026gt; transport layer에서 HTTP를 포함한 TCP 정보를 씌운다.\n-\u0026gt; Internet layer에서 TCP 정보를 포함하는 IP 패킷을 생성한다.\n-\u0026gt; IP 패킷 정보가 인터넷을 거쳐서 서버에 도착한다.\n-\u0026gt; IP 패킷이 서버에 도착하면 IP 패킷과 TCP 세그먼트는 버리고, HTTP 메세지를 서버가 해석한다.\n-\u0026gt; HTTP 응답 메시지를 동일한 방식으로 packet을 생성하여 응답 패킷을 전달한다.\n-\u0026gt; 수 많은 노드들을 통해서 응답 패킷이 도착하면, 웹 브라우저가 HTML 렌더링하여 화면에 보여준다.\n  socket이란??\n application layer와 transport layer 사이에 위치하여, process가 메시지를 송신하고 수신할 수 있도록 API를 제공해주는 역할을 한다.    TCP 정보와 IP packet을 생성한 데이터 안에 담겨진 구체적인 내용은 다음과 같다.\n 2.2 IP 문제점의 해결책: TCP TCP (Transmisstion Control Protocol)는 전송 제어 프로토콜로, IP의 3가지 문제점에 대한 해결책이다. TCP에 여러 특징들이 있지만, 위 문제점을 해결하는 3가지 특징에 대해 중점적으로 알아보자.\n2.2.1 연결지향 - TCP 3 way handshake (가상 연결) 클라이언트가 서버에 데이터를 전송하기 전에 \u0026lsquo;연결과정\u0026rsquo;을 거친다. 이 과정으로 IP의 비연결성 문제를 해결한다.\n 첫 번째, 클라이언트가 서버에 접속 요청(SYN)한다. 접속 요청하는 걸 SYN(Synchronization) 이라 한다. 두 번째, 그 후 서버는 클라이언트의 요청을 수락(ACK)한다. 서버도 클라이언트에게 접속 요청(SYN)한다. 요청을 수락하는 걸 ACK(Acknowledgement) 라 한다. 세 번째, 클라이언트가 서버의 접속 요청에 수락(ACK)한다.  이 3가지 단계를 거친 후, 클라이언트가 서버에 데이터를 전송한다. 그래서 SYN -\u0026gt; SYN + ACK -\u0026gt; ACK 순서로 3 way handshake가 진행된 후, 데이터를 전송한다.\n하지만, 때로는 세 번째 단계 ACK할 때 데이터를 함께 전송한다.\n 3 way handshake 방식은 물리적으로 직접 연결된 상태가 아니라, 논리적으로 연결된 상태이다. 이 의미는 클라이언트와 서버 사이에 무수히 많은 노드들을 거쳐서 연결된 것을 의미한다. 물리적으로 직접 연결된 상태라는 건 클라이언트와 서버가 직섭 랜선으로 연결된 경우를 말한다.\n  2.2.2 데이터 전달 보증 데이터를 전송하면 수신 확인 메세지를 클라이언트에게 보내준다. IP의 \u0026lsquo;비신뢰성\u0026rsquo; 문제를 해결한다.\n 2.2.3 순서 보장 생성한 HTTP data에 TCP 정보를 씌울 때, 순서 정보가 들어가기 때문에, 데이터를 받고 나서 의도한 순서대로 온 건지 판단할 수 있다. IP의 \u0026lsquo;순서 바뀜\u0026rsquo; 문제를 해결한다.\n 3. TCP 문제점의 해결책: UDP IP의 여러 문제점을 해결하는 TCP이지만, 위에 TCP segment에 들어가는 정보들처럼 정보양이 많기 때문에 시간이 오래 걸리고, 최적화가 어렵다. 또한, 인터넷 자체도 이미 TCP 기반이라 다듬을 수 없다. 그래서 UDP를 최적화하여 속도를 증가시킬 수 있다. 최근에 이 UDP가 뜨고 있다. 웹 브라우저가 TCP handshake 과정을 줄일려고 하기 때문이다.\n TCP의 속도 문제를 해결할 수 있는게 UDP(User Datagram Protocol)이다. 데이터를 데이터그램 단위로 처리하는 프로토콜이란 의미다. 연결지향 X, 데이터 전달 보증과 순서보장 X 지만, 단순하고 빠르다. IP와 거의 같지만, 차이점은 PORT와 checksum 기능이 있다.  그리고 바로 이 PORT라는 기능이 IP의 세 번째 문제점을 해결해준다.\n 4. Port와 DNS란 무엇인가?? 4.1 Port란? 한 IP에서 여러 Application을 사용하고 있을 때, 데이터를 원하는 Application으로 보내기 위해서 PORT 가 필요하다. 이 port 정보는 TCP 세그먼트에 포함되어 있다.\n그래서 IP packet에 있는 IP 주소로 원하는 클라 또는 서버에 도달한다. 그리고, 클라 또는 서버 안에 원하는 Application에 데이터를 제공하기 위해서 PORT 정보를 활용한다.\nPort number는\n 0 ~ 65535번까지 할당이 가능하다. 0 ~ 1023번은 잘 알려진 포트이기 때문에, 사용하지 않는 것이 낫다.  FTP - 20, 21 TELNET - 23 HTTP - 80 HTTPS - 443    위 이미지를 예를 들어 서버 IP 200.200.200.3 에서 클라이언트의 웹 브라우저 요청에 응답하기를 원한다면 도착지 IP는 100.100.100.1 이고, PORT는 10010 이다.\n 4.2 DNS란? DNS는 Domain Name System으로, 기억하기 어렵고 변경될 수 있는 IP address 대신에 Domain Name을 사용하면 DNS에서 이 Domain name에 해당되는 IP주소로 응답하여 접속하는 시스템을 말한다.\n Reference  모든 개발자를 위한 HTTP 웹 기본지식 1. 인터넷 네트워크 Application layer Socket  ","permalink":"http://jeha00.github.io/post/network/network_http_1/","summary":"HTTP를 학습하기 위해 사전지식으로 IP,TCP/UDP, PORT, DNS를 알아본다.","title":"[TIL] Network HTTP intro. 1: Internet network"},{"content":"0. Introduction   window 10 환경에서 Hugo 라는 SSG의 한 종류를 사용해서 총 6단계를 거쳐서 \u0026lt;user-id\u0026gt;.github.io 주소의 github page를 만들고 배포한 후, contents를 업로드하는 것까지 내용을 다룬다.\n  마지막으로, 테마를 커스텀마이징하는 지름길과 후기를 남겼다.\n  위 과정들에서 필요한 개념들, 부딪혔던 error 및 해결책도 각 단계 마지막 부분에 작성했다.\n  🚩 동일한 주제로 다룬 블로그들을 보면 3단계와 4단계의 순서를 바꿔서 진행한다. 4단계 진행 후, 3단계를 진행해도 무방하다. 다만, 나는 그 과정에서 헷갈린 부분이 있어서 마지막에 theme 적용을 하기로 선택했다.\n 1. Static Site Generator 로 Hugo를 선택한 이유 1.1 SSG란?   Github page를 만들 때 SSG의 종류들로 \u0026lsquo;Jekyll\u0026rsquo;, \u0026lsquo;Hexo\u0026rsquo;, \u0026lsquo;Hugo\u0026rsquo; 가 많이 언급된다.\n  그러면 SSG란 무엇인가??\n \u0026lsquo;정적 페이지(Static Site)\u0026lsquo;란 HTML, CSS, JS를 미리 올려서 서버가 바뀌지 않는 HTML page를 보여주는 것을 말하는데, 이 정적 페이지를 보다 간편하게 만들어주는 것이 SSG(Static Site Generator)다.     이와 반대로 동적 페이지는 client에 반응하여 HTML page를 동적으로 만들어진 페이지를 말한다. 더 상세한 정보를 원하시는 분은 정적 웹은 뭐고 동적 웹은 뭔가요? 이 영상을 참고하시길 바란다.\n 1.2 SSG의 종류와 Hugo를 선택한 이유  hugo를 선택하기에 앞서 각 SSG의 특징들에 대해 알아야 하기 때문에, Jekyll, Hexo, Hugo의 각 특징들은 다음과 같다.   Jekyll -루비 기반 -현재 가장 인기 있음(깃헙 별 수 제일 많음) -한글 레퍼런스도 제일 많음 -느리다는 제보가 많음(몇 십개의 포스팅 뿐인데도 빌드 하는데 5분씩 걸린다고) -윈도우 공식 지원 안됨 Hexo -자바스크립트(Node.js) 기반 -한글 레퍼런스 꽤 많음 -메인 개발자가 손을 놓은 듯 -개발자가 중국인? 이라 구글링하면 중국어 글이 많이 나옴 Hugo -Golang 기반 -빌드 빠름 -문서화 잘돼있음 -깃헙 별 수가 헥소보다 많음 -한글 레퍼런스가 거의 없음 출처: http://tadakichi.tistory.com/188  그래서 4가지 이유로 Hugo를 선택했다.  남들이 안해본 걸 해보자. 한글 레퍼런스가 거의 없기 때문에, 내가 기여할 수 있는 부분이 다른 것보다 있을 것이다. 내가 원하는 디자인 대부분이 Hugo였다. 앞으로 계속해서 기술 블로그를 작성할 것이기 때문에, 빠른 빌드를 원했다.     2. Github page 만들기 위한 local 환경 조성  첫 번째, git을 설치한다. 그리고, github 에 가입한다.\n두 번째, Visual Studio Code (VSC), Atom 같은 에디터를 설치한다.\n세 번째, window 환경에 Hugo를 설치한다.\n 2.1 첫 번째  github 가입은 Github 에 들어가서 오른쪽 상단에 있는 Sign up을 클릭하여 진행한다. 그러면 최종적으로 https://github.com/user-name/ 을 가진다. github page의 url은 [user-name].github.io 로 가진다.  2.2 두 번째  나는 visual studio code를 사용한다. visual studio code 여기에 들어가 설치한다.  2.3 세 번째  window 환경에 hugo를 설치한다. window에서 Hugo 설치하기 이 영상 하나 따라하면 쉽다. 하지만, 글로 보고 싶은 분들을 위해 작성한다.  hugo 다운로드 로 들어가서 아래로 scroll을 내리면 window 버전을 다운받아 C:\\Hugo\\bin 디렉토리를 생성해서 다운받은 압축 파일을 해제 어느 위치에서나 Hugo가 실행할 수 있도록 윈도우 검색으로 시스템 환경 변수 편집을 검색하여 들어간다. 고급 탭의 환경 변수 로 들어간다. 사용자 변수 란의 path를 클릭 후, 편집 을 클릭한다. 새로 만들기를 클릭하여 C:\\Hugo\\bin 경로를 추가한다. cmd에 echo %PATH% 를 입력하여 추가한 경로가 있는지 확인한다. 해제한 압축 파일에서 hugo 실행하여 설치 후, cmd에 hugo version 으로 동작 확인한다.     3. 새로운 2개 github repo 와 local 연결하기 3.1 Submodule 개념 이해하기 ❗ 이런 개념이 있구나 정도만 이해하고 3.1을 넘어가기. 이해하기 어렵다면 생략하고 바로 다음 3.2 chapter로 넘어가 따라해보자.\n  이 단계를 진행하기 전에 submodule 개념을 알아야 한다. 영어 독해가 가능하신 분들은 How to Set Up a Hugo Site on Github Pages - with Git Submodules! 이 링크에 들어가 보시기 바란다. submodule에 대해 그림과 함께 잘 설명되어있다. 아래 내용은 위 블로그에서 submodule에 대한 부분을 번역한 내용이다. 오역이 있다면 댓글로 알려주시면 감사하겠다.\n  public folder는 3.4 B repo를 public 폴더에 submodule로 연결하기 파트에서 아래 명령어로 만들어진다.\n# blog 폴더의 submodule로 branch main에 B repo를 add 한다. # sample: git submodule add https://github.com/JeHa00/JeHa00.github.io.git public \u0026gt; git submodule add -b main https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git public 출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n   왜 Git submodule인가??\n모든 git project는 repository에 저장된다.\n이 git submodule은 한 레포 안에서 다른 레포를 참조하도록 해준다.\n그래서 프로젝트 안에 프로젝트를 효과적으로 운영할 수 있다.\n중요한 건 submodule은 main project와 달리 자신만의 commit과 branch histroy를 가진다.\n그래서 프로젝트들을 분리시킬 수 있다. 이는 매우 강력한 도구다. 아래 그림에서는 git project에서 submodule을 사용할 시, 어떻게 코드가 포함되는지를 보여준다. \u0026hellip;.\n메인 repository의 submodule로 public folder를 하위 폴더로 설정하여, 독립된 branch history를 갖는 개체로 대할 수 있다.\n출처: https://www.adamormsby.com/posts/000/how-to-set-up-a-hugo-site-on-github-pages-with-submodules/\n   A repo가 blog 에 remote origin으로 연결된다.\n  B repo가 public 폴더 형태로, blog의 submodule로 들어간다.\n출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n   3.2 New repository 2개 만들기  자신의 github에 2개의 repository를 만든다.\n  2개의 repository를 각각 A,B라고 하자. 2개의 repository는 public과 private 중 public으로 만든다. private 으로 하면 site에 배포가 안될 수도 있다. A는 user-name/blog 로, B는 user-name/user-name.github.io 로 명칭을 만든다.\nex) A의 url은 github.com/JeHa00/blog / B의 url은 github/JeHa00/JeHa00.github.io B repo의 이름이 github page로 쓰일 url.  ❗❗ 주의: 두 repo를 만들 때 주의사항\n  A repo에는 README.md 만들지 말기\n README.md가 있다면 나중에 git push 시에 충돌이 일어난다.    B repo에 README.md를 만들기\n repo가 비어있으면 submodule로 연결이 안된다.    3.3 Hugo new site 생성 및 remote add origin A repo 실행  Visual Studio Code의 terminal 또는 Window의 cmd에 입력한다.  경로 C:\\Hugo  # 새로운 Hugo project 생성 # sample: Hugo new site blog \u0026gt; Hugo new site \u0026lt;project 명칭\u0026gt;  # project folder인 blog로 이동 # sample: cd blog \u0026gt; cd \u0026lt;project 명칭\u0026gt;  #3. local git 초기화 \u0026gt; git init  # blog의 remote origin으로 A repo 추가하기 # sample: git remote add origin https://github.com/Jeha00/blog.git \u0026gt; git remote add origin https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;A repo 명칭\u0026gt;.git  # commit 하기 위해 모든 파일을 stage에 올리기 \u0026gt; git add .  # commit \u0026gt; git commit -m \u0026#34;add origin\u0026#34;  # the remote origin 에 push 하겠다. branch는 master로 하겠다. \u0026gt; git push origin master   remote origin이 잘 되었는지 확인하기 위해서는 git remote -v를 입력하면 뜬다.\n  error: src refspec master does not match any 가 뜬다면 이는 stage에 오른 파일이 없다는 의미이므로, git add . 를 했는지 확인하기\n  hugo new site \u0026lt;project 명칭\u0026gt; 명령으로 local에서 컨텐츠를 관리하기 위한 장소 생성\n  이 때 경로는 C:\\Hugo 인 상태에서 terminal에 입력한다.\n  \u0026lt;project 명칭\u0026gt;을 A repo 이름과 똑같이 한다.\n  project를 새로 생성해서 project 파일 경로는 C:\\Hugo\\\u0026lt;project 명칭\u0026gt; 일 것이다.\n  위 명령어로 생긴 tree는 다음과 같다.\n  Hugo/project 명칭 ├─archetypes ├─content ├─data ├─layouts ├─static ├─themes └─config.toml   git remote add origin https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;A repo 명칭\u0026gt;.git Hugo new site로 만든 project 에 대한 remote origin으로 A repo를 추가하겠다는 의미다.\n  C:\\Hugo\\\u0026lt;project 명칭\u0026gt; 경로에서 git push를 하면 앞으로 A repo에 저장된다.\n  그 결과, A repo안에 구성은 다음과 같다.\n  \u0026lt;user-name\u0026gt;/A repo 이름 ├─archetypes └─config.toml 3.4 B repo를 public 폴더에 submodule로 연결하기 # blog 폴더의 submodule로 branch main에 B repo를 add 한다. # sample: git submodule add https://github.com/JeHa00/JeHa00.github.io.git public \u0026gt; git submodule add -b main https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git public  이 명령어로 public 폴더가 생성되고, 이 폴더의 remote origin이 B repo가 된다. public 폴더가 생긴 걸 알 수 있다.  Hugo/project 명칭 ├─archetypes ├─content ├─data ├─layouts ├─public ├─static ├─themes ├─.gitmodules └─config.toml  하지만 public 폴더가 생긴다고 연결된 게 아니다. 확실하게 연결이 되었다면 .gitmodules 파일이 생기고, 이 안에 아래와 같은 코드가 생겨야 한다.  [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/JeHa00/jeha0.github.io.git branch = main   만약 public folder는 생겼지만, .gitmodules와 위 코드가 없다면 다음 조치를 취한다.\n  첫 번째, public folder를 삭제한다.\n  두 번째, local 문서에서 C:\\Hugo\\\u0026lt;new project 명칭\u0026gt; folder로 들어가 숨긴 파일 보이기를 하여, .git 폴더의 modules 폴더를 삭제한다.\n  세 번째, terminal에 C:\\Hugo\\\u0026lt;new project 명칭\u0026gt; 경로에서 git rm --cached public 을 입력한다.\n  첫 번째, 두 번째만 실행한다면 다음과 같은 error 종류들이 뜰 수 있다.\nerror: 'public' does not have a commit checked out\nerror: 'public' already exists in the index\nerror: a git directory for 'public' is found locally with remote(s)\n  이렇게 뜨는 이유는 cach에 public이 아직 남아있기 때문이다. 그래서 이를 제거하고자 git rm --cached public 을 입력한다.\n  그리고, 다시 submodule 명령어를 실행하여, .gitmodules 에 위 코드가 생기는지 확인한다.\n  다시 https://github.com/\u0026lt;user-name\u0026gt;/blog.git 에 public @ 폴더가 생겼는지 확인한다. 이 폴더가 생겼다면 submodule 등록이 확실하게 완료되었다.\n  만약, Permission denied (publickey) 오류가 뜬다면 SSH 보안키를 등록해야한다.\n  위 방법대로 했지만 public 폴더와 B repo가 submodule 연결이 되지 않는다면, B repo에 아무런 file이 존재하지 않아서다.\n  3.2 New repository 2개 만들기 내용처럼 B repo에 README.md를 추가하여 empty repo로 만들지 말자.\n  3.5 public directory와 project root directoy git push 단계 # public directory에 site build 수행하기 \u0026gt; hugo  # public dicrectory로 이동 \u0026gt; cd public  \u0026gt; git add . \u0026gt; git commit -m \u0026#39;first build\u0026#39; \u0026gt; git push origin main  # the project root 로 되돌아가기 \u0026gt; cd ..  \u0026gt; git add . \u0026gt; git commit -m \u0026#39;first build - update submodule reference\u0026#39; \u0026gt; git push origin master  위 명령어로 생긴 tree는 다음과 같다.  Hugo/\u0026lt;project 명칭\u0026gt; ├─archetypes ├─content ├─data ├─layouts ├─public │ ├─categories │ └─tags ├─resources │ │─_gen │ ├─assets │ └─images ├─static │─themes ├─.gitmodules └─config.toml  A repo의 directory는 아래와 같다. 아래 image처럼 public@가 떠야 한다. submodule이 잘 연결되었다는 의미다.   4. Github page에 theme 적용 4.1 원하는 테마 찾기   Hugo Theme Star Ranking, jamstackthemes 그리고, Hugo Themes: Complete List 이 3가지 사이트 정도라면 충분히 찾을 수 있다.\n  처음에 테마 찾는 데 많은 시간을 썼는데, 지금 생각해보면 기본 테마를 찾은 다음에 customizing 하는 방법이 더 빠른 방향이었다.\n  4.2 submodule을 사용하여 테마 적용하기   submodule로 테마를 적용한 이유는 업데이트된 테마를 쉽게 가져올 수 있기 때문에, clone보다 submodule로 만드는 게 더 낫다고 한다. (by submodule이 나은 이유)\n  테마 또한 submodule로 적용한다. 구조는 아래와 같다.   출처: How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # root project folder에 submodule로 테마를 적용한다 # git submodule add .git themes/Paper-Mod \u0026gt; git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt;   원하는 theme을 fork 한다.\n  fork를 하는 이유는 테마를 직접 수정할 수 없고, 수정한 버전을 유지하기 어렵기 때문에, fork하여 자신의 github으로 가져온다.\n  fork한 테마의 경로를 복사하는 방법은 다음과 같다.\n   위 이미지에서 url 옆에 있는 버튼을 클릭하면 복사된다. git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt; 에서 themes란 밑에 이미지의 themes folder를 말한다. 이 folder 밑에 \u0026lt;테마명\u0026gt; folder를 만들어, 테마 자료들을 다운받는다는 의미다.  Hugo/\u0026lt;project 명칭\u0026gt; ├─archetypes ├─content ├─data ├─layouts ├─public │ ├─categories │ └─tags ├─resources │ │─_gen │ ├─assets │ └─images ├─static │─themes │ └─\u0026lt;테마명\u0026gt; ├─.gitmodules └─config.toml  다음으로 config.toml 에 theme = 이 없으면 추가하여, theme = \u0026lt;테마명\u0026gt; 을 적는다. BaseURL을 B repo의 끝 부분인 https://\u0026lt;user-name\u0026gt;.github.io/ 로 수정한다. 이 경로가 앞으로 github page의 URL이 된다. theme 적용 또한 submodule이므로 .gitmodules 파일에 다음과 같이 2개가 등록되었다.  #example [submodule \u0026#34;public\u0026#34;] path = public url = https://github.com/\u0026lt;user-name\u0026gt;/\u0026lt;B repo 명칭\u0026gt;.git branch = main  [submodule \u0026#34;\u0026lt;테마명\u0026gt;\u0026#34;] path = themes/\u0026lt;테마명\u0026gt; url = 테마 url  theme 적용 후, theme 폴더 안에 examplesite 란 의미의 폴더가 있다면, 그 폴더 안에 있는 config.toml을 복사하여 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; 경로에 있는 config.toml에 복사 붙여 넣는다. BaseURL만 다시 수정한다.  4.3 테마 적용되었는지 테스트하기 경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # D 란 draft 문서까지 포함해서 보겠다는 의미다. \u0026gt; hugo server -D  그러면 https://localhost:1313/ 이 뜬다. 이를 클릭하면 테마가 적용되었는지 알 수 있다. terminal 작업을 다시 할려면 Ctrl + C를 눌러 중단한다. hugo server -D 가 돌아가는 동안에는 글의 수정을 바로 확인할 수 있다.   5. Contents 생성과 업로드 5.1 Contents 생성과 public folder에 반영하기 경로 C:\\Hugo\\\u0026lt;New Project 명칭\u0026gt; # contents 생성 \u0026gt; hugo new post/test1.md  # 생성된 글 public 폴더에 반영하기 \u0026gt; hugo -t \u0026lt;테마이름\u0026gt;   hugo new post/test1.md는 \\content\\post\\test1.md 경로로 생성된다.\n  contents 생성 후, hugo server -D로 localhost에는 생성한 contents가 보이는데, github page에는 안보인다면 hugo -t \u0026lt;테마이름\u0026gt;명령을 하지 않았기 때문이다.\n  여기서 \u0026lt;테마이름\u0026gt;은 git submodule add \u0026lt;theme 경로\u0026gt;.git themes/\u0026lt;테마명\u0026gt; 에서 테마명과 동일해야 한다.\n  5.2 컨텐츠 업로드 # public dicrectory로 이동 \u0026gt; cd public  \u0026gt; git add . \u0026gt; git commit -m \u0026#39;commit message\u0026#39; \u0026gt; git push origin main  # the project root 로 되돌아가기 \u0026gt; cd ..  \u0026gt; git add . \u0026gt; git commit -m \u0026#39;commit message\u0026#39; \u0026gt; git push origin master  6. Utterances로 댓글 기능 추가, deploy.sh로 자동화 6.1 Utterances로 댓글 기능 추가  사용 방법   Github에 \u0026lt;user-name\u0026gt;/blog-comments 같이 private이 아닌 public 저장소를 만든다. Utterance에서 1번에서 만든 repository를 입력한다. Utterance에서 Mapping 방식 6가지 중 한 가지를 선택한다. 2번 3번에 따라 Utterance에서 생성된 script를 복사하여 각자의 적절한 템플릿 위치가 추가한다. 추가 위치는 각 theme의 README.md 를 꼼꼼히 읽어본다.  아웃사이더님의 블로그 글에서 보고 가져온다.\n6.2 deploy.sh로 자동화  deploy.sh 파일명으로 아래 코드를 저장한 후, C:\\Hugo\\\u0026lt;프로젝트 명칭\u0026gt; 경로에 저장한다. 이후 Git Bash 프로그램을 사용하여 C:\\Hugo\\\u0026lt;프로젝트 명칭\u0026gt; 경로로 이동 후, bash deploy.sh를 입력하면 the project root와 submodule 모두 순차적으로 push가 실행된다. 나는 submodule은 main default branch에, the project root는 master default branch로 설정했다.  #!/bin/bash  echo -e \u0026#34;\\033[0;32mDeploying updates to GitHub...\\033[0m\u0026#34;  # Build the project. hugo -t \u0026lt;테마명\u0026gt;  # Go To Public folder cd public # Add changes to git. git add .  # Commit changes. msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ]  then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34;  # Push source and build repos. ## master 대신 각자 연결한 branch 명으로 수정하면 된다. git push origin main  # Come Back up to the Project Root cd ..   # blog 저장소 Commit \u0026amp; Push git add .  msg=\u0026#34;rebuilding site `date`\u0026#34; if [ $# -eq 1 ]  then msg=\u0026#34;$1\u0026#34; fi git commit -m \u0026#34;$msg\u0026#34;  ## master 대신 각자 연결한 branch 명으로 수정하면 된다. git push origin master  7. To customize blog theme \u0026amp; 후기 To customize blog theme   커스텀마이징을 위한 제일 좋은 방법은 각자 선택한 테마 템플릿의 README.md를 꼼꼼히 읽어보는 게 제일 빠른 지름길이라 생각한다.\n  사용자가 원하는 기능들을 어떻게 추가하면 되는지 설명해논 템플릿이 많기 때문에, 반드시 README.md 를 꼼꼼히 읽기 바란다.\n  후기   git에 대해 더 숙지를 하고 나서 git page를 만들기 시작했다면 시간 소모를 줄일 수 있었을 것이다. 급한 마음에 github page를 시작하여 생각보다 많은 시행착오와 error들을 격었다. 이 error들은 대체로 git을 정확히 이해하지 못해서 발생하는 문제점들이다.\n  이번 일을 통해서 git이 개발자에게 사람의 숨쉬기와 같다는 걸 느껴서 Pro git 이란 책을 사서 꾸준히 공부하기로 결정했다.\n  gith page를 만들었으니, TIL부터 시작하여 꾸준히 공부하자. Hugo를 선택한 것이 처음 시도할 때는 매우 힘들었지만, 지금 와서는 잘한 선택임을 느낀다.\n  진행하다가 부딪힌 error들에 대해서는 바로 바로 기록을 하자. 이는 반복적인 똑같은 삽질을 예방할 수 있다.\n   Reference   정적 웹은 뭐고 동적 웹은 뭔가요?\n  Jekyll, Hexo, Hugo 차이점 설명\n  Hugo로 Github.io 블로그 만들기\n  How to Set Up a Hugo Site on Github Pages - with Git Submodules!\n  theme 적용에 submodule이 나은 이유\n  아웃사이더님의 블로그 글\n  ","permalink":"http://jeha00.github.io/post/dev-contents/hugo%EB%A1%9C-github-page-%EB%A7%8C%EB%93%A4%EA%B3%A0-%EB%B0%B0%ED%8F%AC%ED%95%98%EA%B8%B0/","summary":"SSG의 한 종류 \u0026lsquo;Hugo\u0026rsquo;와 \u0026lsquo;git remote, git submodule\u0026rsquo;로 Github page를 만든다. 그 후, 컨텐츠 생성과 업로드를 한다. 마지막으로 utterances로 댓글 기능 추가, deploy.sh를 사용하여 업로드하는 방법을 다룬다.","title":"Window에서 Hugo로 Github page 만들고 배포하기"}]